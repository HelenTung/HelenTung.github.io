[{"categories":["内核模块","arch"],"content":"霞诗子のblog","date":"2022-11-04","objectID":"/posts/thinking/%E8%99%9A%E6%8B%9F%E6%91%84%E5%83%8F%E5%A4%B4/","tags":["内核模块","arch"],"title":"ffmpeg+v4l2内核模块-虚拟摄像头","uri":"/posts/thinking/%E8%99%9A%E6%8B%9F%E6%91%84%E5%83%8F%E5%A4%B4/"},{"categories":["内核模块","arch"],"content":"安装依赖以及内核模块 note 这需要安装ffmpeg以及v4l2loopback内核模块: 其中ffmpeg能够将我们想要的视频作为可以安装的网络摄像头源进行流式传输。 v4l2loopback模块允许您创建“虚拟视频设备”。普通v4l2应用程序将像普通设备一样读取这些设备 视频设备，但视频不从捕获卡中读取，而是相反，它是由另一个应用程序生成的。 若官方源无该软件包，则需要自己进行下载并且编译 //安装内核模块，若v4l2loopback-dkms-git安装成功则跳过 git clone https://github.com/umlaeute/v4l2loopback.git ## 编译 make clean make \u0026\u0026 sudo make install ##加载内核依赖关系 sudo depmod -a ## 将用户添加到video用户组 sudo gpasswd -a $USER video ## 添加内核模块，其中devices表示只创建一个环路设备，exclusive_caps为故障排查选项，card_label为设备名称。 sudo modprobe v4l2loopback devices=1 max_buffers=2 exclusive_caps=1 card_label=\"VirtualCam #0\" 若该命令可以正确列出所创建的设备，则内核模块加载完成 ## 判断加载是否完成，记住此摄像头设备，例如为video2 ls -l /sys/devices/virtual/video4linux ## 查看设备属性 v4l2-ctl -d /dev/video0 -l ## 创建新设备 /dev/video7有标签“loopy doopy”的，使用： sudo v4l2loopback-ctl add -n \"loopy doopy\" /dev/video7 ## 删除设备，若提示设备忙碌则需要先卸载设备 sudo v4l2loopback-ctl delete /dev/video7 ","date":"2022-11-04","objectID":"/posts/thinking/%E8%99%9A%E6%8B%9F%E6%91%84%E5%83%8F%E5%A4%B4/:0:1","tags":["内核模块","arch"],"title":"ffmpeg+v4l2内核模块-虚拟摄像头","uri":"/posts/thinking/%E8%99%9A%E6%8B%9F%E6%91%84%E5%83%8F%E5%A4%B4/"},{"categories":["内核模块","arch"],"content":"将视频流链接到虚拟摄像头 在完成以上软件安装以及内核加载之后、准备一份视频、同时测试可用摄像头。 ## 列出所有摄像头设备 ls -l /dev/video* ## 测试可用摄像头，X可以是0,1,2... ffplay /dev/videoX ## 此处的video2是生成的虚拟设备名称 ffmpeg -stream_loop -1 -re -i ./Documents/2022-12-13\\ 20-47-48.mkv -vcodec rawvideo -threads 0 -f v4l2 /dev/video2 note 几个参数的作用以及举例： -re为自适应帧率，-i为指定输入文件路径。 -stream_loop -1：这决定了视频应该循环播放的次数、为其分配负值 -1 让它无限循环、直到我们继续播放close我们的程序。 -vcodec：这指定了视频编解码器，也就是流处理。 rawvideo这个告诉 ffmpeg 使用原始视频解复用器、该多路分配器允许读取原始视频数据。 -threads 要使用的线程数、通常设置为0被认为是最优的。 -f 此标志用于强制输入/输出文件的格式、我们强制输出v4l2格式 ## 使用以下命令删除先前加载的内核模块： sudo modprobe --remove v4l2loopback 注意：若linux内核版本小于2.6.27,则意味着此内核模块在该linux上无法运行和加载，需要另外寻求解决方法。 ","date":"2022-11-04","objectID":"/posts/thinking/%E8%99%9A%E6%8B%9F%E6%91%84%E5%83%8F%E5%A4%B4/:0:2","tags":["内核模块","arch"],"title":"ffmpeg+v4l2内核模块-虚拟摄像头","uri":"/posts/thinking/%E8%99%9A%E6%8B%9F%E6%91%84%E5%83%8F%E5%A4%B4/"},{"categories":["Go","Code"],"content":"霞诗子のblog","date":"2022-07-15","objectID":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/","tags":["Go","Code"],"title":"go并发的三种模式","uri":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["Go","Code"],"content":"并发的三种模式 runner.go 主要为切片放置任务函数 package runner import ( \"errors\" \"os\" \"os/signal\" \"time\" ) type Runner struct { // interrupt 通道报告从操作系统发送的信号 interrupt chan os.Signal //complete通道报告处理任务已经完成 complete chan error //timeout 报告任务超时，注意方向 timeout \u003c-chan time.Time //tasks持有依次执行的任务函数 tasks []func(int) } //任务超时返回 var ErrTimeout = errors.New(\"received timeout\") //任务中断返回 var ErrInterrupt = errors.New(\"received interrupt\") //New返回一个新的准备使用的runner、初始化操作 func New(d time.Duration) *Runner { return \u0026Runner{ interrupt: make(chan os.Signal, 1), complete: make(chan error), timeout: time.After(d), } } //Add函数添加任务到Runner上 func (r *Runner) Add(tasks ...func(int)) { r.tasks = append(r.tasks, tasks...) } //start执行任务，并监视管道 func (r *Runner) Start() error { //接受所有中断信号 signal.Notify(r.interrupt, os.Interrupt) //用不同的goroutine执行不同的任务 go func() { r.complete \u003c- r.run() }() select { //当任务完成的发出的信号 case err := \u003c-r.complete: return err //当任务超时的时发出的信号 case \u003c-r.timeout: return ErrTimeout } } func (r *Runner) run() error { for id, task := range r.tasks { //检测操作系统的中断信号 if r.gotInterrupt() { return ErrInterrupt } //执行已经在队列中的任务 task(id) } return nil } func (r *Runner) gotInterrupt() bool { select { //当中断时间被触发时的信号 case \u003c-r.interrupt: //停止接收后续信号 signal.Stop(r.interrupt) return true //继续正常运行 default: return false } } pool.go 主要有缓冲channel放置任务函数 package pool import ( \"errors\" \"log\" \"io\" \"sync\" ) //管理goroutine的pool type Pool struct{ m sync.Mutex resources chan io.Closer factory func()(io.Closer,error) closed bool } //pool已经关闭 var ErrPoolClosed = errors.New(\"Pool has been closed\") func New(fn func()(io.Closer,error),size uint)(*Pool,error){ if size \u003c= 0{ return nil,errors.New(\"size value too small\") } return \u0026Pool{ factory: fn, resources: make(chan io.Closer,size), },nil } //从池子获取资源 func (p *Pool)Acquire()(io.Closer,error){ select{ //检查是否存在空闲资源 case r,ok := \u003c- p.resources: log.Println(\"Acquire:\",\"Shared Resource\") if !ok { return nil,ErrPoolClosed } return r,nil //因为没有空闲资源，所以提供一个新资源 default: log.Println(\"Acquire:\",\"New Resource\") return p.factory() } } //将最后一个资源放回池子里面 func (p *Pool)Release(r io.Closer){ //保证可靠性 p.m.Lock() defer p.m.Unlock() //如果池子已经被关闭,则销毁资源 if p.closed { r.Close() return } select{ //将资源放入队列 case p.resources \u003c-r: log.Println(\"Releae:\",\"In Queue\") //队列已满，关闭资源 default: log.Println(\"Release:\",\"Closing\") r.Close() } } //让资源池停止工作，并且释放资源 func (p *Pool)Close(){ //保证操作安全性 p.m.Lock() defer p.m.Unlock() //如果pool已经被关闭 if p.closed { return } //关闭池子 p.closed = true //清空管道资源之前要关闭管道，不然会发生死锁 close(p.resources) for r := range p.resources { r.Close() } } work.go 主要为无缓冲放置任务函数 package work import \"sync\" type Worker interface { Task() } type Pool struct { work chan Worker wg sync.WaitGroup } func New(maxGoroutine int) *Pool { p := Pool{ work: make(chan Worker), } p.wg.Add(maxGoroutine) for i := 0; i \u003c maxGoroutine; i++ { go func() { for w := range p.work { w.Task() } p.wg.Done() }() } return \u0026p } func (p *Pool) Run(w Worker) { p.work \u003c- w } func (p *Pool) Shutdown() { close(p.work) p.wg.Wait() } ","date":"2022-07-15","objectID":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/:0:1","tags":["Go","Code"],"title":"go并发的三种模式","uri":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["算法"],"content":"霞诗子のblog","date":"2022-01-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"非对称加密-RSA算法 ","date":"2022-01-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:0","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"概念 加密和解密可以使用不同的规则，只要这两种规则之间存在某种对应关系即可，这样就避免了直接传递密钥。这种新的加密模式被称为\"非对称加密算法\"。 对称加密： 甲方选择某一种加密规则，对信息进行加密； 乙方使用同一种规则，对信息进行解密。 非对称加密： 乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 甲方获取乙方的公钥，然后用它对信息加密。 乙方得到加密后的信息，用私钥解密。 常见的非对称加密算法有RSA算法、ECC椭圆曲线算法等等 ","date":"2022-01-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:1","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"前置知识 RSA算法与欧拉函数存在一定关系，本篇不对欧拉函数进行讨论，仅仅了解计算即可 互质关系： 一个数是质数，另一个数只要不是前者的倍数，两者就构成互质关系，比如3和10。 如果两个数之中，较大的那个数是质数，则两者构成互质关系，比如97和57。 1和任意一个自然数是都是互质关系，比如1和99。 p是大于1的整数，则p和p-1构成互质关系，比如57和56。 p是大于1的奇数，则p和p-2构成互质关系，比如17和15。 欧拉函数计算： 概念：任意给定正整数n，请问在小于等于n的正整数之中，有多少个与n构成互质关系，计算这个值的方法就叫做欧拉函数，以φ(n)表示。例如、在1到7之中，与7形成互质关系的是1、2、3、4、5、6，在1到9之中，与9形成互质关系的是1、2、4、5、7、8。 公式：m^φ(n) ≡ 1 (mod n) 若 p * q = n 且pq也为质数的情况下，则有φ(n) = (p-1) * (q-1)。也即是得出结论：两个质数之积的欧拉函数的值等于两个数的欧拉函数之值的乘积。利用到了互质关系中的第三点，任何数与质数都是互质关系。 模反元素： 模反元素：如果两个正整数a和n互质，那么一定可以找到整数b，使得 ab-1 被n整除，或者说ab被n除的余数是1，b就叫做a的\"模反元素\"。此处的ab即为RSA算法中提到的\"私钥\"与\"公钥\"。公式有：ab≡ 1 (mod n) 举例有：3和11互质，那么3的模反元素就是4，因为3*4-1刚好可以被11整除,所以4和3互为模反元素，又如5和34互质，那么5和7就互为模反元素，也是5*7-1=34 注意互质关系不一定两个数都是质数，具体可以参考5和34,7和12等等。 ","date":"2022-01-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:2","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"RSA加密 加密过程： 第一步：随机生成质数p与q、得出n = p * q 第二步：计算n的欧拉函数值，使用欧拉函数公式即可：φ(n) = (p-1) * (q-1) 第三步：在1与φ(n)之间随机生成整数e，条件是1\u003c e \u003c φ(n)，且e与φ(n) 互质。 第四步：计算e对于φ(n)的模反元素d，带入公式有ed≡ 1 (mod n)，等价于 ed - 1 = kφ(n)、于是，找到模反元素d 第五步：将n和e封装成公钥，n和d封装成私钥。 举例分析：若p = 53、q= 61、则 n = p*q = 3233、φ(n) = (p-1)*(q-1) = 3120、若随即选择e = 17、d = 2753。则私钥对为（3233,2753）、公钥对为（3233,17）。 可靠性分析：p、q、n、e、φ(n)、d是已经出现的数字、这六个数字之中，公钥用到了两个（n和e），其余四个数字都是不公开的。其中最关键的是d，因为n和d组成了私钥，一旦d泄漏，就等于私钥泄漏。那么在（n,e）公开的情况下，有没有可能推导出d,从而得出私钥（n,d）。 推导条件： ed≡1 (mod φ(n))。只有知道e和φ(n)，才能算出d。 φ(n)=(p-1)(q-1)。只有知道p和q，才能算出φ(n)。 n=pq。只有将n因数分解，才能算出p和q。 结论：如果n可以被因数分解，d就可以算出，也就意味着私钥被破解。 “对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法，那么RSA的可靠性就会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA密钥才可能被暴力破解。到2008年为止，世界上还没有任何可靠的攻击RSA算法的方式。只要密钥长度足够长，用RSA加密的信息实际上是不能被解破的。” 解密过程： 加密：m^e ≡ c (mod n)带入上述数字得出65^17 ≡ 2790 (mod 3233)，也即是2790为加密数字，65为真实数字 解密：c^d ≡ m (mod n)带入计算有2790^2753 ≡ 65 (mod 3233),解密得出65为真实数字 至此，“加密–解密\"的整个过程全部完成。 私钥解密的证明： 为什么用私钥解密，一定可以正确地得到m 由解密规则有：c^d ≡ m (mod n)、又由加密规则有：ｍ^e ≡ c (mod n)、则有：c = m^e - kn、将c代入要我们要证明的那个解密规则：(m^e - kn)^d ≡ m (mod n)等同于m^(ed) ≡ m (mod n)推出ed ≡ 1 (mod φ(n))、既有ed = hφ(n)+1、将ed代入ed ≡ 1 (mod φ(n))：m^(hφ(n)+1) ≡ m (mod n) 若mn互质：则有m^φ(n) ≡ 1 (mod n)、与上式连立有：(m^φ(n))^h × m ≡ m (mod n),原式得到证明。 若mn不为互质关系：以 m = kp为例，考虑到这时k与q必然互质，则根据欧拉定理，下面的式子成立：　(kp)^(q-1) ≡ 1 (mod q)、进一步得到:[(kp)^(q-1) ]^h(p-1) × kp ≡ kp (mod q)、既有(kp)ed ≡ kp (mod q)、改写为：(kp)^ed = tq + kp、这时t必然能被p整除，即 t=t’p、因为 m=kp，n=pq，所以m^ed ≡ m (mod n)、得证。 本文参考自：https://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html ","date":"2022-01-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:3","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["go"],"content":"霞诗子のblog","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"gin入门与学习 ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:0","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"静态文件请求 //// 静态文件请求 func main() { r := gin.Default() r.Static(\"/assets\",\"./assets\") r.StaticFS(\"/static\",http.Dir(\"static\")) r.StaticFile(\"/favicon.ico\",\"./favicon.ico\") r.Run() } ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:1","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"路由方法 func main() { r := gin.Default() //定义GET方法 r.GET(\"/get\",func (c *gin.Context) { c.String(200,\"get\") }) // 定义POST方法 r.POST(\"/post\",func (c *gin.Context) { c.String(200,\"post\") }) //方法自定义名字 r.Handle(\"DEL\",\"/delete\",func (c *gin.Context) { c.String(200,\"delete\") }) r.Run() } ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:2","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"路由请求 //路由请求 func main() { r := gin.Default() //注意传入参数这里，传到了param中 r.GET(\"/:names/:id\", func(c *gin.Context) { c.JSON(200, gin.H{ //取出json文件中的对应tag \"name\": c.Param(\"names\"), \"id\": c.Param(\"id\"), }) }) r.Run() } ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:3","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"验证请求参数 *action //验证请求参数 *action func main() { r := gin.Default() // 所有user前缀的都会给预定的函数执行 r.GET(\"/user/*action\", func(c *gin.Context) { c.String(200, \"hello!i am helen\") }) r.Run() } input: curl http://127.0.0.1:8080/user/757 output: hello!i am helen% input: curl http://127.0.0.1:8080/user/dasdas output: hello!i am helen% ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:4","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"处理指定参数 //处理指定参数 func main() { r := gin.Default() r.GET(\"/test\", func(c *gin.Context) { //处理传入路由的指定参数 firstname := c.Query(\"firstname\") //处理指定和非指定的参数 lastname := c.DefaultQuery(\"lastname\", \"lastname_defalt\") c.String(http.StatusOK, \"%s %s\", firstname, lastname) }) r.Run(\":8080\") } input: curl http://127.0.0.1:8080/test?firstname=lihua\u0026\u0026lastname=wang output: lihua wang% ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:5","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"格式转换 func main() { r := gin.Default() r.POST(\"/test\", func(c *gin.Context) { //以json格式才有效， body, err := ioutil.ReadAll(c.Request.Body) if err != nil { c.String(http.StatusBadRequest, err.Error()) c.Abort() } //格式jsonn转换为普通格式 c.Request.Body = ioutil.NopCloser(bytes.NewBuffer(body)) firstname := c.PostForm(\"firtname\") lastname := c.DefaultPostForm(\"lastname\", \"lastname_defalt\") c.String(http.StatusOK, \"%s %s %s\\\\n\", firstname, lastname, string(body)) }) r.Run(\":8080\") } input: curl -X POST http://127.0.0.1:8080/test -d firtname=lihua\u0026\u0026lastname=wang’ output: lihua wang firtname=lihua\u0026\u0026lastname=wang ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:6","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"ShouldBind操作 //ShouldBind操作,参数绑定结构体 type Person struct { Name string `form:\"name\"` Address string `form:\"address\"` Birthday string `form:\"birthday\"` } func main() { r := gin.Default() r.GET(\"/testing\", testing) r.POST(\"/testing\", testing) r.Run() } func testing(c *gin.Context) { var person Person //根据请求的content-type类型来做不同操作 if err := c.ShouldBind(\u0026person); err == nil { c.String(200, \"%v\", person) } else { c.String(300, \"person bind error:%v\", err) } } input: curl -H Content-Type:application/json -X POST http://127.0.0.1:8080/testing -d {name:helen,address:45,birthday:0244}’ output: {helen 45 0244}% input: curl -X GET http://127.0.0.1:8080/testing?name=wang\u0026\u0026address=415\u0026\u0026birthday=2022-01-55 output: {wang 415 2022-01-55}% ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:7","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"参数验证 //参数验证 type Person struct { Name string `form:\"name\" binding:\"required\"` Age string `form:\"age\" binding:\"required\"` Add string `form:\"add\" binding:\"required\"` } func main() { var p Person r := gin.Default() r.GET(\"/testing\", func(c *gin.Context) { if err := c.ShouldBind(\u0026p); err != nil { c.String(500, \"%v\", err) return } c.String(200, \"%v\", p) }) r.POST(\"/testing\", func(c *gin.Context) { if err := c.ShouldBind(\u0026p); err != nil { c.String(500, \"%v\", err) return } c.String(200, \"%v\", p) }) r.Run() } input: curl -X GET http://127.0.0.1:8080/testing?name=wan\u0026\u0026add=415\u0026\u0026age=45 output: {wan 45 415}% input: curl -H Content-Type:application/json -X POST http://127.0.0.1:8080/testing -d {name:helen,add:sda,age:44}’ output: {helen 44 sda}% ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:8","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go"],"content":"自定义验证规则 import ( \"net/http\" \"time\" \"github.com/gin-gonic/gin\" \"github.com/go-playground/validator/v10\" ) // type Booking struct { // CheckIn time.Time `form:\"check_in\" validate:\"required\" time_format:\"2006-01-02\"` // CheckOut time.Time `form:\"check_out\" validate:\"required\" time_format:\"2006-01-02\"` // } type Booking struct { CheckIn time.Time `form:\"check_in\" binding:\"required\" time_format:\"2006-01-02\"` CheckOut time.Time `form:\"check_out\" binding:\"required\" time_format:\"2006-01-02\"` } //自定义验证规则 func Timing(fl validator.FieldLevel) bool { if date, ok := fl.Field().Interface().(time.Time); ok { today := time.Now() if today.After(date) { return false } } return true } func main() { // //路由实例化 r := gin.Default() // //校验器实例化 v := validator.New() // //注册自定义标签,注册验证规则 v.RegisterValidation(\"timing\", Timing) r.GET(\"/time\", func(c *gin.Context) { var b Booking //处理校对传入参数 if err := c.ShouldBind(\u0026b); err != nil { c.JSON(http.StatusInternalServerError, gin.H{ \"error\": err.Error(), }) c.Abort() return } // //校对结构体 if err := v.Struct(b); err != nil { c.JSON(http.StatusInternalServerError, gin.H{ \"error\": err.Error(), }) c.Abort() return } c.JSON(http.StatusOK, gin.H{ \"message\": \"ok!\", \"booking\": \"bookname\"}) }) r.Run() } input: curl -X GET http://127.0.0.1:8080/time?check_in=2022-01-11\u0026check_out=2022-04-06 output: {booking:bookname,message:ok!}% ","date":"2021-12-04","objectID":"/posts/coding/gin%E5%85%A5%E9%97%A8/:1:9","tags":["go","gin"],"title":"gin入门","uri":"/posts/coding/gin%E5%85%A5%E9%97%A8/"},{"categories":["go","标准库"],"content":"霞诗子のblog","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":" fmt 包实现了格式化I/O函数 //常见的格式控制符 type user struct { name string } func main() { u := user{\"tang\"} //占位符 fmt.Printf(\"% + v\\\\n\", u) //格式化输出结构 fmt.Printf(\"%#v\\\\n\", u) //输出值的 Go 语言表示方法 fmt.Printf(\"%T\\\\n\", u) //输出值的类型的 Go 语言表示 //布尔占位符 fmt.Printf(\"%t\\\\n\", true) //输出值的 true 或 false //整数占位符 fmt.Printf(\"%b\\\\n\", 1024) //二进制表示 fmt.Printf(\"%c\\\\n\", 11111111) //数值对应的 Unicode 编码字符 fmt.Printf(\"%d\\\\n\", 10) //十进制表示 fmt.Printf(\"%o\\\\n\", 8) //八进制表示 fmt.Printf(\"%q\\\\n\", 22) //转化为十六进制并附上单引号 fmt.Printf(\"%x\\\\n\", 1223) //十六进制表示，用a-f表示 fmt.Printf(\"%X\\\\n\", 1223) //十六进制表示，用A-F表示 fmt.Printf(\"%U\\\\n\", 1233) //Unicode表示 //浮点数和复数的组成部分（实部和虚部） fmt.Printf(\"%b\\\\n\", 34) //无小数部分，两位指数的科学计数法6946802425218990p-49 fmt.Printf(\"%e\\\\n\", 345) //科学计数法，e表示 fmt.Printf(\"%E\\\\n\", 34455) //科学计数法，E表示 fmt.Printf(\"%f\\\\n\", 3456) //有小数部分，无指数部分 fmt.Printf(\"%g\\\\n\", 3456) //根据实际情况采用%e或%f输出 fmt.Printf(\"%G\\\\n\", 3456) //根据实际情况采用%E或%f输出 //字符串与字节切片 fmt.Printf(\"%s\\\\n\", \"wqdew\") //直接输出字符串或者[]byte fmt.Printf(\"%q\\\\n\", \"dedede\") //双引号括起来的字符串 fmt.Printf(\"%x\\\\n\", \"abczxc\") //每个字节用两字节十六进制表示，a-f表示 fmt.Printf(\"%X\\\\n\", \"asdzxc\") //每个字节用两字节十六进制表示，A-F表示 //指针 fmt.Printf(\"%p\\\\n\", 0x123) //0x开头的十六进制数表示 } ","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/:0:0","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":"Stringer 接口 Stringer接口的定义如下： type Stringer interface { String() string } 一个类型只要有 String() string 方法，我们就说它实现了 Stringer 接口 type Person struct { Name string Age int Sex int } p := \u0026Person{\"polaris\", 28, 0} fmt.Println(p)//\u0026{polaris 28 0} //接下来，为Person增加String方法。 func (this *Person) String() string { buffer := bytes.NewBufferString(\"This is \") buffer.WriteString(this.Name + \", \") if this.Sex == 0 { buffer.WriteString(\"He \") } else { buffer.WriteString(\"She \") } buffer.WriteString(\"is \") buffer.WriteString(strconv.Itoa(this.Age)) buffer.WriteString(\" years old.\") return buffer.String() } fmt.Println(p)// This is polaris, He is 28 years old ","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/:0:1","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":"Formatter 接口 Formatter 接口由带有定制的格式化器的值所实现。 Format 的实现可调用 Sprintf 或 Fprintf(f) 等函数来生成其输出。 func (this *Person) Format(f fmt.State, c rune) { if c == 'L' { f.Write([]byte(this.String())) f.Write([]byte(\" Person has three fields.\")) } else { // 没有此句，会导致 fmt.Printf(\"%s\", p) 啥也不输出 f.Write([]byte(fmt.Sprintln(this.String()))) } } 注意 fmt.State 是一个接口。由于 Format 方法是被 fmt 包调用的，它内部会实例化好一个 fmt.State 接口的实例，我们不需要关心该接口； 可以实现自定义占位符，同时 fmt 包中和类型相对应的预定义占位符会无效。因此例子中 Format 的实现加上了 else 子句； 实现了 Formatter 接口，相应的 Stringer 接口不起作用。但实现了 Formatter 接口的类型应该实现 Stringer 接口，这样方便在 Format 方法中调用 String() 方法。就像本例的做法； Format 方法的第二个参数是占位符中%后的字母（有精度和宽度会被忽略，只保留字母）； ","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/:0:2","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":"bufio — 缓存IO ","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/:1:0","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":"Reader 类型和方法 type Reader struct { buf []byte // 缓存 rd io.Reader // 底层的io.Reader // r:从buf中读走的字节（偏移）；w:buf中填充内容的偏移； // w - r 是buf中可被读的长度（缓存数据的大小），也是Buffered()方法的返回值 r, w int err error // 读过程中遇到的错误 lastByte int // 最后一次读到的字节（ReadByte/UnreadByte) lastRuneSize int // 最后一次读到的Rune的大小 (ReadRune/UnreadRune) } ","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/:1:1","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":"ReadSlice、ReadBytes、ReadString 和 ReadLine 方法 func (b *Reader) ReadSlice(delim byte) (line []byte, err error) ","date":"2021-05-03","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/:1:2","tags":["go"],"title":"输入输出-fmt标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAfmt%E6%A0%87%E5%87%86/"},{"categories":["go","标准库"],"content":"霞诗子のblog","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ioutil — 方便的IO操作函数集 ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:0","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"NopCloser函数 tips 有时候我们需要传递一个 io.ReadCloser 的实例，而我们现在有一个 io.Reader 的实例，比如：strings.Reader ，这个时候 NopCloser 就派上用场了。它包装一个io.Reader，返回一个 io.ReadCloser ，而相应的 Close 方法啥也不做，只是返回 nil。 比如，在标准库 net/http 包中的 NewRequest，接收一个 io.Reader 的 body，而实际上，Request 的 Body 的类型是 io.ReadCloser，因此，代码内部进行了判断，如果传递的 io.Reader 也实现了 io.ReadCloser 接口，则转换，否则通过ioutil.NopCloser 包装转换一下。相关代码如下： ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:1","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReadAll 函数 Go 提供了 ReadAll 这个函数，用来从io.Reader 中一次读取所有数据。 func ReadAll(r io.Reader) ([]byte, error) 它是通过 bytes.Buffer 中的 ReadFrom 来实现读取所有数据的。该函数成功调用后会返回 err == nil 而不是 err == EOF。(成功读取完毕应该为 err == io.EOF，这里返回 nil 由于该函数成功期望 err == io.EOF，符合无错误不处理的理念) ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:2","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReadDir 函数 ioutil 中提供了一个方便的函数：ReadDir，它读取目录并返回排好序的文件和子目录名（ []os.FileInfo ）。 func ReadDir(dirname string)([]fs.FileInfo, error) func main() { dir := os.Args[1] listAll(dir,0) } func listAll(path string, curHier int){ fileInfos, err := ioutil.ReadDir(path) if err != nil{fmt.Println(err); return} for _, info := range fileInfos{ if info.IsDir(){ for tmpHier := curHier; tmpHier \u003e 0; tmpHier--{ fmt.Printf(\"|\\\\t\") } fmt.Println(info.Name(),\"\\\\\\\\\") listAll(path + \"/\" + info.Name(),curHier + 1) }else{ for tmpHier := curHier; tmpHier \u003e 0; tmpHier--{ fmt.Printf(\"|\\\\t\") } fmt.Println(info.Name()) } } } ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:3","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReadFile 和 WriteFile 函数 ReadFile 读取整个文件的内容，在上一节我们自己实现了一个函数读取文件整个内容，由于这种需求很常见，因此 Go 提供了 ReadFile 函数，方便使用。ReadFile 的实现和ReadAll 类似，不过，ReadFile 会先判断文件的大小，给 bytes.Buffer 一个预定义容量，避免额外分配内存。 ReadFile 函数的签名如下: func ReadFile(filename string) ([]byte, error) WriteFile 函数的签名如下： func WriteFile(filename string, data []byte, perm os.FileMode) error WriteFile 将data写入filename文件中，当文件不存在时会根据perm指定的权限进行创建一个,文件存在时会先清空文件内容。对于 perm 参数，我们一般可以指定为：0666，具体含义 os 包中讲解。 ReadFile 源码中先获取了文件的大小，当大小 \u003c 1e9 时，才会用到文件的大小。按源码中注释的说法是 FileInfo 不会很精确地得到文件大小。 ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:4","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"TempDir 和 TempFile 函数 操作系统中一般都会提供临时目录，比如 linux 下的 /tmp 目录（通过 os.TempDir() 可以获取到)。有时候，我们自己需要创建临时目录，比如 Go 工具链源码中（src/cmd/go/build.go），通过 TempDir 创建一个临时目录，用于存放编译过程的临时文件： //第一个参数如果为空，表明在系统默认的临时目录（ os.TempDir ）中创建临时目录；第二个参数指定临时目录名的前缀，该函数返回临时目录的路径。 b.work, err = ioutil.TempDir(\"\", \"go-build\") //相应的，TempFile 用于创建临时文件。如 gofmt 命令的源码中创建临时文件： f1, err := ioutil.TempFile(\"\", \"gofmt\") //如删除临时文件： defer func() { f.Close() os.Remove(f.Name()) }() ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:5","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"Discard 变量 func (devNull) Write(p []byte) (int, error) { return len(p), nil } io包对外提供了一个Discard，这个Discard是一个Writer，但是内部实际上将数据丢弃了。这个工具以一个变量的方式对外暴露，没有以函数或者类型的方式进行暴露，对外提供了Write，WriteString和ReadFrom三个方法。 ","date":"2021-05-02","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/:1:6","tags":["go"],"title":"输入输出-ioutil标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAioutil%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"霞诗子のblog","date":"2021-05-01","objectID":"/posts/coding/go~io.reader/","tags":["go"],"title":"io.Reader接口示例","uri":"/posts/coding/go~io.reader/"},{"categories":["go","标准库"],"content":"io.Reader 接口示例 // io.Reader 接口示例 package main import ( \"fmt\" \"io\" \"os\" \"strings\" \"util\" ) func ReaderExample() { FOREND: for { readerMenu() var ch string fmt.Scanln(\u0026ch) var ( data []byte err error ) switch strings.ToLower(ch) { case \"1\": fmt.Println(\"请输入不多于9个字符，以回车结束：\") data, err = ReadFrom(os.Stdin, 11) case \"2\": file, err := os.Open(util.GetProjectRoot() + \"文件路径\") if err != nil { fmt.Println(\"打开文件 01.txt 错误:\", err) continue } //读取9个字符 data, err = ReadFrom(file, 9) file.Close() case \"3\": data, err = ReadFrom(strings.NewReader(\"from string\"), 12) case \"4\": fmt.Println(\"暂未实现！\") case \"b\": fmt.Println(\"返回上级菜单！\") break FOREND case \"q\": fmt.Println(\"程序退出！\") os.Exit(0) default: fmt.Println(\"输入错误！\") continue } if err != nil { fmt.Println(\"数据读取失败，可以试试从其他输入源读取！\") } else { fmt.Printf(\"读取到的数据是：%s\\n\", data) } } } func ReadFrom(reader io.Reader, num int) ([]byte, error) { p := make([]byte, num) n, err := reader.Read(p) if n \u003e 0 { return p[:n], nil } return p, err } func readerMenu() { fmt.Println(\"\") fmt.Println(\"*******从不同来源读取数据*********\") fmt.Println(\"*******请选择数据源，请输入：*********\") fmt.Println(\"1 表示 标准输入\") fmt.Println(\"2 表示 普通文件\") fmt.Println(\"3 表示 从字符串\") fmt.Println(\"4 表示 从网络\") fmt.Println(\"b 返回上级菜单\") fmt.Println(\"q 退出\") fmt.Println(\"***********************************\") } ","date":"2021-05-01","objectID":"/posts/coding/go~io.reader/:1:0","tags":["go"],"title":"io.Reader接口示例","uri":"/posts/coding/go~io.reader/"},{"categories":["go","标准库"],"content":"霞诗子のblog","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"输入输出 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:0","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"基本的 IO 接口 Reader 接口: type Reader interface{ Read(p []byte)(n int, err error) } Read 将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 \u003c= n \u003c= len(p)） 以及任何遇到的错误。即使 Read 返回的 n \u003c len(p)，它也会在调用过程中占用 len(p) 个字节作为暂存空间。若可读取的数据不到 len(p) 个字节，Read 会返回可用数据，而不是等待更多数据。 example: func ReadFrom(reader io.Reader,num int)([]byte,err){ p := make([]byte,num) n,err := reader.Read(p) if n\u003e0{ return p[:n],nil } return p,err } ReadFrom 函数将 io.Reader 作为参数，也就是说，ReadFrom 可以从任意的地方读取数据，只要来源实现了 io.Reader 接口。比如，我们可以从标准输入、文件、字符串等读取数据，示例代码如下： // 从标准输入读取 data, err = ReadFrom(os.Stdin, 11) // 从普通文件读取，其中 file 是 os.File 的实例 data, err = ReadFrom(file, 9) // 从字符串读取 data, err = ReadFrom(strings.NewReader(\"from string\"), 12) ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:1","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"Writer 接口 Writer 接口的定义如下： type Wirter interface{ Wirte(p []byte)(n int,err error) } ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:2","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"实现了 io.Reader 接口或 io.Writer 接口的类型 note os.File 同时实现了 io.Reader 和 io.Writer strings.Reader 实现了 io.Reader bufio.Reader/Writer 分别实现了 io.Reader 和 io.Writer bytes.Buffer 同时实现了 io.Reader 和 io.Writer bytes.Reader 实现了 io.Reader compress/gzip.Reader/Writer 分别实现了 io.Reader 和 io.Writer crypto/cipher.StreamReader/StreamWriter 分别实现了 io.Reader 和 io.Writer crypto/tls.Conn 同时实现了 io.Reader 和 io.Writer encoding/csv.Reader/Writer 分别实现了 io.Reader 和 io.Writer mime/multipart.Part 实现了 io.Reader net/conn 分别实现了 io.Reader 和 io.Writer(Conn接口定义了Read/Write) 实现了 Reader 的类型：LimitedReader、PipeReader、SectionReader 实现了 Writer 的类型：PipeWriter 以上类型中，常用的类型有： os.File、strings.Reader、bufio.Reader/Writer、bytes.Buffer、bytes.Reader ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:3","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReaderAt 和 WriterAt 接口 type ReaderAt interface { ReadAt(p []byte, off int64) (n int, err error) } ReadAt 从基本输入源的偏移量off处开始，将 len(p)个字节读取到 p中。它返回读取的字节数 n（0 \u003c= n \u003c= len(p)）以及任何遇到的错误。 当 ReadAt 返回的 n \u003c len(p) 时，它就会返回一个非nil的错误来解释 为什么没有返回更多的字节。在这一点上，ReadAt 比 Read 更严格。 即使 ReadAt 返回的 n \u003c len(p)，它也会在调用过程中使用 p 的全部作为暂存空间。若可读取的数据不到 len(p) 字节，ReadAt 就会阻塞,直到所有数据都可用或一个错误发生。 在这一点上 ReadAt 不同于 Read。 可见，ReaderAt 接口使得可以从指定偏移量处开始读取数据。 reader := strings.NewReader(\"Go语言\") p := make([]byte, 6) n, err := reader.ReadAt(p, 2) if err != nil { panic(err) } fmt.Printf(\"%s, %d\\n\", p, n)//语言, 6 WriterAt 接口的定义如下： type WriterAt interface { WriteAt(p []byte, off int64) (n int, err error) } WriteAt 从 p 中将 len(p) 个字节写入到偏移量 off 处的基本数据流中。它返回从 p 中被写入的字节数 n（0 \u003c= n \u003c= len(p)）以及任何遇到的引起写入提前停止的错误。若 WriteAt 返回的 n \u003c len(p)，它就必须返回一个 非nil 的错误。若 WriteAt 携带一个偏移量写入到目标中，WriteAt 应当既不影响偏移量也不被它所影响。若被写区域没有重叠，可对相同的目标并行执行 WriteAt 调用。 file, err := os.Create(\"writeAt.txt\") if err != nil { panic(err) } defer file.Close() file.WriteString(\"Golang练习作品——这里是多余的\") n, err := file.WriteAt([]byte(\"Go\"), 24)//偏移24 if err != nil { panic(err) } fmt.Println(n)//Golang练习作品-Go ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:4","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReaderFrom 和 WriterTo 接口 ReaderFrom 的定义如下： type ReaderFrom interface { ReadFrom(r Reader) (n int64, err error) } ReadFrom 方法不会返回 err == EOF。 ReadFrom 从 r 中读取数据，直到 EOF 或发生错误。其返回值 n 为读取的字节数。除 io.EOF 之外，在读取过程中遇到的任何错误也将被返回。如果 ReaderFrom 可用，Copy 函数就会使用它。 file, err := os.Open(\"writeAt.txt\") if err != nil { panic(err) } defer file.Close() writer := bufio.NewWriter(os.Stdout) writer.ReadFrom(file) writer.Flush() WriterTo的定义如下： type WriterTo interface { WriteTo(w Writer) (n int64, err error) } WriteTo 将数据写入 w 中，直到没有数据可写或发生错误。其返回值 n 为写入的字节数。 在写入过程中遇到的任何错误也将被返回。 io.ReaderFrom 和 io.WriterTo,一次性从某个地方读或写到某个地方去。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:5","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"Seeker 接口 接口定义如下： type Seeker interface { Seek(offset int64, whence int) (ret int64, err error) } reader := strings.NewReader(\"Go语言练习\") reader.Seek(-4, io.SeekEnd)//末尾开始 r, _, _ := reader.ReadRune() fmt.Printf(\"%c\\n\", r) whence 的值，在 io 包中定义了相应的常量，应该使用这些常量 const ( SeekStart = 0 // seek relative to the origin of the file SeekCurrent = 1 // seek relative to the current offset SeekEnd = 2 // seek relative to the end ) ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:6","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"Closer接口 接口定义如下： type Closer interface { Close() error } 该接口比较简单，只有一个 Close() 方法，用于关闭数据流。文件 (os.File)、归档（压缩包）、数据库连接、Socket 等需要手动关闭的资源都实现了 Closer 接口。 file, err := os.Open(\"studygolang.txt\") defer file.Close() if err != nil { ... } 当文件 studygolang.txt 不存在或找不到时，file.Close() 会 panic，因为 file 是 nil。因此，应该将 defer file.Close() 放在错误检查之后。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:7","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ByteReader 和 ByteWriter 接口定义如下： type ByteReader interface { ReadByte() (c byte, err error) } type ByteWriter interface { WriteByte(c byte) error } 读或写一个字节,这两个接口在二进制数据或归档压缩时用的比较多。 note bufio.Reader/Writer 分别实现了io.ByteReader 和 io.ByteWriter bytes.Buffer 同时实现了 io.ByteReader 和 io.ByteWriter bytes.Reader 实现了 io.ByteReader strings.Reader 实现了 io.ByteReader var ch byte fmt.Scanf(\"%c\\n\", \u0026ch) buffer := new(bytes.Buffer) err := buffer.WriteByte(ch) if err == nil { fmt.Println(\"写入一个字节成功！准备读取该字节……\") newCh, _ := buffer.ReadByte() fmt.Printf(\"读取的字节：%c\\n\", newCh) } else { fmt.Println(\"写入错误\") } ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:8","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ByteScanner、RuneReader 和 RuneScanner 接口定义如下： type ByteScanner interface { ByteReader //UnreadByte 方法的意思是：将上一次 ReadByte 的字节还原,且不能连续调用 UnreadByte。 UnreadByte() error } //读取一个 UTF-8 字符。UTF-8 是一种变长编码规则，从 1 到 4 个字节不等 //比如一个字母占一个字节，中文每个字符占用 3 个字节。 //ReadRune 每次读出的是一个完整的编码字符，比如读汉字，每次就会读出一个汉字。 type RuneReader interface { ReadRune() (r rune, size int, err error) } type RuneScanner interface { RuneReader UnreadRune() error } ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:9","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReadCloser、ReadSeeker、ReadWriteCloser、ReadWriteSeeker、ReadWriter、WriteCloser 和 WriteSeeker 接口 这些接口是上面介绍的接口的两个或三个组合而成的新接口。例如 ReadWriter 接口： //这是 Reader 接口和 Writer 接口的简单组合（内嵌）。 type ReadWriter interface { Reader Writer } ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:10","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"SectionReader 类型 该类型读取数据流中部分数据、结构定义如下： type SectionReader struct { r ReaderAt // 该类型最终的 Read/ReadAt 最终都是通过 r 的 ReadAt 实现,内嵌了 ReaderAt 接口 base int64 // NewSectionReader 会将 base 设置为 off off int64 // 从 r 中的 off 偏移处开始读取数据 limit int64 // limit - off = SectionReader 流的长度 } ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:11","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"LimitedReader 类型 LimitedReader 结构定义如下： type LimitedReader struct { R Reader // underlying reader，最终的读取操作通过 R.Read 完成 N int64 // max bytes remaining } 文档说明如下： 从 R 读取但将返回的数据量限制为 N 字节。每调用一次 Read 都将更新 N 来反应新的剩余数量。 也就是说，最多只能返回 N 字节数据。 content := \"This Is LimitReader Example\" reader := strings.NewReader(content) limitReader := \u0026io.LimitedReader{R: reader, N: 8} for limitReader.N \u003e 0 { tmp := make([]byte, 2)//2 limitReader.Read(tmp)//写进去数据？ fmt.Printf(\"%s\", tmp)//This Is } ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:12","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"PipeReader 和 PipeWriter 类型 它实现了 io.Reader 和 io.Closer 接口。结构定义如下： type PipeReader struct { p *pipe } 关于 PipeReader.Read 方法的说明：从管道中读取数据。该方法会堵塞，直到管道写入端开始写入数据或写入端被关闭。如果写入端关闭时带有 error（即调用 CloseWithError 关闭），该Read返回的 err 就是写入端传递的error；否则 err 为 EOF。 PipeWriter（一个没有任何导出字段的 struct）是管道的写入端。它实现了 io.Writer 和 io.Closer 接口。结构定义如下： type PipeReader struct { p *pipe } example func main() { pipeReader, pipeWriter := io.Pipe() go PipeWrite(pipeWriter) go PipeRead(pipeReader) time.Sleep(30 * time.Second) } func PipeWrite(writer *io.PipeWriter){ data := []byte(\"Go语言\") for i := 0; i \u003c 3; i++{ n, err := writer.Write(data) if err != nil{ fmt.Println(err) return } fmt.Printf(\"写入字节 %d\\n\",n) } writer.CloseWithError(errors.New(\"写入段已关闭\")) } func PipeRead(reader *io.PipeReader){ buf := make([]byte, 128) for{ fmt.Println(\"接口端开始阻塞5秒钟...\") time.Sleep(5 * time.Second) fmt.Println(\"接收端开始接受\") n, err := reader.Read(buf) if err != nil{ fmt.Println(err) return } fmt.Printf(\"收到字节: %d\\n buf内容: %s\\n\",n,buf) } } io.Pipe() 用于创建一个同步的内存管道 (synchronous in-memory pipe) func Pipe() (*PipeReader, *PipeWriter) note 它将 io.Reader 连接到 io.Writer。一端的读取匹配另一端的写入，直接在这两端之间复制数据；它没有内部缓存。它对于并行调用 Read 和 Write 以及其它函数或 Close 来说都是安全的。一旦等待的 I/O 结束，Close 就会完成。并行调用 Read 或并行调用 Write 也同样安全：同种类的调用将按顺序进行控制。 正因为是同步的，因此不能在一个 goroutine 中进行读和写。 另外，对于管道的 close 方法（非 CloseWithError 时），err 会被置为 EOF。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:13","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"Copy 和 CopyN 函数 func Copy(dst Writer, src Reader) (written int64, err error) note Copy 将 src 复制到 dst，直到在 src 上到达 EOF 或发生错误。它返回复制的字节数，如果有错误的话，还会返回在复制时遇到的第一个错误。 成功的 Copy 返回 err == nil，而非 err == EOF。由于 Copy 被定义为从 src 读取直到 EOF 为止，因此它不会将来自 Read 的 EOF 当做错误来报告 若 dst 实现了 ReaderFrom 接口，其复制操作可通过调用 dst.ReadFrom(src) 实现。此外，若 src 实现了 WriterTo 接口，其复制操作可通过调用 src.WriteTo(dst) 实现。 package main import ( \"fmt\" \"io\" \"os\" ) func main() { io.Copy(os.Stdout, os.Stdin) fmt.Println(\"Got EOF -- bye\") } func CopyN(dst Writer, src Reader, n int64) (written int64, err error) CopyN 将 n 个字节(或到一个error)从 src 复制到 dst。 它返回复制的字节数以及在复制时遇到的最早的错误。当且仅当err == nil时,written == n 。 若 dst 实现了 ReaderFrom 接口，复制操作也就会使用它来实现。 io.CopyN(os.Stdout, strings.NewReader(\"Go语言中文网\"), 8)//汉字是2～3bytes ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:14","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"ReadAtLeast 和 ReadFull 函数 ReadAtLeast 函数的签名： func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) 官方文档： ReadAtLeast 将 r 读取到 buf 中，直到读了最少 min 个字节为止。它返回复制的字节数，如果读取的字节较少，还会返回一个错误。若没有读取到字节，错误就只是 EOF。如果一个 EOF 发生在读取了少于 min 个字节之后，ReadAtLeast 就会返回 ErrUnexpectedEOF。若 min 大于 buf 的长度，ReadAtLeast 就会返回 ErrShortBuffer。对于返回值，当且仅当 err == nil 时，才有 n \u003e= min。 ReadFull 函数的签名： func ReadFull(r Reader, buf []byte) (n int, err error) 官方文档： ReadFull 精确地从 r 中将 len(buf) 个字节读取到 buf 中。它返回复制的字节数，如果读取的字节较少，还会返回一个错误。若没有读取到字节，错误就只是 EOF。如果一个 EOF 发生在读取了一些但不是所有的字节后，ReadFull 就会返回 ErrUnexpectedEOF。对于返回值，当且仅当 err == nil 时，才有 n == len(buf)。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:15","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"WriteString 函数 func WriteString(w Writer, s string) (n int, err error) 函数文档： WriteString 将s的内容写入w中，当 w 实现了 WriteString 方法时，会直接调用该方法，否则执行 w.Write([]byte(s))。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:16","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"MultiReader 和 MultiWriter 函数 func MultiReader(readers ...Reader) Reader func MultiWriter(writers ...Writer) Writer 它们接收多个 Reader 或 Writer，返回一个 Reader 或 Writer。我们可以猜想到这两个函数就是操作多个 Reader 或 Writer 就像操作一个。 事实上，在 io 包中定义了两个非导出类型：mutilReader 和 multiWriter，它们分别实现了 io.Reader 和 io.Writer 接口。类型定义为： type multiReader struct { readers []Reader } type multiWriter struct { writers []Writer } Read 方法获取到的是 slice 中第一个元素的内容……也就是说，MultiReader 只是逻辑上将多个 Reader 组合起来，并不能通过调用一次 Read 方法获取所有 Reader 的内容。在所有的 Reader 内容都被读完后，Reader 会返回 EOF。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:17","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["go","标准库"],"content":"TeeReader函数 func TeeReader(r Reader, w Writer) Reader TeeReader 返回一个 Reader，它将从 r 中读到的数据写入 w 中。所有经由它处理的从 r 的读取都匹配于对应的对 w 的写入。它没有内部缓存，即写入必须在读取完成前完成。任何在写入时遇到的错误都将作为读取错误返回。 ","date":"2021-05-01","objectID":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/:1:18","tags":["go"],"title":"输入输出-go标准库","uri":"/posts/coding/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BAgo%E6%A0%87%E5%87%86%E5%BA%93/"},{"categories":["操作系统"],"content":"霞诗子","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"死锁避免 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:1:0","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"资源轨迹图 我们看到一个处理两个进程和两种资源（打印机和绘图仪）的模型。横轴表示进程A执行的指令，纵轴表示进程B执行的指令。进程A在I1 处请求一台打印机，在I3 处释放，在I2 处请求一台绘图仪，在I4 处释放。进程B在I5 到I7 之间需要绘图仪，在I6 到I8 之间需要打印机。 如果系统一旦进入由I1 、I2 和I5 、I6 组成的矩形区域，那么最后一定会到达I2 和I6 的交叉点，这时就产生死锁。在该点处，A请求绘图仪，B请求打印机，而且这两种资源均已被分配。这整个矩形区域都是不安全的，因此决不能进入这个区域。在点t处惟一的办法是运行进程A直到I4 ，过了I4 后，可以按任何路线前进，直到终点u。 需要注意的是，在点t进程B请求资源。系统必须决定是否分配。如果系统把资源分配给B，系统进入不安全区域，最终形成死锁。要避免死锁，应该将B挂起，直到A请求并释放绘图仪。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:1:1","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"安全状态和不安全状态 在任何时刻，当前状态包括了E、A、C和R。如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 值得注意的是，不安全状态并不是死锁。实际上，甚至有一个进程能够完成。而且，在A请求其他资源实例前，A可能先释放一个资源实例，这就可以让C先完成，从而避免了死锁。因而，安全状态和不安全状态的区别是：从安全状态出发，系统能够保证所有进程都能完成；而从不安全状态出发，就没有这样的保证。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:1:2","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"单个资源的银行家算法 银行家算法就是对每一个请求进行检查，检查如果满足这一请求是否会达到安全状态。若是，那么就满足该请求；若否，那么就推迟对这一请求的满足。为了看状态是否安全，银行家看他是否有足够的资源满足某一个客户。如果可以，那么这笔投资认为是能够收回的，并且接着检查最接近最大限额的一个客户，以此类推。如果所有投资最终都被收回，那么该状态是安全的，最初的请求可以批准。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:1:3","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"多个资源的银行家算法 检查一个状态是否安全的算法如下 查找右边矩阵中是否有一行，其没有被满足的资源数均小于或等于A。如果不存在这样的行，那么系统将会死锁，因为任何进程都无法运行结束（假定进程会一直占有资源直到它们终止为止）。 假若找到这样一行，那么可以假设它获得所需的资源并运行结束，将该进程标记为终止，并将其资源加到向量A上。 重复以上两步，或者直到所有的进程都标记为终止，其初始状态是安全的；或者所有进程的资源需求都得不到满足，此时就是发生了死锁。 如果在第1步中同时有若干进程均符合条件，那么不管挑选哪一个运行都没有关系，因为可用资源或者会增多，或者至少保持不变。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:1:4","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"死锁预防 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:0","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"破坏互斥条件 先考虑破坏互斥使用条件。如果资源不被一个进程所独占，那么死锁肯定不会产生。 通过采用假脱机打印机（spooling printer）技术可以允许若干个进程同时产生输出。该模型中惟一真正请求使用物理打印机的进程是打印机守护进程，由于守护进程决不会请求别的资源，所以不会因打印机而产生死锁。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:1","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"破坏占有和等待条件 只要禁止已持有资源的进程再等待其他资源便可以消除死锁。 破坏占有和等待条件的两种方法 一种实现方法是规定所有进程在开始执行前请求所需的全部资源。如果所需的全部资源可用，那么就将它们分配给这个进程，于是该进程肯定能够运行结束。如果有一个或多个资源正被使用，那么就不进行分配，进程等待。(先获取后释放) 另一种破坏占有和等待条件的略有不同的方案是，要求当一个进程请求资源时，先暂时释放其当前占用的所有资源，然后再尝试一次获得所需的全部资源。（先释放后获取） ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:2","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"破坏不可抢占条件 但是，一些资源可以通过虚拟化的方式来避免发生这样的情况。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:3","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"破坏环路等待条件 一种避免出现环路等待的方法是将所有资源统一编号，现在的规则是：进程可以在任何时刻提出资源请求，但是所有请求必须按照资源编号的顺序（升序）提出。进程可以先请求打印机后请求磁带机，但不可以先请求绘图仪后请求打印机。 尽管对资源编号的方法消除了死锁的问题，但几乎找不出一种使每个人都满意的编号次序。当资源包括进程表项、假脱机磁盘空间、加锁的数据库记录及其他抽象资源时，潜在的资源及各种不同用途的数目会变得很大，以至于使编号方法根本无法使用。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:4","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"两阶段加锁 常用的方法是两阶段加锁（two-phase locking）。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:5","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"通信死锁 资源死锁是最普遍的一种类型，但不是惟一的一种。另一种死锁发生在通信系统中（比如说网络），即两个或两个以上进程利用发送信息来通信时。一种普遍的情形是进程A向进程B发送请求信息，然后阻塞直至B回复。假设请求信息丢失，A将阻塞以等待回复，而B会阻塞等待一个向其发送命令的请求，因此发生死锁。 通常可以用来中断通信死锁：超时。在大多数网络通信系统中，只要一个信息被发送至一个特定的地方，并等待其返回一个预期的回复，发送者就同时启动计时器。若计时器在回复到达前计时就停止了，则信息的发送者可以认定信息已经丢失，并重新发送（如果需要，则一直重复）。通过这种方式，可以避免死锁。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:6","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"活锁 在某种情形下，轮询（忙等待）可用于进入临界区或存取资源。采用这一策略的主要原因是，相比所做的工作而言，互斥的时间很短而挂起等待的时间开销很大 因此，没有出现死锁现象（因为没有进程阻塞），但是从现象上看好像死锁发生了，这就是活锁（livelock）。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:7","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"饥饿 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:2:8","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"小结 死锁小结 死锁是任何操作系统的潜在问题。在一组进程中，每个进程都因等待由该组进程中的另一进程所占有的资源而导致阻塞，死锁就发生了。这种情况会使所有的进程都处于无限等待的状态。一般来讲，这是进程一直等待被其他进程占用的某些资源释放的事件。死锁的另外一种可能的情况是一组通信进程都在等待一个消息，而通信信道却是空的，并且也没有采用超时机制。 通过跟踪哪一个状态是安全状态，哪一个状态是不安全状态，可以避免死锁。安全状态就是这样一个状态：存在一个事件序列，保证所有的进程都能完成。不安全状态就不存在这样的保证。银行家算法可以通过拒绝可能引起不安全状态的请求来避免死锁。 也可以在设计系统时就不允许死锁发生，从而在系统结构上预防死锁的发生。例如，只允许进程在任何时刻最多占有一个资源，这就破坏了循环等待环路。也可以将所有的资源编号，规定进程按严格的升序请求资源，这样也能预防死锁。 资源死锁并不是惟一的一种死锁。尽管我们可以通过设置适当的超时机制来解决通信死锁，但它依然是某些系统中潜在的问题。 活锁和死锁的问题有些相似，那就是它也可以停止所有的转发进程，但是二者在技术上不同，由于活锁包含了一些实际上并没有锁住的进程，因此可以通过先来先服务的分配策略来避免饥饿。 ","date":"2021-04-25","objectID":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/:3:0","tags":["操作系统"],"title":"操作系统-死锁篇","uri":"/posts/thinking/%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2/"},{"categories":["操作系统"],"content":"霞诗子","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"资源 需要排他性使用的对象称为资源（resource）。资源可以是硬件设备（如磁带机）或是一组信息（如数据库中一个加锁的记录）。通常在计算机中有多种（可获取的）资源。一些类型的资源会有若干个相同的实例 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:1:0","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"可抢占资源和不可抢占资源 资源分为两类：可抢占的和不可抢占的。可抢占资源（preemptable resource）可以从拥有它的进程中抢占而不会产生任何副作用。相反，不可抢占资源（nonpreemptable resource）是指在不引起相关的计算失败的情况下，无法把它从占有它的进程处抢占过来。 总的来说，死锁和不可抢占资源有关，有关可抢占资源的潜在死锁通常可以通过在进程之间重新分配资源而化解。 资源处理过程 使用一个资源所需要的事件顺序可以用抽象的形式表示如下： 请求资源。 使用资源。 释放资源。 若请求时资源不可用，则请求进程被迫等待。在一些操作系统中，资源请求失败时进程会自动被阻塞，在资源可用时再唤醒它。在其他的系统中，资源请求失败会返回一个错误代码，请求的进程会等待一段时间，然后重试。 当一个进程请求资源失败时，它通常会处于这样一个小循环中：请求资源，休眠，再请求。这个进程虽然没有被阻塞，但是从各角度来说，它不能做任何有价值的工作，实际和阻塞状态一样。在后面的讨论中，我们假设：如果某个进程请求资源失败，那么它就进入休眠状态。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:1:1","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"资源获取 现在考虑两个进程（A和B）以及两个资源的情况。 死锁 其中一个进程先于另一个进程获取资源。这个进程能够成功地获取第二个资源并完成它的任务。如果另一个进程想在第一个资源被释放之前获取该资源，那么它会由于资源加锁而被阻塞，直到该资源可用为止。 可能其中一个进程获取了两个资源并有效地阻塞了另外一个进程，直到它使用完这两个资源为止。但是，也有可能进程A获取了资源1，进程B获取了资源2，每个进程如果都想请求另一个资源就会被阻塞，那么，每个进程都无法继续运行。这种情况就是死锁。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:1:2","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"死锁概述 如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么，该进程集合就是死锁的。 在大多数情况下，每个进程所等待的事件是释放该进程集合中其他进程所占有的资源。换言之，这个死锁进程集合中的每一个进程都在等待另一个死锁的进程已经占有的资源。但是由于所有进程都不能运行，它们中的任何一个都无法释放资源，所以没有一个进程可以被唤醒。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:2:0","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"资源死锁的条件 （资源）死锁的四个必要条件： 必要条件 互斥条件。每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待条件。已经得到了某个资源的进程可以再请求新的资源。 不可抢占条件。已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待条件。死锁发生时，系统中一定有由两个或两个以上的进程组成的一条环路，该环路中的每个进程都在等待着下一个进程所占有的资源。 死锁发生时，以上四个条件一定是同时满足的。如果其中任何一个条件不成立，死锁就不会发生。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:2:1","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"死锁建模 死锁与策略 忽略该问题。也许如果你忽略它，它也会忽略你。 检测死锁并恢复。让死锁发生，检测它们是否发生，一旦发生死锁，采取行动解决问题。 仔细对资源进行分配，动态地避免死锁。 通过破坏引起死锁的四个必要条件之一，防止死锁的产生。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:2:2","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"鸵鸟算法 最简单的解决方法是鸵鸟算法：把头埋到沙子里，假装根本没有问题发生 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:3:0","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"死锁检测和死锁恢复 在使用这种技术时，系统并不试图阻止死锁的产生，而是允许死锁发生，当检测到死锁发生后，采取措施进行恢复。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:4:0","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"每种类型一个资源的死锁检测 一种资源的死锁检测算法 通过执行下列步骤完成上述算法： 对图中的每一个节点N，将N作为起始点执行下面5个步骤。 将L初始化为空表，并清除所有的有向边标记。 将当前节点添加到L的尾部，并检测该节点是否在L中已出现过两次。如果是，那么该图包含了一个环（已列在L中），算法结束。 从给定的节点开始，检测是否存在没有标记的从该节点出发的弧（有向边）。如果存在的话，做第5步；如果不存在，跳到第6步。 随机选取一条没有标记的从该节点出发的弧（有向边），标记它。然后顺着这条弧线找到新的当前节点，返回到第3步。 如果这一节点是起始节点，那么表明该图不存在任何环，算法结束。否则意味着我们走进了死胡同，所以需要移走该节点，返回到前一个节点，即当前节点前面的一个节点，并将它作为新的当前节点，同时转到第3步。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:4:1","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"每种类型多个资源的死锁检测 如果有多种相同的资源存在，就需要采用另一种方法来检测死锁。 换言之，如果我们将所有已分配的资源j的数量加起来再和所有可供使用的资源数相加，结果就是该类资源的资源总数。 死锁检测算法 寻找一个没有标记的进程Pi ，对于它而言R矩阵的第i行向量小于或等于A。 如果找到了这样一个进程，那么将C矩阵的第i行向量加到A中，标记该进程，并转到第1步。 如果没有这样的进程，那么算法终止。 算法结束时，所有没有标记过的进程（如果存在的话）都是死锁进程。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:4:2","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"从死锁中恢复 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:5:0","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"利用抢占恢复 在不通知原进程的情况下，将某一资源从一个进程强行取走给另一个进程使用，接着又送回，这种做法是否可行主要取决于该资源本身的特性。 用这种方法恢复通常比较困难或者说不太可能。若选择挂起某个进程，则在很大程度上取决于哪一个进程拥有比较容易收回的资源 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:5:1","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"利用回滚恢复 如果系统设计人员以及主机操作员了解到死锁有可能发生，他们就可以周期性地对进程进行检查点检查（checkpointed）。进程检查点检查就是将进程的状态写入一个文件以备以后重启。该检查点中不仅包括存储映像，还包括了资源状态，即哪些资源分配给了该进程。为了使这一过程更有效，新的检查点不应覆盖原有的文件，而应写到新文件中。这样，当进程执行时，将会有一系列的检查点文件被累积起来。 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:5:2","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"通过杀死进程恢复 ","date":"2021-04-23","objectID":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/:5:3","tags":["操作系统"],"title":"操作系统-死锁与资源","uri":"/posts/thinking/%E8%B5%84%E6%BA%90%E4%B8%8E%E6%AD%BB%E9%94%81/"},{"categories":["操作系统"],"content":"霞诗子","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"磁盘 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:0:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"磁盘格式化 在磁盘能够使用之前，每个盘片必须经受由软件完成的低级格式化（low-level format）。该格式包含一系列同心的磁道，每个磁道包含若干数目的扇区，扇区间存在短的间隙。一个扇区的格式如图。 前导码以一定的位模式开始，位模式使硬件得以识别扇区的开始。前导码还包含柱面与扇区号以及某些其他信息。数据部分的大小是由低级格式化程序决定的，大多数磁盘使用512字节的扇区。ECC域包含冗余信息，可以用来恢复读错误。该域的大小和内容随生产商的不同而不同，它取决于设计者为了更高的可靠性愿意放弃多少磁盘空间以及控制器能够处理的ECC编码有多复杂。16字节的ECC域并不是罕见的。此外，所有硬盘都分配有某些数目的备用扇区，用来取代具有制造瑕疵的扇区。 在设置低级格式时，每个磁道上第0扇区的位置与前一个磁道存在偏移。这一偏移称为柱面斜进（cylinder skew），这样做是为了改进性能、想法是让磁盘在一次连续的操作中读取多个磁道而不丢失数据。 假设一个读请求需要最内侧磁道上从第0扇区开始的18个扇区，磁盘旋转一周可以读取前16个扇区，但是为了得到第17个扇区，则需要一次寻道操作以便磁头向外移动一个磁道。到磁头移动了一个磁道时，第0扇区已经转过了磁头，所以需要旋转一整周才能等到它再次经过磁头。 格式化 柱面斜进量取决于驱动器的几何规格。例如，一个10 000rpm的驱动器每6ms旋转一周，如果一个磁道包含300个扇区，那么每20µs就有一个新扇区在磁头下通过。如果磁道到磁道的寻道时间是800µs，那么在寻道期间将有40个扇区通过，所以柱面斜进应该是40个扇区而不是图中的三个扇区。值得一提的是，像柱面斜进一样也存在着磁头斜进（head skew），但是磁头斜进不是非常大。 低级格式化的结果是磁盘容量减少，减少的量取决于前导码、扇区间间隙和ECC的大小以及保留的备用扇区的数目。通常格式化的容量比未格式化的容量低20%。备用扇区不计入格式化的容量，所以一种给定类型的所有磁盘在出厂时具有完全相同的容量，与它们实际具有多少坏扇区无关（如果坏扇区的数目超出了备用扇区的数目，则该驱动器是不合格的，不会出厂）。 实际上，以这一速率连续地读磁盘要求控制器中有一个大容量的缓冲区。例如，考虑一个控制器，它具有一个扇区的缓冲区，该控制器接到一条命令要读两个连续的扇区。当从磁盘上读出第一个扇区并做了ECC计算之后，数据必须传送到主存中。就在传送正在进行时，下一个扇区将从磁头下通过。当完成了向主存的复制时，控制器将不得不等待几乎一整周的旋转时间才能等到第二个扇区再次回来。 通过在格式化磁盘时以交错方式对扇区进行编号可以消除这一问题。在图a中，我们看到的是通常的编号模式（此处忽略柱面斜进）。在图b中，我们看到的是单交错（single interleaving），它可以在连续的扇区之间给控制器以喘息的空间以便将缓冲区复制到主存。 在低级格式化完成之后，要对磁盘进行分区。在逻辑上，每个分区就像是一个独立的磁盘。分区对于多个操作系统共存是必需的。 在准备一块磁盘以便于使用的最后一步是对每一个分区分别执行一次高级格式化（high-level format）。这一操作要设置一个引导块、空闲存储管理（空闲列表或位图）、根目录和一个空文件系统。这一操作还要将一个代码设置在分区表项中，以表明在分区中使用的是哪个文件系统，因为许多操作系统支持多个兼容的文件系统（由于历史原因）。这时，系统就可以引导了。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:1:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"磁盘臂调度算法 调度算法 寻道时间（将磁盘臂移动到适当的柱面上所需的时间）。 旋转延迟（等待适当扇区旋转到磁头下所需的时间）。 实际数据传输时间。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:2:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"先来先服务（First-Come，First-Served，FCFS） 磁盘驱动程序每次接收一个请求并按照接收顺序完成请求、缺陷：磁盘负载过重 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:2:1","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"最短寻道优先（Shortest Seek First，SSF） 下一次总是处理与磁头距离最近的请求以使寻道时间最小化。缺陷：不断有新请求距离最近，距离最远的请求永远无法处理 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:2:2","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"电梯算法（elevator algorithm） 当一个请求处理完之后，磁盘或电梯的驱动程序检查该位，如果是UP，磁盘臂或电梯舱移至下一个更高的未完成的请求。如果更高的位置没有未完成的请求，则方向位取反。当方向位设置为DOWN时，同时存在一个低位置的请求，则移向该位置。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:2:3","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"错误处理 对于坏块存在两种一般的处理方法：在控制器中对它们进行处理或者在操作系统中对它们进行处理。在前一种方法中，磁盘在从工厂出厂之前要进行测试，并且将一个坏扇区列表写在磁盘上。对于每一个坏扇区，用一个备用扇区替换它。 a)具有一个坏扇区的磁盘磁道；b)用备用扇区替换坏扇区；c)移动所有扇区以回避坏扇区 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:3:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"稳定存储器 稳定存储器使用一对完全相同的磁盘，对应的块一同工作以形成一个无差错的块。当不存在错误时，在两个驱动器上对应的块是相同的，读取任意一个都可以得到相同的结果。为了达到这一目的，定义了下述三种操作： 三种操作 稳定写（stable write）。稳定写首先将块写到驱动器1上，然后将其读回以校验写的是正确的。如果写的不正确，那么就再次做写和重读操作，一直到n次，直到正常为止。经过n次连续的失败之后，就将该块重映射到一个备用块上，并且重复写和重读操作直到成功为止，无论要尝试多少个备用块。在对驱动器1的写成功之后，对驱动器2上对应的块进行写和重读，如果需要的话就重复这样的操作，直到最后成功为止。如果不存在CPU崩溃，那么当稳定写完成后，块就正确地被写到两个驱动器上，并且在两个驱动器上得到校验。 稳定读（stable read）。稳定读首先从驱动器l上读取块。如果这一操作产生错误的ECC，则再次尝试读操作，一直到n次。如果所有这些操作都给出错误的ECC，则从驱动器2上读取对应的数据块。给定一个成功的稳定写为数据块留下两个可靠的副本这样的事实，并且我们假设在合理的时间间隔内相同的块在两个驱动器上自发地变坏的概率可以忽略不计，那么稳定读就总是成功的。 崩溃恢复（crash recovery）。崩溃之后，恢复程序扫描两个磁盘，比较对应的块。如果一对块都是好的并且是相同的，就什么都不做。如果其中一个具有ECC错误，那么坏块就用对应的好块来覆盖。如果一对块都是好的但是不相同，那么就将驱动器1上的块写到驱动器2上。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:4:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"时钟 时钟（clock）又称为定时器（timer），时钟负责维护时间，并且防止一个进程垄断CPU，此外还有其他的功能。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:5:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"时钟硬件 时钟由三个部件构成：晶体振荡器、计数器和存储寄存器， 工作流程 当把一块石英晶体适当地切割并且安装在一定的压力之下时，它就可以产生非常精确的周期性信号，典型的频率范围是几百兆赫兹，具体的频率值与所选的晶体有关。使用电子器件可以将这一基础信号乘以一个小的整数来获得高达1000MHz甚至更高的频率。在任何一台计算机里通常都可以找到至少一个这样的电路，它给计算机的各种电路提供同步信号。该信号被送到计数器，使其递减计数至0。当计数器变为0时，产生一个CPU中断。 可编程时钟通常具有几种操作模式。在一次完成模式（one-shot mode）下，当时钟启动时，它把存储寄存器的值复制到计数器中，然后，来自晶体的每一个脉冲使计数器减1。当计数器变为0时，产生一个中断，并停止工作，直到软件再一次显式地启动它。在方波模式（square-wave mode）下，当计数器变为0并且产生中断之后，存储寄存器的值自动复制到计数器中，并且整个过程无限期地再次重复下去。这些周期性的中断称为时钟滴答（clock tick）。 可编程时钟的优点是其中断频率可以由软件控制 如果采用500MHz的晶体，那么计数器将每隔2ns脉动一次。对于（无符号）32位寄存器，中断可以被编程为从2ns时间间隔发生一次到8.6s时间间隔发生一次。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:5:1","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"时钟软件 时钟硬件所做的全部工作是根据已知的时间间隔产生中断。涉及时间的其他所有工作都必须由软件——时钟驱动程序完成。时钟驱动程序的确切任务因操作系统而异，但通常包括下面的大多数任务： 任务 维护日时间。 防止进程超时运行。 对CPU的使用情况记账。 处理用户进程提出的alarm系统调用。 为系统本身的各个部分提供监视定时器。 完成概要剖析、监视和统计信息收集。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:5:2","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"软定时器 一般而言，有两种方法管理I/O：中断和轮询。 描述 系统调用。 TLB未命中。 页面故障。 I/O中断。 CPU变成空闲。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:5:3","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"用户界面：键盘、鼠标和监视器 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:6:0","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"输入软件 键盘软件 每当一个键被按下的时候都会产生一个中断，并且每当一个键被释放的时候还会产生第二个中断。 鼠标软件 当鼠标在随便哪个方向移动了一个确定的最小距离，或者按钮被按下或释放时，都会有一条消息发送给计算机。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:6:1","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"输出软件 文本窗口 当输出是连续的单一字体、大小和颜色的形式时，输出比输入简单。大体上，程序将字符发送到当前窗口，而字符在那里显示出来。通常，一个字符块或者一行是在一个系统调用中被写到窗口上的。 X窗口系统 几乎所有UNIX系统的用户界面都以X窗口系统（X Window System）为基础，X窗口系统经常仅称为X，它是作为Athena计划 [1] 的一部分于20世纪80年代在MIT开发的。 图形用户界面 位图 字体 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:6:2","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"客户机 此处的基本思想是从客户机剥离一切智能和软件，只是将其用作一台显示器，使所有计算（包括建立待显示的位图）都在服务器端完成。客户机和服务器之间的协议只是通知显示器如何更新视频RAM，再无其他。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:6:3","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"小结 小结 输入/输出是一个经常被忽略但是十分重要的话题。任何一个操作系统都有大量的组分与I/O有关。I/O可以用三种方式来实现。第一是程序控制I/O，在这种方式下主CPU输入或输出每个字节或字并且闲置在一个密封的循环中等待，直到它能够获得或者发送下一个字节或字。第二是中断驱动的I/O，在这种方式下CPU针对一个字节或字开始I/O传送并且离开去做别的事情，直到一个中断到来发出信号通知I/O完成。第三是DMA，在这种方式下有一个单独的芯片管理着一个数据块的完整传送过程，只有当整个数据块完成传送时才引发一个中断。 I/O可以组织成4个层次：中断服务程序、设备驱动程序、与设备无关的I/O软件和运行在用户空间的I/O库与假脱机程序。设备驱动程序处理运行设备的细节并且向操作系统的其余部分提供统一的接口。与设备无关的I/O软件做类似缓冲与错误报告这样的事情。 盘具有多种类型，包括磁盘、RAID和各类光盘。磁盘臂调度算法经常用来改进磁盘性能，但是虚拟几何规格的出现使事情变得十分复杂。通过将两块磁盘组成一对，可以构造稳定的存储介质，具有某些有用的性质。 时钟可以用于跟踪实际时间，限制进程可以运行多长时间，处理监视定时器，以及进行记账。 面向字符的终端具有多种多样的问题，这些问题涉及特殊的字符如何输入以及特殊的转义序列如何输出。输入可以采用原始模式或加工模式，取决于程序对于输入需要有多少控制。针对输出的转义序列控制着光标的移动并且允许在屏幕上插入和删除文本。 大多数UNIX系统使用X窗口系统作为用户界面的基础。它包含与特殊的库相绑定并发出绘图命令的程序，以及在显示器上执行绘图的服务器。 许多个人计算机使用GUI作为它们的输出。GUI基于WIMP范式：窗口、图标、菜单和定点设备。基于GUI的程序一般是事件驱动的，当键盘事件、鼠标事件和其他事件发生时立刻会被发送给程序以便处理。在UNIX系统中，GUI几乎总是运行在X之上。 瘦客户机与标准PC相比具有某些优势，对用户而言，值得注意的是简单性并且需要较少维护。对THINC瘦客户机进行的实验表明，以五条简单的原语就能制造出具有良好性能的客户机，即使对于视频也是如此。 最后，电源管理对于笔记本电脑来说是一个主要的问题，因为电池寿命是有限的。操作系统可以采用各种技术来减少功率消耗。通过牺牲某些质量以换取更长的电池寿命，应用程序也可以做出贡献。 ","date":"2021-04-22","objectID":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/:6:4","tags":["操作系统"],"title":"操作系统-IO输入输出","uri":"/posts/thinking/io-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"},{"categories":["操作系统"],"content":"霞诗子","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"磁盘 磁盘被组织成柱面，每一个柱面包含若干磁道，磁道数与垂直堆叠的磁头个数相同。磁道又被分成若干扇区，软盘上大约每条磁道有8～32个扇区，硬盘上每条磁道上扇区的数目可以多达几百个。磁头数大约是1～16个。 老式的磁盘只有少量的电子设备，它们只是传送简单的串行位流。在这些磁盘上，控制器做了大部分的工作。在其他磁盘上，特别是在IDE（Integrated Drive Electronics，集成驱动电子设备）和SATA（Serial ATA，串行ATA）盘上，磁盘驱动器本身包含一个微控制器，该微控制器承担了大量的工作并且允许实际的控制器发出一组高级命令。控制器经常做磁道高速缓存、坏块重映射以及更多的工作。 对磁盘驱动程序有重要意义的一个设备特性是：控制器是否可以同时控制两个或多个驱动器进行寻道，这就是重叠寻道（overlapped seek）。 当控制器和软件等待一个驱动器完成寻道时，控制器可以同时启动另一个驱动器进行寻道。许多控制器也可以在一个驱动器上进行读写操作，与此同时再对另一个或多个其他驱动器进行寻道，但是软盘控制器不能在两个驱动器上同时进行读写操作。（读写数据要求控制器在微秒级时间尺度传输数据，所以一次传输就用完了控制器大部分的计算能力。） 对于具有集成控制器的硬盘而言情况就不同了，在具有一个以上这种硬盘驱动器的系统上，它们能够同时操作，至少在磁盘与控制器的缓冲存储器之间进行数据传输的限度之内是这样。然而，在控制器与主存之间可能同时只有一次传输。同时执行两个或多个操作的能力极大地降低了平均存取时间。 ","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/:0:1","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"RAID RAID背后的基本思想是将一个装满了磁盘的盒子安装到计算机（通常是一个大型服务器）上，用RAID控制器替换磁盘控制器卡，将数据复制到整个RAID上，然后继续常规的操作。 RAID分级总结 RAID 0亦称为带区卷。它将两个以上的磁盘并联起来，成为一个大容量的磁盘。在存放数据时，分段后分散存储在这些磁盘中，因为读写时都可以并行处理，所以在所有的级别中，RAID 0的速度是最快的。但是RAID 0既没有冗余功能，也不具备容错能力，如果一个磁盘（物理）损坏，所有数据都会丢失，危险程度与JBOD相当。 两组以上的N个磁盘相互作镜像，在一些多线程操作系统中能有很好的读取速度，理论上读取速度等于硬盘数量的倍数，与RAID 0相同。另外写入速度有微小的降低。只要一个磁盘正常即可维持运作，可靠性最高。其原理为在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。因为有镜像硬盘做数据备份，所以RAID 1的数据安全性在所有的RAID级别上来说是最好的。但无论用多少磁盘做RAID 仅算一个磁盘的容量，是所有RAID中磁盘利用率最低的一个级别。RAID 1没有校验机制。用两个磁盘组成RAID 1阵列，如果两个硬盘上的数据出现差异，RAID 1会不知道该相信哪一个硬盘，这种情形称作大脑分裂。事实上，RAID 1的磁盘数量越多，越有可能其中某个磁盘的数据变得不一致（但仍然工作），RAID 1只会从第一个工作的硬盘里提供数据，没有办法检测到底哪个硬盘的数据不对。 这是RAID 0的改良版，以汉明码（Hamming Code）的方式将数据进行编码后分割为独立的比特，并将数据分别写入硬盘中。因为在数据中加入错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些。RAID 2最少要三台磁盘驱动器方能运作。 采用Bit－interleaving（数据交错存储）技术，它需要通过编码再将数据比特分割后分别存在硬盘中，而将同比特检查后单独存在一个硬盘中，但由于数据内的比特分散在不同的硬盘上，因此就算要读取一小段数据资料都可能需要所有的硬盘进行工作，所以这种规格比较适于读取大量数据时使用。 RAID 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分割）技术。RAID 5使用“奇偶校验位”。与 RAID-4 一样，有效大小是 N-1 个磁盘的大小。 然而，由于奇偶校验信息也在 N 个驱动器之间均匀分布，因此避免了每次写入都必须更新奇偶校验磁盘的瓶颈。防止单个磁盘故障，而且访问速度快[2]。RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID 5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID 5的一个磁盘数据发生损坏后，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。RAID 5可以理解为是RAID 0和RAID 1的折衷方案。RAID 5可以为系统提供数据安全保障，但保障程度要比镜像低而磁盘空间利用率要比镜像高。RAID 5具有和RAID 0相近似的数据读取速度，只是因为多了一个奇偶校验信息， ","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/:0:2","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"CD-ROM 黄皮书（Yellow Book），定义了现在称为CD-ROM（Compact Disc-Read Only Memory，压缩光盘-只读存储器）的光盘的确切标准。 CD-ROM CD-ROM的基本格式是每个字节以14位的符号进行编码。正如我们在前面看到的，14位足以对一个8位的字节进行汉明编码，并且剩下2位。实际上，CD-ROM使用的是功能更为强大的编码系统 [2] 。对于读操作而言，14到8映射是通过查找表由硬件实现的。在下一个层次上，一组42个连续符号形成一个588位的帧（frame）。每一帧拥有192个数据位（24个字节），剩余的396位用于纠错和控制。在这396位中，252位是14位符号中的纠错位，而144位包含在8位符号的有效载荷中 [3] 。到目前为止，这一方案对于音频CD和CD-ROM是完全一致的。 黄皮书定义了两种模式。模式1具有16字节的前导码、2048个数据字节和一个288字节的纠错码（横交叉Reed-Solomon码）。模式2将数据和ECC域合并成一个2336字节的数据域，用于不需要纠错（或者抽不出时间执行纠错）的应用，例如音频和视频。注意，为了提供优异的可靠性，在符号内部、帧内部和CD-ROM扇区内部使用了三种独立的纠错方案。单个位的错误在最低的层次上纠正，短暂的突发错误在帧的层次上纠正，任何残留的错误在扇区的层次上捕获。为这一可靠性付出的代价是花费98个588位的帧（7203字节）来容纳2048字节的有效载荷，效率只有28%。 单速CD-ROM驱动器以75扇区/秒的速度工作，提供的数据率在模式1下是153 600字节/秒，在模式2下是175 200字节/秒。双速驱动器快两倍，以此类推，直到最高的速度。因此，一个40倍速的驱动器能够以40×153 600字节/秒的速度传递数据，假设驱动器接口、总线以及操作系统都能够处理这样的数据率。一个标准的音频CD具有存放74分钟音乐的空间，如果将其用于在模式1下存放数据，提供的容量是681 984 000字节。这一数字通常被报告为650MB，这是因为1MB是220 字节（1 048 576字节），而不是1 000 000字节。 注意，即使一个32倍速的CD-ROM驱动器（数据率为4 915 200字节/秒）也无法与速度为10MB/s的快速SCSI-2磁盘驱动器相配，尽管许多CD-ROM驱动器使用了SCSI接口（也存在IDE CD-ROM驱动器）。当你意识到寻道时间通常是几百毫秒时，就会清楚CD-ROM驱动器与磁盘驱动器在性能上不属于同样的范畴，尽管它们有非常大的容量。 ","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/:0:3","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"可刻录CD 物理上，CD-R在开始的时候是像CD-ROM一样的120mm的聚碳酸酯空盘，不同的是CD-R包含一个0.6mm宽的凹槽来引导激光进行写操作。凹槽具有3mm的正弦振幅，频率精确地为22.05 kHz，以便提供连续的反馈，这样就可以正确地监视旋转速度并且在需要的时候对其进行调整。CD-R看上去就像是常规的CD-ROM，只是CD-R顶面是金色的而不是银色的。金色源于使用真金代替铝作为反射层。银色的CD在其上具有物理的凹陷，与此不同的是，在CD-R上，必须模拟凹痕和槽脊的不同反射率。这是通过在聚碳酸酯与反射金层之间添加一层染料而实现的。 在初始状态下，染料层是透明的，能够让激光透过并且从金层反射回来。写入时，CD-R激光提升到高功率（8～16mW）。当光束遇到染料时，将其加热，从而破坏其化学结合力，这一分子结构的变化造成一个暗斑。当读回时（以0.5mW），光电探测器会识别出已经被烧过的染料处的暗斑与完好的透明区域之间的区别。这一区别被解释为凹痕与槽脊之间的差别，即使在常规的CD-ROM阅读器甚至在音频CD播放器上读回时，也是如此。 如果没有一本有色的书，就没有CD的新类型能够骄傲地昂起头，所以CD-R具有橘皮书（Orange Book），出版于1989年。这份文档定义了CD-R和一个新格式CD-ROM XA，它允许CD-R被逐渐增长地写入，今天几个扇区，明天几个扇区，下个月几个扇区。一次写入的一组连续的扇区称为一个CD-ROM光轨（CD-ROM track）。 ","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/:0:4","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"可重写CD 尽管人们习惯于使用其他一次性写的介质，例如纸张和摄影胶片，但是却存在着对可重写CD-ROM的需求。目前可用的一个技术是CD-RW（CD-ReWritable，可重写CD）、它使用与CD-ROM相同尺寸的介质。然而，CD-RW使用银、铟、锑和碲合金作为记录层，以取代花菁和酞菁染料。这一合金具有两个稳定的状态：结晶态和非结晶态，两种状态具有不同的反射率。 ","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/:0:5","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"DVD DVD采用与CD同样的总体设计，使用120 mm的注模聚碳酸酯盘片，包含凹痕和槽脊，它们由激光二极管照明并且由光电探测器读取。新特性包括使用了： DVD 结构特点： 更小的凹痕（0.4µm，CD是0.8µm）。 更密的螺旋（轨迹间距0.74µm，CD是1.6µm）。 红色激光（波长0.65µm，CD是0.78µm）。 为追求容量定义了四种格式： 单面单层（4.7GB）。 单面双层（8.5GB）。 双面单层（9.4GB）。 双面双层（17GB）。 综合起来，这些改进将容量提高了7倍，达到4.7GB。一个1倍速的DVD驱动器以1.4 MB/s的速率运转（CD是150 KB/s）。但是，切换到红色激光意味着DVD播放器需要第二个激光器或者价格高昂的光学转换器才能够读取现有的CD和CD-ROM。随着激光器价格的下降，现在大多数驱动器都有两种激光器，所以它们能够读取两种类型的介质。 ","date":"2021-04-20","objectID":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/:0:6","tags":["操作系统"],"title":"操作系统-IO物理设备","uri":"/posts/thinking/io-%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E7%AF%87/"},{"categories":["操作系统"],"content":"霞诗子","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"I/O软件原理 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:1:0","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"I/O软件的目标 在设计I/O软件时一个关键的概念是设备独立性（device independence）。 它的意思是应该能够编写出这样的程序：它可以访问任意I/O设备而无需事先指定设备。例如，读取一个文件作为输入的程序应该能够在硬盘、CD-ROM、DVD或者USB盘上读取文件，无需为每一种不同的设备修改程序。 注意 与设备独立性密切相关的是统一命名（uniform naming）这一目标。一个文件或一个设备的名字应该是一个简单的字符串或一个整数，它不应依赖于设备。在UNIX系统中，所有存储盘都能以任意方式集成到文件系统层次结构中，因此，用户不必知道哪个名字对应于哪台设备。例如，一个USB盘可以安装（mount）到目录/usr/ast/backup下，这样复制文件到/usr/ast/backup/monday就是将文件复制到USB盘上。用这种方法，所有文件和设备都采用相同的方式——路径名进行寻址 I/O软件的另一个重要问题是错误处理（error handling）。一般来说，错误应该尽可能地在接近硬件的层面得到处理。当控制器发现了一个读错误时，如果它能够处理那么就应该自己设法纠正这一错误。如果控制器处理不了，那么设备驱动程序应当予以处理，可能只需重读一次这块数据就正确了。很多错误是偶然性的，例如，磁盘读写头上的灰尘导致读写错误时，重复该操作，错误经常就会消失。只有在低层软件处理不了的情况下，才将错误上交高层处理。在许多情况下，错误恢复可以在低层透明地得到解决，而高层软件甚至不知道存在这一错误。 另一个关键问题是同步（synchronous）（即阻塞）和异步（asynchronous）（即中断驱动）传输。大多数物理I/O是异步的——CPU启动传输后便转去做其他工作，直到中断发生。如果I/O操作是阻塞的，那么用户程序就更加容易编写——在read系统调用之后，程序将自动被挂起，直到缓冲区中的数据准备好。正是操作系统使实际上是中断驱动的操作变为在用户程序看来是阻塞式的操作。 I/O软件的另一个问题是缓冲（buffering）。数据离开一个设备之后通常并不能直接存放到其最终的目的地。例如，从网络上进来一个数据包时，直到将该数据包存放在某个地方并对其进行检查，操作系统才知道要将其置于何处。此外，某些设备具有严格的实时约束（例如，数字音频设备），所以数据必须预先放置到输出缓冲区之中，从而消除缓冲区填满速率和缓冲区清空速率之间的相互影响，以避免缓冲区欠载。缓冲涉及大量的复制工作，并且经常对I/O性能有重大影响。 最后一个概念是共享设备和独占设备的问题。有些I/O设备（如磁盘）能够同时让多个用户使用。多个用户同时在同一磁盘上打开文件不会引起什么问题。其他设备（如磁带机）则必须由单个用户独占使用，直到该用户使用完，另一个用户才能拥有该磁带机。让两个或更多的用户随机地将交叉混杂的数据块写入相同的磁带是注定不能工作的。独占（非共享）设备的引入也带来了各种各样的问题，如死锁。同样，操作系统必须能够处理共享设备和独占设备以避免问题发生。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:1:1","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"程序IO 任务完成前一直占用cpu 借助于例子来说明程序控制I/O是最简单的。考虑一个用户进程，该进程想在打印机上打印8个字符的字符串ABCDEFGH。它首先要在用户空间的一个缓冲区中组装字符串，如图5-7a所示。 然后，用户进程通过发出系统调用打开打印机来获得打印机以便进行写操作。如果打印机当前被另一个进程占用，该系统调用将失败并返回一个错误代码，或者将阻塞直到打印机可用，具体情况取决于操作系统和调用参数。一旦拥有打印机，用户进程就发出一个系统调用通知操作系统在打印机上打印字符串。 然后，操作系统（通常）将字符串缓冲区复制到内核空间中的一个数组（如p）中，在这里访问更加容易（因为内核可能必须修改内存映射才能到达用户空间）。然后操作系统要查看打印机当前是否可用。如果不可用，就要等待直到它可用。一旦打印机可用，操作系统就复制第一个字符到打印机的数据寄存器中，在这个例子中使用了内存映射I/O。这一操作将激活打印机。字符也许还不会出现在打印机上，因为某些打印机在打印任何东西之前要先缓冲一行或一页。然而，在图5-7b中，我们看到第一个字符已经打印出来，并且系统已经将B标记为下一个待打印的字符。 一旦将第一个字符复制到打印机，操作系统就要查看打印机是否就绪准备接收另一个字符。一般而言，打印机都有第二个寄存器，用于表明其状态。将字符写到数据寄存器的操作将导致状态变为非就绪。当打印机控制器处理完当前字符时，它就通过在其状态寄存器中设置某一位或者将某个值放到状态寄存器中来表示其可用性。 这时，操作系统将等待打印机状态再次变为就绪。打印机就绪事件发生时，操作系统就打印下一个字符，如图5-7c所示。这一循环继续进行，直到整个字符串打印完。然后，控制返回到用户进程。 操作系统进入一个密闭的循环，一次输出一个字符。在该图中，清楚地说明了程序控制I/O的最根本的方面，这就是输出一个字符之后，CPU要不断地查询设备以了解它是否就绪准备接收另一个字符。这一行为经常称为轮询（polling）或忙等待（busy waiting）。 程序控制I/O十分简单但是有缺点，即直到全部I/O完成之前要占用CPU的全部时间。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:1:2","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"中断驱动I/O 在字符打印完成后发起中断执行其他任务 现在我们考虑在不缓冲字符而是在每个字符到来时便打印的打印机上进行打印的情形。如果打印机每秒可以打印100个字符，那么打印每个字符将花费10ms。这意味着，当每个字符写到打印机的数据寄存器中之后，CPU将有10ms搁置在无价值的循环中，等待允许输出下一个字符。这10ms时间足以进行一次上下文切换并且运行其他进程，否则就浪费了。 这种允许CPU在等待打印机变为就绪的同时做某些其他事情的方式就是使用中断。当打印字符串的系统调用被发出时，如我们前面所介绍的，字符串缓冲区被复制到内核空间，并且一旦打印机准备好接收一个字符时就将第一个字符复制到打印机中。这时，CPU要调用调度程序，并且某个其他进程将运行。请求打印字符串的进程将被阻塞，直到整个字符串打印完。 当打印机将字符打印完并且准备好接收下一个字符时，它将产生一个中断。这一中断将停止当前进程并且保存其状态。然后，打印机中断服务过程将运行。如果没有更多的字符要打印，中断处理程序将采取某个操作将用户进程解除阻塞。否则，它将输出下一个字符，应答中断，并且返回到中断之前正在运行的进程，该进程将从其停止的地方继续运行。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:1:3","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"使用DMA的I/O DMA重大的成功是将中断的次数从打印每个字符一次减少到打印每个缓冲区一次。 中断驱动I/O的一个明显缺点是中断发生在每个字符上。中断要花费时间，所以这一方法将浪费一定数量的CPU时间。这一问题的一种解决方法是使用DMA。此处的思路是让DMA控制器一次给打印机提供一个字符，而不必打扰CPU。本质上，DMA是程序控制I/O，只是由DMA控制器而不是主CPU做全部工作。这一策略需要特殊的硬件（DMA控制器），但是使CPU获得自由从而可以在I/O期间做其他工作。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:1:4","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"I/O软件层次 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:2:0","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"中断处理程序 处理程序 保存没有被中断硬件保存的所有寄存器（包括PSW）。 为中断服务过程设置上下文，可能包括设置TLB、MMU和页表。 为中断服务过程设置堆栈。 应答中断控制器，如果不存在集中的中断控制器，则再次开放中断。 将寄存器从它们被保存的地方（可能是某个堆栈）复制到进程表中。 运行中断服务过程，从发出中断的设备控制器的寄存器中提取信息。 选择下一次运行哪个进程，如果中断导致某个被阻塞的高优先级进程变为就绪，则可能选择它现在就运行。 为下一次要运行的进程设置MMU上下文，也许还需要设置某个TLB。 装入新进程的寄存器，包括其PSW。 开始运行新进程。 当中断发生时，中断处理程序将做它必须要做的全部工作以便对中断进行处理。然后，它可以将启动中断的驱动程序解除阻塞。在一些情形中，它只是在一个信号量上执行up操作；其他情形中，是对管程中的条件变量执行signal操作；还有一些情形中，是向被阻塞的驱动程序发一个消息。在所有这些情形中，中断最终的结果是使先前被阻塞的驱动程序现在能够继续运行。如果驱动程序构造为内核进程，具有它们自己的状态、堆栈和程序计数器，那么这一模型运转得最好。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:2:1","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"设备驱动程序 因而，每个连接到计算机上的I/O设备都需要某些设备特定的代码来对其进行控制。这样的代码称为设备驱动程序（device driver），它一般由设备的制造商编写并随同设备一起交付。因为每一个操作系统都需要自己的驱动程序，所以设备制造商通常要为若干流行的操作系统提供驱动程序。 介绍 为了访问设备的硬件（意味着访问设备控制器的寄存器），设备驱动程序通常必须是操作系统内核的一部分，至少对目前的体系结构是如此。实际上，有可能构造运行在用户空间的驱动程序，使用系统调用来读写设备寄存器、这一设计使内核与驱动程序相隔离，并且使驱动程序之间相互隔离，这样做可以消除系统崩溃的一个主要源头——有问题的驱动程序以这样或那样的方式干扰内核。对于建立高度可靠的系统而言，这绝对是正确的方向。MINIX 3就是一个这样的系统，其中设备驱动程序就作为用户进程而运行。 随着个人计算机的出现，这一模型不再起作用，因为个人计算机有太多种类的I/O设备。即便拥有源代码或目标模块，也只有很少的用户有能力重新编译和重新连接内核，何况他们并不总是拥有源代码或目标模块。为此，从MS-DOS开始，操作系统转向驱动程序在执行期间动态地装载到系统中的另一个模型。不同的操作系统以不同的方式处理驱动程序的装载工作。 操作系统通常将驱动程序归类于少数的类别之一。最为通用的类别是块设备（block device）和字符设备（character device）。块设备（例如磁盘）包含多个可以独立寻址的数据块，字符设备（例如键盘和打印机）则生成或接收字符流。 驱动程序的功能 设备驱动程序具有若干功能。最明显的功能是接收来自其上方与设备无关的软件所发出的抽象的读写请求，并且目睹这些请求被执行。除此之外，还有一些其他的功能必须执行。例如，如果需要的话，驱动程序必须对设备进行初始化。它可能还需要对电源需求和日志事件进行管理。 许多设备驱动程序具有相似的一般结构。典型的驱动程序在启动时要检查输入参数，检查输入参数的目的是搞清它们是否是有效的，如果不是，则返回一个错误。如果输入参数是有效的，则可能需要进行从抽象事项到具体事项的转换。对磁盘驱动程序来说，这可能意味着将一个线性的磁盘块号转换成磁盘几何布局的磁头、磁道、扇区和柱面号。 接着，驱动程序可能要检查设备当前是否在使用。如果在使用，请求将被排入队列以备稍后处理。如果设备是空闲的，驱动程序将检查硬件状态以了解请求现在是否能够得到处理。在传输能够开始之前，可能需要接通设备或者启动马达。一旦设备接通并就绪，实际的控制就可以开始了。 控制设备意味着向设备发出一系列命令。依据控制设备必须要做的工作，驱动程序处在确定命令序列的地方。驱动程序在获知哪些命令将要发出之后，它就开始将它们写入控制器的设备寄存器。驱动程序在把每个命令写到控制器之后，它可能必须进行检测以了解控制器是否已经接收命令并且准备好接收下一个命令。这一序列继续进行，直到所有命令被发出。对于某些控制器，可以为其提供一个在内存中的命令链表，并且告诉它自己去读取并处理所有命令而不需要操作系统提供进一步帮助。 命令发出之后，会牵涉两种情形之一。在多数情况下，设备驱动程序必须等待，直到控制器为其做某些事情，所以驱动程序将阻塞其自身直到中断到来解除阻塞。然而，在另外一些情况下，操作可以无延迟地完成，所以驱动程序不需要阻塞。在字符模式下滚动屏幕只需要写少许字节到控制器的寄存器中，由于不需要机械运动，所以整个操作可以在几纳秒内完成，这便是后一种情形的例子。 在前一种情况下，阻塞的驱动程序可以被中断唤醒。在后一种情况下，驱动程序根本就不会休眠。无论是哪一种情况，操作完成之后驱动程序都必须检查错误。如果一切顺利，驱动程序可能要将数据（例如刚刚读出的一个磁盘块）传送给与设备无关的软件。最后，它向调用者返回一些用于错误报告的状态信息。如果还有其他未完成的请求在排队，则选择一个启动执行。如果队列中没有未完成的请求，则该驱动程序将阻塞以等待下一个请求。 这一简单的模型只是现实的粗略近似，许多因素使相关的代码比这要复杂得多。首先，当一个驱动程序正在运行时，某个I/O设备可能会完成操作，这样就会中断驱动程序。中断可能会导致一个设备驱动程序运行，事实上，它可能导致当前驱动程序运行。例如，当网络驱动程序正在处理一个到来的数据包时，另一个数据包可能到来。因此，驱动程序必须是重入的（reentrant），这意味着一个正在运行的驱动程序必须预料到在第一次调用完成之前第二次被调用。 在一个热可插拔的系统中，设备可以在计算机运行时添加或删除。因此，当一个驱动程序正忙于从某设备读数据时，系统可能会通知它用户突然将设备从系统中删除了。在这样的情况下，不但当前I/O传送必须中止并且不能破坏任何核心数据结构，而且任何对这个现已消失的设备的悬而未决的请求都必须适当地从系统中删除，同时还要为它们的调用者提供这一坏消息。此外，未预料到的新设备的添加可能导致内核重新配置资源（例如中断请求线），从驱动程序中撤除旧资源，并且在适当位置填入新资源。 驱动程序不允许进行系统调用，但是它们经常需要与内核的其余部分进行交互。对某些内核过程的调用通常是允许的。例如，通常需要调用内核过程来分配和释放硬接线的内存页面作为缓冲区。还可能需要其他有用的调用来管理MMU、定时器、DMA控制器、中断控制器等。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:2:2","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"与设备无关的I/O软件 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:0","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"设备驱动程序的统一接口 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:1","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":" 设备驱动程序与操作系统其余部分之间的接口是这一问题的一个方面。图所示为这样一种情形：每个设备驱动程序有不同的与操作系统的接口。这意味着，可供系统调用的驱动程序函数随驱动程序的不同而不同。这可能还意味着，驱动程序所需要的内核函数也是随驱动程序的不同而不同的。综合起来看，这意味着为每个新的驱动程序提供接口都需要大量全新的编程工作。 这种设计的工作方式如下。对于每一种设备类型，例如磁盘或打印机，操作系统定义一组驱动程序必须支持的函数。对于磁盘而言，这些函数自然地包含读和写，除此之外还包含开启和关闭电源、格式化以及其他与磁盘有关的事情。驱动程序通常包含一张表格，这张表格具有针对这些函数指向驱动程序自身的指针。当驱动程序装载时，操作系统记录下这张函数指针表的地址，所以当操作系统需要调用一个函数时，它可以通过这张表格发出间接调用。这张函数指针表定义了驱动程序与操作系统其余部分之间的接口。给定类型（磁盘、打印机等）的所有设备都必须服从这一要求。 如何给I/O设备命名是统一接口问题的另一个方面。与设备无关的软件要负责把符号化的设备名映射到适当的驱动程序上。例如，在UNIX系统中，像/dev/disk0这样的设备名惟一确定了一个特殊文件的i节点，这个i节点包含了主设备号（major device number），主设备号用于定位相应的驱动程序。i节点还包含次设备号（minor device number），次设备号作为参数传递给驱动程序，用来确定要读或写的具体单元。所有设备都具有主设备号和次设备号，并且所有驱动程序都是通过使用主设备号来选择驱动程序而得到访问。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:2","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"缓冲 a)无缓冲的输入；b)用户空间中的缓冲；c)内核空间中的缓冲接着复制到用户空间；d)内核空间中的双缓冲 四种缓冲模式 对于每个到来的字符，都必须启动用户进程。对于短暂的数据流量让一个进程运行许多次效率会很低，所以这不是一个良好的设计。 此处，用户进程在用户空间中提供了一个包含n个字符的缓冲区，并且执行读入n个字符的读操作。中断服务过程负责将到来的字符放入该缓冲区中直到缓冲区填满，然后唤醒用户进程。这一方案比前一种方案的效率要高很多，但是它也有一个缺点：当一个字符到来时，如果缓冲区被分页而调出了内存会出现什么问题呢？解决方法是将缓冲区锁定在内存中，但是如果许多进程都在内存中锁定页面，那么可用页面池就会收缩并且系统性能将下降。 另一种方法是在内核空间中创建一个缓冲区并且让中断处理程序将字符放到这个缓冲区中、当该缓冲区被填满的时候，将包含用户缓冲区的页面调入内存（如果需要的话），并且在一次操作中将内核缓冲区的内容复制到用户缓冲区中。这一方法的效率要高很多。 广泛使用的另一种形式的缓冲是循环缓冲区（circular buffer）。它由一个内存区域和两个指针组成。一个指针指向下一个空闲的字，新的数据可以放置到此处。另一个指针指向缓冲区中数据的第一个字，该字尚未被取走。在许多情况下，当添加新的数据时（例如刚刚从网络到来），硬件将推进第一个指针，而操作系统在取走并处理数据时推进第二个指针。两个指针都是环绕的，当它们到达顶部时将回到底部。 缓冲对于输出也是十分重要的。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:3","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"错误报告 错误在I/O上下文中比在其他上下文中要常见得多。当错误发生时，操作系统必须尽最大努力对它们进行处理。许多错误是设备特定的并且必须由适当的驱动程序来处理，但是错误处理的框架是设备无关的。 错误类型 一种类型的I/O错误是编程错误，这些错误发生在一个进程请求某些不可能的事情时，例如写一个输入设备（键盘、扫描仪、鼠标等）或者读一个输出设备（打印机、绘图仪等）。其他的错误包括提供了一个无效的缓冲区地址或者其他参数，以及指定了一个无效的设备（例如，当系统只有两块磁盘时指定了磁盘3），如此等等。在这些错误上采取的行动是直截了当的：只是将一个错误代码报告返回给调用者。 另一种类型的错误是实际的I/O错误，例如，试图写一个已经被破坏的磁盘块，或者试图读一个已经关机的便携式摄像机。在这些情形中，应该由驱动程序决定做什么。如果驱动程序不知道做什么，它应该将问题向上传递，返回给与设备无关的软件。 软件要做的事情取决于环境和错误的本质。 如果是一个简单的读错误并且存在一个交互式的用户可利用，那么它就可以显示一个对话框来询问用户做什么。选项可能包括重试一定的次数，忽略错误，或者杀死调用进程。如果没有用户可利用，惟一的实际选择或许就是以一个错误代码让系统调用失败。 然而，某些错误不能以这样的方式来处理。 例如，关键的数据结构（如根目录或空闲块列表）可能已经被破坏，在这种情况下，系统也许只好显示一条错误消息并且终止。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:4","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"分配与释放专用设备 某些设备，例如CD-ROM刻录机，在任意给定的时刻只能由一个进程使用。这就要求操作系统对设备使用的请求进行检查，并且根据被请求的设备是否可用来接受或者拒绝这些请求。处理这些请求的一种简单方法是要求进程在代表设备的特殊文件上直接执行open操作。如果设备是不可用的，那么open就会失败。于是就关闭这样的一个专用设备，然后将其释放。 一种代替的方法是对于请求和释放专用设备要有特殊的机制。试图得到不可用的设备可以将调用者阻塞，而不是让其失败。阻塞的进程被放入一个队列。迟早被请求的设备会变得可用，这时就可以让队列中的第一个进程得到该设备并且继续执行。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:5","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"与设备无关的块大小 不同的磁盘可能具有不同的扇区大小。 应该由与设备无关的软件来隐藏这一事实并且向高层提供一个统一的块大小，例如，将若干个扇区当作一个逻辑块。这样，高层软件就只需处理抽象的设备，这些抽象设备全都使用相同的逻辑块大小，与物理扇区的大小无关。类似地，某些字符设备（如调制解调器）一次一个字节地交付它们的数据，而其他的设备（如网络接口）则以较大的单位交付它们的数据。这些差异也可以被隐藏起来。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:6","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"用户空间的I/O软件 例如，当一个用户程序试图从一个文件中读一个块时，操作系统被调用以实现这一请求。与设备无关的软件在缓冲区高速缓存中查找有无要读的块。如果需要的块不在其中，则调用设备驱动程序，向硬件发出一个请求，让它从磁盘中获取该块。然后，进程被阻塞直到磁盘操作完成。 当磁盘操作完成时，硬件产生一个中断。中断处理程序就会运行，它要查明发生了什么事情，也就是说此刻需要关注哪个设备。然后中断处理程序从设备提取状态信息，唤醒休眠的进程以结束此次I/O请求，并且让用户进程继续运行。 ","date":"2021-04-11","objectID":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/:3:7","tags":["操作系统"],"title":"操作系统-IO软件原理","uri":"/posts/thinking/io%E8%BD%AF%E4%BB%B6%E5%8E%9F%E7%90%86/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"页面置换算法篇 当发生缺页中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间。 如果要换出的页面在内存驻留期间已经被修改过，就必须把它写回磁盘以更新该页面在磁盘上的副本；如果该页面没有被修改过（如一个包含程序正文的页面），那么它在磁盘上的副本已经是最新的，不需要回写。直接用调入的页面覆盖掉被淘汰的页面就可以了。 当发生缺页中断时，虽然可以随机地选择一个页面来置换，但是如果每次都选择不常使用的页面会提升系统的性能。如果一个被频繁使用的页面被置换出内存，很可能它在很短时间内又要被调入内存，这会带来不必要的开销。 如果要换出的页面在内存驻留期间已经被修改过，就必须把它写回磁盘以更新该页面在磁盘上的副本；如果该页面没有被修改过（如一个包含程序正文的页面），那么它在磁盘上的副本已经是最新的，不需要回写。直接用调入的页面覆盖掉被淘汰的页面就可以了。 在接下来讨论的所有页面置换算法中都存在一个问题：当需要从内存中换出某个页面时，它是否只能是缺页进程本身的页面？这个要换出的页面是否可以属于另外一个进程？ 在前一种情况下，可以有效地将每一个进程限定在固定的页面数目内；后一种情况则不能。这两种情况都是可能的。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:0","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"最优页面置换算法 在缺页中断发生时，有些页面在内存中，其中有一个页面（包含紧接着的下一条指令的那个页面）将很快被访问，其他页面则可能要到10、100或1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数作为标记。 最优页面置换算法规定应该置换标记最大的页面。如果一个页面在800万条指令内不会被使用，另外一个页面在600万条指令内不会被使用，则置换前一个页面，从而把因需要调入这个页面而发生的缺页中断推迟到将来，越久越好。 这个算法惟一的问题就是它是无法实现的。当缺页中断发生时，操作系统无法知道各个页面下一次将在什么时候被访问。（在最短作业优先调度算法中，我们曾遇到同样的情况，即系统如何知道哪个作业是最短的呢？）当然，通过首先在仿真程序上运行程序，跟踪所有页面的访问情况，在第二次运行时利用第一次运行时收集的信息是可以实现最优页面置换算法的。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:1","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"最近未使用页面置换算法 可以用R位和M位来构造一个简单的页面置换算法：当启动一个进程时，它的所有页面的两个位都由操作系统设置成0，R位被定期地（比如在每次时钟中断时）清零，以区别最近没有被访问的页面和被访问的页面。 当发生缺页中断时，操作系统检查所有的页面并根据它们当前的R位和M位的值，把它们分为4类： 没有被访问，没有被修改。 没有被访问，已被修改。 已被访问，没有被修改。 已被访问，已被修改。 NRU（Not Recently Used，最近未使用）算法随机地从类编号最小的非空类中挑选一个页面淘汰之。 这个算法隐含的意思是，在最近一个时钟滴答中（典型的时间是大约20ms）淘汰一个没有被访问的已修改页面要比淘汰一个被频繁使用的“干净”页面好。NRU主要优点是易于理解和能够有效地被实现，虽然它的性能不是最好的，但是已经够用了。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:2","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"先进先出页面置换算法 另一种开销较小的页面置换算法是FIFO（First-In First-Out，先进先出）算法。 由操作系统维护一个所有当前在内存中的页面的链表，最新进入的页面放在表尾，最久进入的页面放在表头。当发生缺页中断时，淘汰表头的页面并把新调入的页面加到表尾。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:3","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"第二次机会页面置换算法 FIFO算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：检查最老页面的R位。如果R位是0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是1，就将R位清0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续搜索。 这一算法称为第二次机会（second chance）算法 假设在时间20发生了一次缺页中断，这时最老的页面是A，它是在时刻0到达的。如果A的R位是0，则将它淘汰出内存，或者把它写回磁盘（如果它已被修改过），或者只是简单地放弃（如果它是“干净”的）；另一方面，如果其R位已经设置了，则将A放到链表的尾部并且重新设置“装入时间”为当前时刻（20），然后清除R位。然后从B页面开始继续搜索合适的页面。 第二次机会算法就是寻找一个最近的时钟间隔以来没有被访问过的页面。如果所有的页面都被访问过了，该算法就简化为纯粹的FIFO算法。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:4","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"时钟页面置换算法 尽管第二次机会算法是一个比较合理的算法，但它经常要在链表中移动页面，既降低了效率又不是很有必要。一个更好的办法是把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面。 当发生缺页中断时，算法首先检查表针指向的页面，如果它的R位是0就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；如果R位是1就清除R位并把表针前移一个位置，重复这个过程直到找到了一个R位为0的页面为止。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:5","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"最近最少使用页面置换算法 这个思想提示了一个可实现的算法：在缺页中断发生时，置换未使用时间最长的页面。这个策略称为LRU（Least Recently Used，最近最少使用）页面置换算法。 在前面几条指令中频繁使用的页面很可能在后面的几条指令中被使用。反过来说，已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用、为了完全实现LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是在每次访问内存时都必须要更新整个链表。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作，即使使用硬件实现也一样费时（假设有这样的硬件）。 硬件LRU算法实现的两种可能 有一些使用特殊硬件实现LRU的方法。我们先考虑一个最简单的方法。这个方法要求硬件有一个64位计数器C，它在每条指令执行完后自动加1，每个页表项必须有一个足够容纳这个计数器值的域。在每次访问内存后，将当前的C值保存到被访问页面的页表项中。一旦发生缺页中断，操作系统就检查所有页表项中计数器的值，找到值最小的一个页面，这个页面就是最近最少使用的页面。 二个硬件实现的LRU算法。在一个有n个页框的机器中，LRU硬件可以维持一个初值为0的n×n位的矩阵。当访问到页框k时，硬件首先把k行的位都设置成1，再把k列的位都设置成0。在任何时刻，二进制数值最小的行就是最近最少使用的，第二小的行是下一个最近最少使用的，以此类推。这个算法的工作过程可以用图3-17所示的实例说明，该实例中有4个页框，页面访问次序为： ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:6","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"用软件模拟LRU NFU（Not Frequently Used，最不常用）算法。该算法将每个页面与一个软件计数器相关联，计数器的初值为0。每次时钟中断时，由操作系统扫描内存中所有的页面，将每个页面的R位（它的值是0或1）加到它的计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。发生缺页中断时，则置换计数器值最小的页面。 NFU的主要问题是它从来不忘记任何事情。比如，在一个多次（扫描）编译器中，在第一次扫描中被频繁使用的页面在程序进入第二次扫描时，其计数器的值可能仍然很高。实际上，如果第一次扫描的执行时间恰好是各次扫描中最长的，含有以后各次扫描代码的页面的计数器可能总是比含有第一次扫描代码的页面小，结果是操作系统将置换有用的页面而不是不再使用的页面。 只需对NFU做一个小小的修改就能使它很好地模拟LRU。其修改分为两部分：首先，在R位被加进之前先将计数器右移一位；其次，将R位加到计数器最左端的位而不是最右端的位。 修改以后的算法称为老化（aging）算法， LRU和老化算法的第二个区别是老化算法的计数器只有有限位数，这就限制了其对以往页面的记录。如果两个页面的计数器都是0，我们只能在两个页面中随机选一个进行置换。时钟周期越长、要求位数越长、记录次数越多 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:7","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"工作集页面置换算法 一个进程当前正在使用的页面的集合称为它的工作集（working set） 如果整个工作集都被装入到了内存中，那么进程在运行到下一运行阶段（例如，编译器的下一遍扫描）之前，不会产生很多缺页中断。若内存太小而无法容纳下整个工作集，那么进程的运行过程中会产生大量的缺页中断，导致运行速度也会变得很缓慢，因为通常只需要几个纳秒就能执行完一条指令，而通常需要十毫秒才能从磁盘上读入一个页面。 不少分页系统都会设法跟踪进程的工作集，以确保在让进程运行以前，它的工作集就已在内存中了。该方法称为工作集模型（working set model）（Denning，1970），其目的在于大大减少缺页中断率。在让进程运行前预先装入其工作集页面也称为预先调页（prepaging）。请注意工作集是随着时间变化的。 人们很早就发现大多数程序都不是均匀地访问它们的地址空间的，而访问往往是集中于一小部分页面。一次内存访问可能会取出一条指令，也可能会取数据，或者是存储数据。在任一时刻t，都存在一个集合，它包含所有最近k次内存访问所访问过的页面。这个集合w(k,t)就是工作集。因为最近k=1次访问肯定会访问最近k＞1次访问所访问过的页面，所以w(k,t)是k的单调非递减函数。随着k的变大，w(k,t)是不会无限变大的，因为程序不可能访问比它的地址空间所能容纳的页面数目上限还多的页面，并且几乎没有程序会使用每个页面。 现在就可以这样定义：工作集即是过去10ms中的内存访问所用到的页面的集合。 因此，如果一个进程在T时刻开始，在（T+100）ms的时刻使用了40ms CPU时间，对工作集而言，它的时间就是40ms。一个进程从它开始执行到当前所实际使用的CPU时间总数通常称作当前实际运行时间。通过这个近似的方法，进程的工作集可以被称为在过去的τ秒实际运行时间中它所访问过的页面的集合。 工作集的页面置换算法、基本思路就是找出一个不在工作集中的页面并淘汰它。 只有那些在内存中的页面才可以作为候选者被淘汰，所以该算法忽略了那些不在内存中的页面。每个表项至少包含两条信息：上次使用该页面的近似时间和R（访问）位。空白的矩形表示该算法不需要的其他域，如页框号、保护位、M（修改）位。 在处理每个表项时，都需要检查R位。如果它是1，就把当前实际时间写进页表项的“上次使用时间”域，以表示缺页中断发生时该页面正在被使用。既然该页面在当前时钟滴答中已经被访问过，那么很明显它应该出现在工作集中，并且不应该被删除（假定τ横跨多个时钟滴答）。 如果R是0，那么表示在当前时钟滴答中，该页面还没有被访问过，则它就可以作为候选者被置换。为了知道它是否应该被置换，需要计算它的生存时间（即当前实际运行时间减去上次使用时间），然后与τ做比较。如果它的生存时间大于τ，那么这个页面就不再在工作集中，而用新的页面置换它。扫描会继续进行以更新剩余的表项。 然而，如果R是0同时生存时间小于或等于τ，则该页面仍然在工作集中。这样就要把该页面临时保留下来，但是要记录生存时间最长（“上次使用时间”的最小值）的页面。如果扫描完整个页表却没有找到适合被淘汰的页面，也就意味着所有的页面都在工作集中。在这种情况下，如果找到了一个或者多个R=0的页面，就淘汰生存时间最长的页面。在最坏情况下，在当前时间滴答中，所有的页面都被访问过了（也就是都有R=1），因此就随机选择一个页面淘汰，如果有的话最好选一个干净页面。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:8","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"工作集时钟页面置换算法 当缺页中断发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法是比较费时的。有一种改进的算法，它基于时钟算法，并且使用了工作集信息，称为WSClock（工作集时钟）算法（Carr和Hennessey，1981） 与时钟算法一样，所需的数据结构是一个以页框为元素的循环表。最初，该表是空的。当装入第一个页面后，把它加到该表中。随着更多的页面的加入，它们形成一个环。每个表项包含来自基本工作集算法的上次使用时间，以及R位（已标明）和M位（未标明）。 与时钟算法一样，每次缺页中断时，首先检查指针指向的页面。如果R位被置为1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰。然后把该页面的R位置为0，指针指向下一个页面，并重复该算法。 如果指针经过一圈返回它的起始点会发生什么呢？这里有两种情况： 至少调度了一次写操作。 对于第一种情况，指针仅仅是不停地移动，寻找一个干净页面。既然已经调度了一个或者多个写操作，最终会有某个写操作完成，它的页面会被标记为干净。置换遇到的第一个干净页面，这个页面不一定是第一个被调度写操作的页面，因为硬盘驱动程序为了优化性能可能已经把写操作重排序了。 没有调度过写操作。 对于第二种情况，所有的页面都在工作集中，否则将至少调度了一个写操作。由于缺乏额外的信息，一个简单的方法就是随便置换一个干净的页面来使用，扫描中需要记录干净页面的位置。如果不存在干净页面，就选定当前页面并把它写回磁盘。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:9","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"页面置换算法小结 NRU算法根据R位和M位的状态把页面分为四类。从编号最小的类中随机选择一个页面置换。该算法易于实现，但是性能不是很好，还存在更好的算法。 FIFO算法通过维护一个页面的链表来记录它们装入内存的顺序。淘汰的是最老的页面，但是该页面可能仍在使用，因此FIFO算法不是一个好的选择。 第二次机会算法是对FIFO算法的改进，它在移出页面前先检查该页面是否正在被使用。如果该页面正在被使用，就保留该页面。这个改进大大提高了性能。时钟算法是第二次机会算法的另一种实现。它具有相同的性能特征，而且只需要更少的执行时间。 LRU算法是一种非常优秀的算法，但是只能通过特定的硬件来实现。如果机器中没有该硬件，那么也无法使用该算法。NFU是一种近似于LRU的算法，它的性能不是非常好，然而，老化算法更近似于LRU并且可以更有效地实现，是一个很好的选择。 最后两种算法都使用了工作集。工作集算法有合理的性能，但它的实现开销较大。工作集时钟算法是它的一种变体，不仅具有良好的性能，并且还能高效地实现。 ","date":"2021-04-04","objectID":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/:1:10","tags":["操作系统"],"title":"操作系统-储存管理页面置换算法篇","uri":"/posts/thinking/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-04-01","objectID":"/posts/thinking/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","tags":["操作系统"],"title":"操作系统-储存管理虚拟内存","uri":"/posts/thinking/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"categories":["操作系统"],"content":"储存管理篇～虚拟内存技术 ","date":"2021-04-01","objectID":"/posts/thinking/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/:1:0","tags":["操作系统"],"title":"操作系统-储存管理虚拟内存","uri":"/posts/thinking/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"categories":["操作系统"],"content":"虚拟内存 尽管基址寄存器和界限寄存器可以用于创建地址空间的抽象，还有另一个问题需要解决：管理软件的膨胀（bloatware）。虽然存储器容量增长快速，但是软件大小的增长更快。 虚拟内存的基本思想是：每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一页或页面（page）。每一页有连续的地址范围。 这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。 从某个角度来讲，虚拟内存是对基址寄存器和界限寄存器的一种综合。 分页 由程序产生的这些地址称为虚拟地址（virtual address），它们构成了一个虚拟地址空间（virtual address space）。 在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到内存管理单元（Memory Management Unit，MMU），MMU把虚拟地址映射为物理内存地址。 MMU的位置和功能。这里MMU作为CPU芯片的一部分，因为通常就是这样做的。不过从逻辑上看，它可以是一片单独的芯片，并且早就已经这样了 虚拟地址空间按照固定大小划分成称为页面（page）的若干单元。在物理内存中对应的单元称为页框（page frame）。页面和页框的大小通常是一样的。RAM和磁盘之间的交换总是以整个页面为单元进行的。 通过恰当地设置MMU，可以把16个虚拟页面映射到8个页框中的任何一个。但是这并没有解决虚拟地址空间比物理内存大的问题。在图3-9中只有8个物理页框，于是只有8个虚拟页面被映射到了物理内存中，中用叉号表示的其他页并没有被映射。在实际的硬件中，用一个“在/不在”位（present/absent bit）记录页面在内存中的实际存在情况。 当程序访问了一个未映射的页面，例如执行指令 MOV REG,32780 MMU注意到该页面没有被映射（在图中用叉号表示），于是使CPU陷入到操作系统，这个陷阱称为缺页中断（page fault）。操作系统找到一个很少使用的页框且把它的内容写入磁盘（如果它不在磁盘上）。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。 为什么我们选用的页面大小都是2的整数次幂。 可用页号作为页表（page table）的索引，以得出对应于该虚拟页面的页框号。如果“在/不在”位是0，则将引起一个操作系统陷阱。如果该位是1，则将在页表中查到的页框号复制到输出寄存器的高3位中，再加上输入虚拟地址中的低12位偏移量。如此就构成了15位的物理地址。输出寄存器的内容随即被作为物理地址送到内存总线。 页表 作为一种最简单的实现，虚拟地址到物理地址的映射可以概括如下：虚拟地址被分成虚拟页号（高位部分）和偏移量（低位部分）两部分。 对于16位地址和4KB的页面大小，高4位可以指定16个虚拟页面中的一页，而低12位接着确定了所选页面中的字节偏移量（0～4095）。 虚拟页号可用做页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到页框号（如果有的话）。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址。 页表的目的是把虚拟页面映射为页框。从数学角度说，页表是一个函数，它的参数是虚拟页号，结果是物理页框号。通过这个函数可以把虚拟地址中的虚拟页面域替换成页框域，从而形成物理地址。 最重要的域是页框号。毕竟页映射的目的是找到这个值，其次是“在/不在”位，这一位是1时表示该表项是有效的，可以使用；如果是0，则表示该表项对应的虚拟页面现在不在内存中，访问该页面会引起一个缺页中断。 “保护”（protection）位指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。一个更先进的方法是使用三位，各位分别对应是否启用读、写、执行该页面。 为了记录页面的使用状况，引入了“修改”（modified）位和“访问”（referenced）位。 在写入一页时由硬件自动设置修改位。该位在操作系统重新分配页框时是非常有用的。如果一个页面已经被修改过（即它是“脏”的），则必须把它写回磁盘。如果一个页面没有被修改过（即它是“干净”的），则只简单地把它丢弃就可以了，因为它在磁盘上的副本仍然是有效的。这一位有时也被称为脏位（dirty bit），因为它反映了该页面的状态。 不论是读还是写，系统都会在该页面被访问时设置访问位。它的值被用来帮助操作系统在发生缺页中断时选择要被淘汰的页面。不再使用的页面要比正在使用的页面更适合淘汰。 最后一位用于禁止该页面被高速缓存。对那些映射到设备寄存器而不是常规内存的页面而言，这个特性是非常重要的。通过这一位可以禁止高速缓存。具有独立的I/O空间而不使用内存映射I/O的机器不需要这一位。 虚拟内存本质上是用来创造一个新的抽象概念——地址空间，这个概念是对物理内存的抽象，类似于进程是对物理机器（CPU）的抽象。虚拟内存的实现，是将虚拟地址空间分解成页，并将每一页映射到物理内存的某个页框或者（暂时）解除映射。 加速分页过程 在任何分页式系统中，都需要考虑两个主要问题： 虚拟地址到物理地址的映射必须非常快。 如果虚拟地址空间很大，页表也会很大。 第一个问题是由于每次访问内存，都需要进行虚拟地址到物理地址的映射。 所有的指令最终都必须来自内存，并且很多指令也会访问内存中的操作数。因此，每条指令进行一两次或更多页表访问是必要的。如果执行一条指令需要1ns，页表查询必须在0.2ns之内完成，以避免映射成为一个主要瓶颈。 第二个问题来自现代计算机使用至少32位的虚拟地址，而且64位变得越来越普遍。 假设页长为4KB，32位的地址空间将有100万页，而64位地址空间简直多到超乎你的想象。如果虚拟地址空间中有100万个页，那么页表必然有100万条表项。另外请记住，每个进程都需要自己的页表（因为它有自己的虚拟地址空间）。 对大而快速的页映射的需求成为了构建计算机的重要约束。最简单的设计（至少从概念上）是使用由一组“快速硬件寄存器”组成的单一页表，每一个表项对应一个虚页，虚页号作为索引，如图所示。 另一种极端方法是，整个页表都在内存中。那时所需的硬件仅仅是一个指向页表起始位置的寄存器。。这样的设计使得在上下文切换时，进行“虚拟地址到物理地址”的映射只需重新装入一个寄存器。当然，这种做法的缺陷是在执行每条指令时，都需要一次或多次内存访问，以完成页表项的读入，速度非常慢。 现在讨论加速分页机制和处理大的虚拟地址空间的实现方案，先介绍加速分页问题。大多数优化技术都是从内存中的页表开始的。这种设计对效率有着巨大的影响。例如，假设一条指令要把一个寄存器中的数据复制到另一个寄存器。在不分页的情况下，这条指令只访问一次内存，即从内存中取指令。有了分页后，则因为要访问页表而引起更多次的访问内存。由于执行速度通常被CPU从内存中取指令和数据的速度所限制，所以每次内存访问必须进行两次页表访问会降低一半的性能。在这种情况下，没人会采用分页机制。 转换检测缓冲区 为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问页表。这种设备称为转换检测缓冲区（Translation Lookaside Buffer，TLB），有时又称为相联存储器（associate memory） 这种解决方案的建立基于这样一种现象：大多数程序总是对少量的页面进行多次的访问，而不是相反的。因此，只有很少的页表项会被反复读取，而其他的页表项很少被访问。 它通常在MMU中，包含少量的表项，在此例中为8个，在实际中很少会超过64个。每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位、保护码（读/写/执行权限）和该页所对应的物理页框。除了虚拟页号（不是必须放在页表中的），这些域与页表中的域是一一对应的。另外还有一位用来记录这个表项是否有效（即是否在使用）。 TLB是如何工作的 将一个虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时（即并行）进行匹配，判断虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位，则将页框号直接从TLB中取出而不必再访问页表。如果虚拟页面号确实是在TLB中，但指令试图在一个只读页面上进行写操作，则会产生一个保护错误，就像对页表进行非法访问一样。 当虚拟页号不在TLB中时发生的事情值得讨论。如果MMU检测到没有有效的匹配项时，就会进行正常的页表查询。接着从TLB中淘汰一个表项，然后用新找到的页表项代替它。这样，如果这一页面很快再被访问，第二次访问TLB时自然将会命中而不是不命中。当一个表项被清除出TLB时，将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项中从页表装入到TLB中时，所有的值都来自内存。 软件TLB管理 许多现代的RISC机器，包括SPARC、MIPS以及HP PA，几乎所有的页面管理都是在软件中实现的。在这些机器上，TLB表项被操作系统显式地装载。当发生TLB访问失效，不再是由MMU到页表中查找并取出需要的页表项，而是生成一个TLB失效并将问题交给操作系统解决。系统必须先找到该页面，然后从TLB中删除一个项，接着装载一个新的项，最后再执行先前出错的指令。当然，所有这一切都必须在有限的几条指令中完成，因为TLB失效比缺页中断发生的更加频繁。 无论是用硬","date":"2021-04-01","objectID":"/posts/thinking/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/:1:1","tags":["操作系统"],"title":"操作系统-储存管理虚拟内存","uri":"/posts/thinking/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-26","objectID":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/","tags":["操作系统"],"title":"操作系统-存储交换技术","uri":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/"},{"categories":["操作系统"],"content":"存储管理 操作系统中管理分层存储器体系的部分称为存储管理器（memory manager）。它的任务是有效地管理内存，即记录哪些内存是正在使用的，哪些内存是空闲的；在进程需要时为其分配内存，在进程使用完后释放内存。 ","date":"2021-03-26","objectID":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/:1:0","tags":["操作系统"],"title":"操作系统-存储交换技术","uri":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/"},{"categories":["操作系统"],"content":"无存储器抽象 最简单的存储器抽象就是根本没有抽象。每一个程序都直接访问物理内存。 在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在2000的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。 不过即使存储器模型就是物理内存，还是存在一些可行选项的。当按这种方式组织系统时，通常同一个时刻只能有一个进程在运行。一旦用户键入了一个命令，操作系统就把需要的程序从磁盘复制到内存中并执行；当进程运行结束后，操作系统在用户终端显示提示符并等待新的命令。收到新的命令后，它把新的程序装入内存，覆盖前一个程序。 在没有内存抽象的系统中实现并行的一种方法是使用多线程来编程。 虽然这个想法行得通，但却没有被广泛使用，因为人们通常希望能够在同一时间运行没有关联的程序，而这正是线程抽象所不能提供的。更进一步地，一个没有内存抽象的系统也不大可能具有线程抽象的功能。 在不使用内存抽象的情况下运行多道程序 但是，即使没有内存抽象，同时运行多个程序也是可能的。操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可。只要在某一个时间内存中只有一个程序，那么就不会发生冲突。 a)一个16KB程序；b)另一个16KB程序；c)两个程序连续地装载到内存中 但是，当第一个程序已经运行了一段时间后，操作系统可能会决定开始运行第二个程序，即装载在第一个程序之上的地址16 384处的程序。这个程序的第一条指令是JMP 28，这条指令会使程序跳转到第一个程序的ADD指令，而不是事先设定的跳转到CMP指令。由于对内存地址的不正确访问，这个程序很可能在1秒之内就崩溃了。 这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。我们希望每个程序都使用一套私有的本地地址来进行内存寻址。 ","date":"2021-03-26","objectID":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/:1:1","tags":["操作系统"],"title":"操作系统-存储交换技术","uri":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/"},{"categories":["操作系统"],"content":"存储器抽象：地址空间 把物理地址暴露给进程会带来下面几个严重问题 第一，如果用户程序可以寻址内存的每个字节，它们就可以很容易地（故意地或偶然地）破坏操作系统，从而使系统慢慢地停止运行 第二，使用这种模型，想要同时（如果只有一个CPU就轮流执行）运行多个程序是很困难的。 地址空间的概念 要保证多个应用程序同时处于内存中并且不互相影响，则需要解决两个问题：保护和重定位 一个更好的办法是创造一个新的内存抽象：地址空间。就像进程的概念创造了一类抽象的CPU以运行程序一样，地址空间为程序创造了一种抽象的内存。地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间（除了在一些特殊情况下进程需要共享它们的地址空间外）。 比较难的是给每个程序一个自己的地址空间，使得一个程序中的地址28所对应的物理地址与另一个程序中的地址28所对应的物理地址不同。 基址寄存器与界限寄存器 这个简单的解决办法使用一种简单的动态重定位。它所做的是简单地把每个进程的地址空间映射到物理内存的不同部分。 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU硬件会在把地址发送到内存总线前，自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。如果访问的地址超过了界限，会产生错误并中止访问。 使用基址寄存器和界限寄存器重定位的缺点是，每次访问内存都需要进行加法和比较运算。比较可以做得很快，但是加法由于进位传递时间的问题，在没有使用特殊电路的情况下会显得很慢。 交换技术 如果计算机物理内存足够大，可以保存所有进程，那么之前提及的所有方案都或多或少是可行的。 有两种处理内存超载的通用方法。最简单的策略是交换（swapping）技术，即把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘。空闲进程主要存储在磁盘上，所以当它们不运行时就不会占用内存（尽管它们的一些进程会周期性地被唤醒以完成相关工作，然后就又进入睡眠状态）。另一种策略是虚拟内存（virtual memory），该策略甚至能使程序在只有一部分被调入内存的情况下运行。 交换在内存中产生了多个空闲区（hole，也称为空洞），通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块。该技术称为内存紧缩（memory compaction）。 有一个问题值得注意，即当进程被创建或换入时应该为它分配多大的内存。 若进程创建时其大小是固定的并且不再改变，则分配很简单，操作系统准确地按其需要的大小进行分配，不多也不少。 但是如果进程的数据段可以增长，例如，很多程序设计语言都允许从堆中动态地分配内存，那么当进程空间试图增长时，就会出现问题。若该进程与一个空闲区相邻，那么可把该空闲区分配给该进程让它在这个空闲区增大。 另一方面，若进程相邻的是另一个进程，那么要么把需要增长的进程移到内存中一个足够大的区域中去，要么把一个或多个进程交换出去，以便生成一个足够大的空闲区。 若一个进程在内存中不能增长，而且磁盘上的交换区也已满了，那么这个进程只有挂起直到一些空间空闲（或者可以结束该进程）。 如果大部分进程在运行时都要增长，为了减少因内存区域不够而引起的进程交换和移动所产生的开销，一种可用的方法是，当换入或移动进程时为它分配一些额外的内存。 然而，当进程被换出到磁盘上时，应该只交换进程实际上使用的内存中的内容，将额外的内存交换出去是一种浪费 a)为可能增长的数据段预留空间；b)为可能增长的数据段和堆栈段预留空间 如果进程有两个可增长的段，例如，供变量动态分配和释放的作为堆使用的一个数据段，以及存放普通局部变量与返回地址的一个堆栈段，则可使用另一种安排，在图中可以看到所示进程的堆栈段在进程所占内存的顶端并向下增长，紧接在程序段后面的数据段向上增长。在这两者之间的内存可以供两个段使用。如果用完了，进程或者必须移动到足够大的空闲区中（它可以被交换出内存直到内存中有足够的空间），或者结束该进程。 空闲内存管理 在动态分配内存时，操作系统必须对其进行管理。一般而言，有两种方式跟踪内存使用情况：位图和空闲链表。 使用位图的存储管理 使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0表示空闲，1表示占用（或者相反） a)一段有5个进程和3个空闲区的内存，刻度表示内存分配的单元，阴影区域表示空闲（在位图中用0表示）；b)对应的位图；c)用空闲表表示的同样的信息 分配单元的大小是一个重要的设计因素。分配单元越小，位图越大。但若进程的大小不是分配单元的整数倍，那么在最后一个分配单元中就会有一定数量的内存被浪费了。 因为内存的大小和分配单元的大小决定了位图的大小，所以它提供了一种简单的利用一块固定大小的内存区就能对内存使用情况进行记录的方法。这种方法的主要问题是，在决定把一个占k个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有k个连续0的串。查找位图中指定长度的连续0串是耗时的操作（因为在位图中该串可能跨越字的边界），这是位图的缺点。 使用链表的存储管理 另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是两个进程间的一个空的空闲区。 链表中的每一个结点都包含以下域：空闲区（H）或进程（P）的指示标志、起始地址、长度和指向下一结点的指针。段链表是按照地址排序的，其好处是当进程终止或被换出时链表的更新非常直接。 当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程（或从磁盘换入的已存在的进程）分配内存 最简单的算法是首次适配（first fit）算法。 存储管理器沿着段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将该空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区。首次适配算法是一种速度很快的算法，因为它尽可能少地搜索链表结点。 下次适配（next fit）算法。 它的工作方式和首次适配算法相同，不同点是每次找到合适的空闲区时都记录当时的位置。以便在下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次适配算法那样每次都从头开始。下次适配算法的性能略低于首次适配算法。 著名的并广泛应用的算法是最佳适配（best fit）算法。 最佳适配算法搜索整个链表（从开始到结束），找出能够容纳进程的最小的空闲区。最佳适配算法试图找出最接近实际需要的空闲区，以最好地区配请求和可用空闲区，而不是先拆分一个以后可能会用到的大的空闲区。 因为每次调用最佳适配算法时都要搜索整个链表，所以它要比首次适配算法慢。让人感到有点意外的是它比首次适配算法或下次适配算法浪费更多的内存，因为它会产生大量无用的小空闲区。 最差适配（worst fit）算法 即总是分配最大的可用空闲区，使新的空闲区比较大从而可以继续使用。仿真程序表明最差适配算法也不是一个好主意。 快速适配（quick fit）算法 它为那些常用大小的空闲区维护单独的链表。例如，有一个n项的表，该表的第一项是指向大小为4KB的空闲区链表表头的指针，第二项是指向大小为8KB的空闲区链表表头的指针，第三项是指向大小为12KB的空闲区链表表头的指针，以此类推。像21KB这样的空闲区既可以放在20KB的链表中，也可以放在一个专门存放大小比较特别的空闲区的链表中。 如果为进程和空闲区维护各自独立的链表，那么这四个算法的速度都能得到提高。这样就能集中精力只检查空闲区而不是进程。 但这种分配速度的提高的一个不可避免的代价就是增加复杂度和内存释放速度变慢，因为必须将一个回收的段从进程链表中删除并插入空闲区链表。 如果进程和空闲区使用不同的链表，则可以按照大小对空闲区链表排序，以便提高最佳适配算法的速度。 在使用最佳适配算法搜索由小到大排列的空闲区链表时，只要找到一个合适的空闲区，则这个空闲区就是能容纳这个作业的最小的空闲区，因此是最佳适配。因为空闲区链表以单链表形式组织，所以不需要进一步搜索。空闲区链表按大小排序时，首次适配算法与最佳适配算法一样快，而下次适配算法在这里则毫无意义。 ","date":"2021-03-26","objectID":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/:1:2","tags":["操作系统"],"title":"操作系统-存储交换技术","uri":"/posts/thinking/%E5%86%85%E5%AD%98%E7%AF%87/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"调度 当计算机系统是多道程序设计系统时，通常就会有多个进程或线程同时竞争CPU。只要有两个或更多的进程处于就绪状态，这种情形就会发生。如果只有一个CPU可用，那么就必须选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为调度程序（scheduler），该程序使用的算法称为调度算法（scheduling algorithm）。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:0","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"调度介绍 调度程序还要考虑CPU的利用率，因为进程切换的代价是比较高的。 首先，用户态必须切换到内核态；然后要保存当前进程的状态，包括在进程表中存储寄存器值以便以后重新装载。在许多系统中，内存映像（例如，页表内的内存访问位）也必须保存；接着，通过运行调度算法选定一个新进程；之后，应该将新进程的内存映像重新装入MMU；最后新进程开始运行。除此之外，进程切换还要使整个内存高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核一次，离开内核一次）。总之，如果每秒钟切换进程的次数太多，会耗费大量CPU时间，所以有必要提醒注意。 进程行为 几乎所有进程的（磁盘）I/O请求或计算都是交替突发的 典型地，CPU不停顿地运行一段时间，然后发出一个系统调用以便读写文件。在完成系统调用之后，CPU又开始计算，直到它需要读更多的数据或写更多的数据为止。 请注意，某些I/O活动可以看作是计算。例如，当CPU向视频RAM复制数据以更新屏幕时，因为使用了CPU，所以这是计算，而不是I/O活动 何时调度 第一，在创建一个新进程之后，需要决定是运行父进程还是运行子进程 由于这两种进程都处于就绪状态，所以这是一种正常的调度决策，可以任意决定，也就是说，调度程序可以合法选择先运行父进程还是先运行子进程。 第二，在一个进程退出时必须做出调度决策。 一个进程不再运行（因为它不再存在），所以必须从就绪进程集中选择另外某个进程。如果没有就绪的进程，通常会运行一个系统提供的空闲进程。 第三，当一个进程阻塞在I/O和信号量上或由于其他原因阻塞时，必须选择另一个进程运行。 有时，阻塞的原因会成为选择的因素。例如，如果A是一个重要的进程，并正在等待B退出临界区，让B随后运行将会使得B退出临界区，从而可以让A运行。不过问题是，通常调度程序并不拥有做出这种相关考虑的必要信息。 第四，在一个I/O中断发生时，必须做出调度决策。 如果中断来自I/O设备，而该设备现在完成了工作，某些被阻塞的等待该I/O的进程就成为可运行的就绪进程了。是否让新就绪的进程运行，这取决于调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让某个其他进程运行。 调度算法分类 批处理。 在批处理系统中，不会有用户不耐烦地在终端旁等待一个短请求的快捷响应。因此，非抢占式算法，或对每个进程都有长时间周期的抢占式算法，通常都是可接受的。 交互式。 在交互式用户环境中，为了避免一个进程霸占CPU拒绝为其他进程服务，抢占是必需的。服务器也归于此类，因为通常它们要服务多个突发的（远程）用户。 实时 实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。 调度算法的目标 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:1","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"批处理系统中的调度 先来先服务 在所有调度算法中，最简单的是非抢占式的先来先服务（first-come first-severd）算法。使用该算法，进程按照它们请求CPU的顺序使用CPU。基本上，有一个就绪进程的单一队列。 这个算法的主要优点是易于理解并且便于在程序中运用。就难以得到的体育或音乐会票的分配问题而言，这对那些愿意在早上两点就去排队的人们也是公平的。在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或阻塞一个进程，只要把该作业或进程附加在相应队列的末尾即可。 最短作业优先 现在来看一种适用于运行时间可以预知的另一个非抢占式的批处理调度算法。 这里有4个作业A、B、C、D，运行时间分别为8、4、4、4分钟。若按图中的次序运行，则A的周转时间为8分钟，B为12分钟，C为16分钟，D为20分钟，平均为14分钟。 考虑有4个作业的情况，其运行时间分别为a、b、c、d。第一个作业在时间a结束，第二个在时间a+b结束，以此类推。平均周转时间为（4a+3b+2c+d）/4。显然a对平均值影响最大，所以它应是最短作业，其次是b，再次是c，最后的d只影响它自己的周转时间。 最短作业调度是将后续具有最短处理时间的进程先放到CPU上运行，如果就绪队列中有同样长度的进程，那么它们之间是采用FCFS调度的。 最短下一个CPU区间，需要操作系统知道接下来是那个进程的CPU区间最短。 SJF就是调度这个最短CPU区间的进程。 有必要指出，只有在所有的作业都可同时运行的情形下，最短作业优先算法才是最优化的。 最短剩余时间优先 最短作业优先的抢占式版本是最短剩余时间优先（shortest remaining time next）算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。 再次提醒，有关的运行时间必须提前掌握。当一个新的作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式可以使新的短作业获得良好的服务。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:2","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"交互式系统中的调度 轮转调度 一种最古老、最简单、最公平且使用最广的算法是轮转调度（round robin）。 每个进程被分配一个时间段，称为时间片（quantum），即允许该进程在该时间段中运行。如果在时间片结束时该进程还在运行，则将剥夺CPU并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则CPU立即进行切换。时间片轮转调度很容易实现，调度程序所要做的就是维护一张可运行进程列表，当一个进程用完它的时间片后，就被移到队列的末尾 时间片轮转调度中惟一有趣的一点是时间片的长度。从一个进程切换到另一个进程是需要一定时间进行管理事务处理的——保存和装入寄存器值及内存映像、更新各种表格和列表、清除和重新调入内存高速缓存等。假如进程切换（process switch），有时称为上下文切换（context switch），需要1ms，包括切换内存映像、清除和重新调入高速缓存等。再假设时间片设为4ms。有了这些参数，则CPU在做完4ms有用的工作之后，CPU将花费（即浪费）1ms来进行进程切换。因此，CPU时间的20%浪费在管理开销上。 可以归结如下结论：时间片设得太短会导致过多的进程切换，降低了CPU效率；而设得太长又可能引起对短的交互请求的响应时间变长。将时间片设为20ms～50 ms通常是一个比较合理的折中。 优先级调度 轮转调度做了一个隐含的假设，即所有的进程同等重要 可以很方便地将一组进程按优先级分成若干类，并且在各类之间采用优先级调度，而在各类进程的内部采用轮转调度。 优先级也可以由系统动态确定。优先级可以是静态赋予或动态赋予。为了防止高优先级进程无休止地运行下去，调度程序可以在每个时钟滴答（即每个时钟中断）降低当前进程的优先级。如果这个动作导致该进程的优先级低于次高优先级的进程，则进行进程切换。一个可采用的方法是，每个进程可以被赋予一个允许运行的最大时间片，当这个时间片用完时，下一个次高优先级的进程获得机会运行。 如果不偶尔对优先级进行调整，则低优先级进程很可能会产生饥饿现象。 多级队列 如前所述，长时间片的进程又会影响到响应时间，其解决办法是设立优先级类。属于最高优先级类的进程运行一个时间片，属于次高优先级类的进程运行2个时间片，再次一级运行4个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。 最短进程优先 对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互进程，那将是非常好的。 一种办法是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设某个终端上每条命令的估计运行时间为T0 。现在假设测量到其下一次运行时间为T1 。可以用这两个值的加权和来改进估计时间，即aT0 +(1-a)T1 。 保证调度 一种完全不同的调度算法是向用户作出明确的性能保证，然后去实现它。 一种很实际并很容易实现的保证是：若用户工作时有n个用户登录，则用户将获得CPU处理能力的1/n。类似地，在一个有n个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得1/n的CPU时间。看上去足够公平了。 为了实现所做的保证，系统必须跟踪各个进程自创建以来已使用了多少CPU时间。然后它计算各个进程应获得的CPU时间，即自创建以来的时间除以n。由于各个进程实际获得的CPU时间是已知的，所以很容易计算出真正获得的CPU时间和应获得的CPU时间之比。比率为0.5说明一个进程只获得了应得时间的一半，而比率为2.0则说明它获得了应得时间的2倍。于是该算法随后转向比率最低的进程，直到该进程的比率超过它的最接近竞争者为止。 彩票调度 其基本思想是向进程提供各种系统资源（如CPU时间）的彩票。一旦需要做出一项调度决策时，就随机抽出一张彩票，拥有该彩票的进程获得该资源。 彩票调度具有若干有趣的性质。例如，如果有一个新的进程出现并得到一些彩票，那么在下一次的抽奖中，该进程会有同它持有彩票数量成比例的机会赢得奖励。换句话说，彩票调度是反应迅速的。 公平分享调度 到现在为止，我们假设被调度的都是各个进程自身，并不关注其所有者是谁。这样做的结果是，如果用户1启动9个进程而用户2启动1个进程，使用轮转或相同优先级调度算法，那么用户1将得到90%的CPU时间，而用户2只得到10%的CPU时间。 为了避免这种情形，某些系统在调度处理之前考虑谁拥有进程这一因素。在这种模式中，每个用户分配到CPU时间的一部分，而调度程序以一种强制的方式选择进程。这样，如果两个用户都得到获得50%CPU时间的保证，那么无论一个用户有多少进程存在，每个用户都会得到应有的CPU份额。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:3","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"实时系统中的调度 实时系统是一种时间起着主导作用的系统。典型地，外部的一种或多种物理设备给了计算机一个刺激，而计算机必须在一个确定的时间范围内恰当地做出反应。 实时系统通常可以分为硬实时（hard real time）和软实时（soft real time），前者的含义是必须满足绝对的截止时间，后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。 在这两种情形中，实时性能都是通过把程序划分为一组进程而实现的，其中每个进程的行为是可预测和提前掌握的。这些进程一般寿命较短，并且极快地就运行完成。在检测到一个外部信号时，调度程序的任务就是按照满足所有截止时间的要求调度进程。 实时系统中的事件可以按照响应方式进一步分类为周期性（以规则的时间间隔发生）事件或非周期性（发生时间不可预知）事件。 一个系统可能要响应多个周期性事件流。根据每个事件需要处理时间的长短，系统甚至有可能无法处理完所有的事件。例如，如果有m个周期事件，事件i以周期Pi 发生，并需要Ci 秒CPU时间处理一个事件，那么可以处理负载的条件是 满足这个条件的实时系统称为是可调度的。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:4","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"策略和机制 以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。 解决问题的方法是将调度机制（scheduling mechanism）与调度策略（scheduling policy）分离（著名的原则，Levin等人，1975），也就是将调度算法以某种形式参数化，而参数可以由用户进程填写。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:5","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"线程调度 当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。 首先考虑用户级线程。由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为A，并给予A以时间片控制。A中的线程调度程序决定哪个线程运行，假设为A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。在进程A终于又一次运行时，线程A1会接着运行。该线程会继续耗费A进程的所有时间，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程A内部所发生的事。 惟一的局限是，缺乏一个时钟将运行过长的线程加以中断。 现在考虑A线程每次CPU计算的工作比较少的情况，例如，在50ms的时间片中有5ms的计算工作。于是，每个线程运行一会儿，然后把CPU交回给线程调度程序。这样在内核切换到进程B之前，就会有序列A1，A2，A3，A1，A2，A3，A1，A2，A3，A1 现在考虑使用内核级线程的情形。内核选择一个特定的线程运行。它不用考虑该线程属于哪个进程，不过如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在50ms的时间片内，5ms之后被阻塞，在30ms的时间段中，线程的顺序会是A1，B1，A2，B2，A3，B3 用户级线程和内核级线程之间的差别在于性能。 用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:6","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"IPC问题 哲学家就餐问题 有 5 个哲学家，他们面前都有一双筷子，即左手有一根筷子，右手有一根筷子。当然，这个问题有多个版本的描述，可以说是筷子，也可以说是一刀一叉，因为吃牛排的时候，需要刀和叉，缺一不可，也有说是用两把叉子来吃意大利面。这里具体是刀叉还是筷子并不重要，重要的是必须要同时持有左右两边的两个才行，也就是说，哲学家左手要拿到一根筷子，右手也要拿到一根筷子，在这种情况下哲学家才能吃饭。 读者-写者问题 例如，设想一个飞机订票系统，其中有许多竞争的进程试图读写其中的数据。多个进程同时读数据库是可以接受的，但如果一个进程正在更新（写）数据库，则所有的其他进程都不能访问该数据库，即使读操作也不行。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:7","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"小结 为了隐蔽中断的影响，操作系统提供了一个由并行运行的顺序进程组成的概念模型。进程可以动态地创建和终止。每个进程都有自己的地址空间。 对于某些应用而言，在一个进程中使用多个控制线程是有益的。这些线程被独立调度，每个线程有自己的堆栈，但是在一个进程中的所有线程共享一个公共地址空间。线程可以在用户空间或内核中实现。 进程之间通过进程间通信原语彼此通信，如信号量、管程或消息。这些原语用来确保同一时刻不会有两个进程在临界区中，免除了出现混乱的情形。进程可以处在运行、可运行或阻塞状态，并且在该进程或其他进程执行某个进程间通信原语时，可以改变其状态。线程间通信也是类似的。 进程间通信原语可以用来解决诸如生产者-消费者问题、哲学家就餐问题和读者-写者问题等。即便有了这些原语，也要仔细设计以避免出错和死锁。 已经有一大批研究出来的调度算法。某些算法主要用于批处理系统中，如最短作业优先调度算法。其他算法常用在批处理系统和交互式系统中，它们包括轮转调度、优先级调度、多级队列、保证调度、彩票调度以及公平分享调度等。有些系统将调度策略和调度机制清晰地分离，这样可以使用户对调度算法进行控制。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:8","tags":["操作系统"],"title":"操作系统-进程与线程调度算法","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"进程间通信 简要地说，有三个问题。 第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。 第二个要处理的问题是，确保两个或更多的进程在关键活动中不会出现交叉，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。 第三个问题与正确的顺序有关（如果该顺序是有关联的话），比如，如果进程A产生数据而进程B打印数据，那么B在打印之前必须等待，直到A已经产生一些数据。我们将从下一节开始考察所有这三个问题。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:0","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"竞争条件 即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为竞争条件（race condition） 在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中（可能是在内核数据结构中），也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。 怎样避免竞争条件？实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。 换言之，我们需要的是互斥（mutual exclusion），即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:1","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"临界区 我们把对共享内存进行访问的程序片段称作临界区域（critical region）或临界区（critical section） 对于一个好的解决方案，需要满足以下4个条件： 任何两个进程不能同时处于其临界区。 不应对CPU的速度和数量做任何假设。 临界区外运行的进程不得阻塞其他进程。 不得使进程无限期等待进入临界区。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:2","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"忙等待的互斥 屏蔽中断 意义 在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介入。 缺陷 把屏蔽中断的权力交给用户进程是不明智的。设想一下，若一个进程屏蔽中断后不再打开中断，其结果将会如何？整个系统可能会因此终止。而且，如果系统是多处理器（有两个或可能更多的处理器），则屏蔽中断仅仅对执行disable指令的那个CPU有效。其他CPU仍将继续运行，并可以访问共享内存。屏蔽一个CPU的中断不会阻止其他CPU干预第一个CPU所做的操作。结果是人们需要更加复杂的计划。 所以结论是：屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。 锁变量 意义 设想有一个共享（锁）变量，其初始值为0。当一个进程想进入其临界区时，它首先测试这把锁。如果该锁的值为0，则该进程将其设置为1并进入临界区。若这把锁的值已经为1，则该进程将等待直到其值变为0。于是，0就表示临界区内没有进程，1表示已经有某个进程进入临界区。 缺陷 这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为0，而恰好在它将其值设置为1之前，另一个进程被调度运行，将该锁变量设置为1。当第一个进程再次能运行时，它同样也将该锁设置为1，则此时同时有两个进程进入临界区中。同样还会发生竞争条件。 严格轮换法 整型变量turn，初始值为0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程0检查turn，发现其值为0，于是进入临界区。进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。连续测试一个变量直到某个值出现为止，称为忙等待（busy waiting）。由于这种方式浪费CPU时间，所以通常应该避免。 只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为自旋锁（spin lock）。 进程0离开临界区时，它将turn的值设置为1，以便允许进程1进入其临界区。假设进程1很快便离开了临界区，则此时两个进程都处于临界区之外，turn的值又被设置为0。现在进程0很快就执行完其整个循环，它退出临界区，并将turn的值设置为1。此时，turn的值为1，两个进程都在其临界区外执行。 突然，进程0结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为turn的当前值为1，而此时进程1还在忙于非临界区的操作，进程0只有继续while循环，直到进程1把turn的值改为0。这说明，在一个进程比另一个慢了很多的情况下，轮流进入临界区并不是一个好办法。 尽管该算法的确避免了所有的竞争条件，但由于它违反了条件3，所以不能作为一个很好的备选方案。 Peterson解法 在使用共享变量（即进入其临界区）之前，各个进程使用其进程号0或1作为参数来调用enter_region。该调用在需要时将使进程等待，直到能安全地进入临界区。在完成对共享变量的操作之后，进程将调用leave_region，表示操作已完成，若其他的进程希望进入临界区，则现在就可以进入。 一开始，没有任何进程处于临界区中，现在进程0调用enter_region。它通过设置其数组元素和将turn置为0来标识它希望进入临界区。由于进程1并不想进入临界区，所以enter_region很快便返回。如果进程1现在调用enter_region，进程1将在此处挂起直到interested[0]变成FALSE，该事件只有在进程0调用leave_region退出临界区时才会发生。 现在考虑两个进程几乎同时调用enter_region的情况。它们都将自己的进程号存入turn，但只有后被保存进去的进程号才有效，前一个因被重写而丢失。假设进程1是后存入的，则turn为1。当两个进程都运行到while语句时，进程0将循环0次并进入临界区，而进程1则将不停地循环且不能进入临界区，直到进程0退出临界区为止。 TSL指令 TSL RX,LOCK 称为测试并加锁（Test and Set Lock），它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行TSL指令的CPU将锁住内存总线，以禁止其他CPU在本指令结束之前访问内存。 注意 锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器1上屏蔽中断对处理器2根本没有任何影响。让处理器2远离内存直到处理器1完成的惟一方法就是锁住总线，这需要一个特殊的硬件设施（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用）。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:3","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"睡眠与唤醒 Peterson解法和TSL或XCHG解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的：当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。 考虑一台计算机有两个进程，H优先级较高，L优先级较低。调度规则规定，只要H处于就绪态它就可以运行。在某一时刻，L处于临界区中，此时H变到就绪态，准备运行（例如，一条I/O操作结束）。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。这种情况有时被称作优先级反转问题（priority inversion problem）。 生产者-消费者（producer-consumer）问题，也称作有界缓冲区（bounded-buffer）问题。 两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者，将信息放入缓冲区；另一个是消费者，从缓冲区中取出信息。（也可以把这个问题一般化为m个生产者和n个消费者问题，但是我们只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。） 问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。 这个方法听起来很简单，但它包含与前边假脱机目录问题一样的竞争条件。为了跟踪缓冲区中的数据项数，我们需要一个变量count。 如果缓冲区最多存放N个数据项，则生产者代码将首先检查count是否达到N，若是，则生产者睡眠；否则生产者向缓冲区中放入一个数据项并增量count的值。消费者的代码与此类似：首先测试count是否为0，若是，则睡眠；否则从中取走一个数据项并递减count的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。 现在回到竞争条件的问题。这里有可能会出现竞争条件，其原因是对count的访问未加限制。有可能出现以下情况：缓冲区为空，消费者刚刚读取count的值发现它为0。此时调度程序决定暂停消费者并启动运行生产者。生产者向缓冲区中加入一个数据项，count加1。现在count的值变成了1。它推断认为由于count刚才为0，所以消费者此时一定在睡眠，于是生产者调用wakeup来唤醒消费者。但是，消费者此时在逻辑上并未睡眠，所以wakeup信号丢失。当消费者下次运行时，它将测试先前读到的count值，发现它为0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。 问题的实质在于发给一个（尚）未睡眠进程的wakeup信号丢失了。如果它没有丢失，则一切都很正常。 一种快速的弥补方法是修改规则，加上一个唤醒等待位。当一个wakeup信号发送给一个清醒的进程信号时，将该位置1。随后，当该进程要睡眠时，如果唤醒等待位为1，则将该位清除，而该进程仍然保持清醒。唤醒等待位实际上就是wakeup信号的一个小仓库。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:4","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"信号量 信号量是E.W.Dijkstra在1965年提出的一种方法，它使用一个整型变量来累计唤醒次数，供以后使用。在他的建议中引入了一个新的变量类型，称作信号量（semaphore）。一个信号量的取值可以为0（表示没有保存下来的唤醒操作）或者为正值（表示有一个或多个唤醒操作）。 检查数值、修改变量值以及可能发生的睡眠操作均作为一个单一的、不可分割的原子操作完成。保证一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。 所谓原子操作，是指一组相关联的操作要么都不间断地执行，要么都不执行。原子操作在计算机科学的其他领域也是非常重要的。 读者必须搞清楚，使用TSL或XCHG指令来防止几个CPU同时访问一个信号量，这与生产者或消费者使用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量操作仅需几个毫秒，而生产者或消费者则可能需要任意长的时间。 信号量的另一种用途是用于实现同步（synchronization）。信号量full和empty用来保证某种事件的顺序发生或不发生。在本例中，它们保证当缓冲区满的时候生产者停止运行，以及当缓冲区空的时候消费者停止运行。这种用法与互斥是不同的。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:5","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"互斥量 如果不需要信号量的计数能力，有时可以使用信号量的一个简化版本，称为互斥量（mutex）。互斥量仅仅适用于管理共享资源或一小段代码。由于互斥量在实现时既容易又有效，这使得互斥量在实现用户空间线程包时非常有用。 互斥量是一个可以处于两态之一的变量：解锁和加锁。这样，只需要一个二进制位表示它，不过实际上，常常使用一个整型量，0表示解锁，而其他所有的值则表示加锁。互斥量使用两个过程。当一个线程（或进程）需要访问临界区时，它调用mutex_lock。如果该互斥量当前是解锁的（即临界区可用），此调用成功，调用线程可以自由进入该临界区。 另一方面，如果该互斥量已经加锁，调用线程被阻塞，直到在临界区中的线程完成并调用mutex_unlock。如果多个线程被阻塞在该互斥量上，将随机选择一个线程并允许它获得锁。 Pthread中的互斥 Pthread提供许多可以用来同步线程的函数。其基本机制是使用一个可以被锁定和解锁的互斥量来保护每个临界区。 除互斥量之外，pthread提供了另一种同步机制：条件变量。互斥量在允许或阻塞对临界区的访问上是很有用的，条件变量则允许线程由于一些未达到的条件而阻塞。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:6","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"管道 为了更易于编写正确的程序，Brinch Hansen（1973）和Hoare（1974）提出了一种高级同步原语，称为管程（monitor） 管道有一个很重要的特性，即任一时刻管道中只能有一个活跃进程，这一特性使管道能有效地完成互斥。管道是编程语言的组成部分，编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管道的调用。 进入管程时的互斥由编译器负责，但通常的做法是用一个互斥量或二元信号量。因为是由编译器而非程序员来安排互斥，所以出错的可能性要小得多。在任一时刻，写管程的人无须关心编译器是如何实现互斥的。他只需知道将所有的临界区转换成管程过程即可，决不会有两个进程同时执行临界区中的代码。 与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问公共内存的一个或多个CPU上的互斥问题的。通过将信号量放在共享内存中并用TSL或XCHG指令来保护它们，可以避免竞争。 如果一个分布式系统具有多个CPU，并且每个CPU拥有自己的私有内存，它们通过一个局域网相连，那么这些原语将失效。这里的结论是：信号量太低级了，而管程在少数几种编程语言之外又无法使用，并且，这些原语均未提供机器间的信息交换方法。所以还需要其他的方法。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:7","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"消息传递 。这种进程间通信的方法使用两条原语send和receive，它们像信号量而不像管程，是系统调用而不是语言成分。因此，可以很容易地将它们加入到库例程中去。例如：send(destination,＆message);receive(source,＆message); 前一个调用向一个给定的目标发送一条消息，后一个调用从一个给定的源（或者是任意源，如果接收者不介意的话）接收一条消息。如果没有消息可用，则接收者可能被阻塞，直到一条消息到达，或者，带着一个错误码立即返回。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:8","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"屏障 最后一个同步机制是准备用于进程组而不是用于双进程的生产者-消费者类情形的。在有些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段。可以通过在每个阶段的结尾安置屏障（barrier）来实现这种行为。当一个进程到达屏障时，它就被屏障阻拦，直到所有进程都到达该屏障为止。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:9","tags":["操作系统"],"title":"操作系统-进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"进程与线程～线程篇 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:0","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"线程的使用 必要性 并行实体共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型（它们具有不同地址空间）所无法表达的。 由于线程比进程更轻量级，所以它们比进程更容易（即更快）创建，也更容易撤销。 若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:1","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"经典的线程模型 概念的差异 理解进程的一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的报警、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。 另一个概念是，进程拥有一个执行的线程，通常简写为线程（thread）。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体。 线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。 在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为轻量级进程（lightweight process）。 通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象。多线程的工作方式也是类似的。CPU在线程之间的快速切换，制造了线程并行运行的假象，好似它们在一个比实际CPU慢一些的CPU上同时运行。在一个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个CPU上得到了真实CPU速度的三分之一。 进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。 线程之间是没有保护的，原因是: 不可能 也没有必要 这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。 线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作。 和传统进程一样（即只有一个线程的进程），线程可以处于若干种状态的任何一个：运行、阻塞、就绪或终止。线程状态之间的转换和进程状态之间的转换是一样的 认识到每个线程有其自己的堆栈很重要、通常每个线程会调用不同的过程，从而有一个各自不同的执行历史。这就是为什么每个线程需要有自己的堆栈的原因 在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数（如thread_create）创建新的线程。thread_create的参数专门指定了新线程要运行的过程名。这里，没有必要对新线程的地址空间加以规定，因为新线程会自动在创建线程的地址空间中运行。有时，线程是有层次的，它们具有一种父子关系，但是，通常不存在这样一种关系，所有的线程都是平等的。不论有无层次关系，创建线程通常都返回一个线程标识符，该标识符就是新线程的名字。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:2","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"在用户空间中实现线程 有两种主要的方法实现线程包：在用户空间中和在内核中。这两种方法互有利弊，不过混合实现方式也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。 第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。这种方法第一个，也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。 在用户空间管理线程时，每个进程需要有其专用的线程表（thread table），用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。 线程与进程有一个关键的差别。在线程完成运行时，例如，在它调用thread_yield时，pthread_yield代码可以把该线程的信息保存在线程表中、进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。 用户级线程还有另一个优点。它允许每个进程有自己定制的调度算法。 例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题。 尽管用户级线程包有更好的性能，但它也存在一些明显的问题。 其中第一个问题是如何实现阻塞系统调用。 假设在还没有任何击键之前，一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。有了阻塞系统调用，这个目标不是轻易地能够实现的。 系统调用可以全部改成非阻塞的（例如，如果没有被缓冲的字符，对键盘的read操作可以只返回0字节），但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变read操作的语义需要修改许多用户程序。 在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些UNIX版本中，有一个系统调用select可以允许调用者通知预期的read是否会阻塞。若有这个调用，那么库过程read就可以被新的操作替代，首先进行select调用，然后只有在安全的情形下（即不会阻塞）才进行read调用。如果read调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为包装器（jacket或wrapper）。 页面故障问题 此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令（和该指令的“邻居们”），这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘I/O完成为止，尽管其他的线程是可以运行的。 用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU。 在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度（轮流）的方式调度进程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。对线程永久运行问题的一个可能的解决方案是让运行时系统请求每秒一次的时钟信号（中断），但是这样对程序也是生硬和无序的。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。 在经常发生线程阻塞的应用中才希望使用多个线程。例如，在多线程Web服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行select系统调用，以便检查read系统调用是否安全。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢？这样的做法并不能得到任何益处。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:3","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"在内核中实现线程 内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中（在运行时系统中）的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息（即进程状态）的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。 所有能够阻塞线程的调用都以系统调用的形式实现，这与运行时系统过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程（若有一个就绪线程）或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU（或者没有可运行的线程存在了）为止。 由于在内核中创建或撤销线程的代价比较大，某些系统采取“环保”的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。 在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。 内核线程不需要任何新的、非阻塞系统调用。 如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:4","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"混合实现 使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来、采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。 内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。如同在没有多线程能力操作系统中某个进程中的用户级线程一样，可以创建、撤销和调度这些用户级线程。在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:5","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"调度程序激活机制 调度程序激活机制的一个目标是作为上行调用的信赖基础，这是一种违反分层次系统内在结构的概念。通常，n层提供n+1层可调用的特定服务，但是n层不能调用n+1层中的过程。上行调用并不遵守这个基本原理。 使该机制工作的基本思路是，当内核了解到一个线程被阻塞之后（例如，由于执行了一个阻塞系统调用或者产生了一个页面故障），内核通知该进程的运行时系统，并且在堆栈中以参数形式传递有问题的线程编号和所发生事件的一个描述。内核通过在一个已知的起始地址启动运行时系统，从而发出了通知，这是对UNIX中信号的一种粗略模拟。这个机制称为上行调用upcall 一旦如此激活，运行时系统就重新调度其线程，这个过程通常是这样的：把当前线程标记为阻塞并从就绪表中取出另一个线程，设置其寄存器，然后再启动之。稍后，当内核知道原来的线程又可运行时（例如，原先试图读取的管道中有了数据，或者已经从磁盘中读入了故障的页面），内核就又一次上行调用运行时系统，通知它这一事件。此时该运行时系统按照自己的判断，或者立即重启动被阻塞的线程，或者把它放入就绪表中稍后运行。 在某个用户线程运行的同时发生一个硬件中断时，被中断的CPU切换进核心态。如果被中断的进程对引起该中断的事件不感兴趣，比如，是另一个进程的I/O完成了，那么在中断处理程序结束之后，就把被中断的线程恢复到中断之前的状态。不过，如果该进程对中断感兴趣，比如，是该进程中的某个线程所需要的页面到达了，那么被中断的线程就不再启动，代之为挂起被中断的线程。而运行时系统则启动对应的虚拟CPU，此时被中断线程的状态保存在堆栈中。随后，运行时系统决定在该CPU上调度哪个线程：被中断的线程、新就绪的线程还是某个第三种选择。 调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。避免了在用户空间和内核空间之间的不必要转换、例如，如果某个线程由于等待另一个线程的工作而阻塞，此时没有理由请求内核，这样就减少了内核-用户转换的开销。用户空间的运行时系统可以阻塞同步的线程而另外调度一个新线程。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:6","tags":["操作系统"],"title":"操作系统-线程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-20","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/","tags":["操作系统"],"title":"操作系统-进程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"进程与线程～进程篇 ","date":"2021-03-20","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/:1:0","tags":["操作系统"],"title":"操作系统-进程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"进程 进程模型 一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟CPU。 在一台多道程序计算机的内存中有4道程序。在图2-1b中，这4道程序被抽象为4个各自拥有自己控制流程（即每个程序自己的逻辑程序计数器）的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束（或暂停执行）时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中 在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。 一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。 创建进程 有4种主要事件导致进程的创建： 系统初始化。 启动操作系统时，通常会创建若干个进程。 执行了正在运行的进程所调用的进程创建系统调用。 除了在启动阶段创建进程之外，新的进程也可以以后创建。一个正在运行的进程经常发出系统调用，以便创建一个或多个新进程协助其工作。 用户请求创建一个新进程。 在交互式系统中，键入一个命令或者点（双）击一个图标就可以启动一个程序。在基于命令行的UNIX系统中运行程序X，新的进程会从该进程接管开启它的窗口。 一个批处理作业的初始化。 最后一种创建进程的情形仅在大型机的批处理系统中应用。用户在这种系统中（可能是远程地）提交批处理作业。在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。 在UNIX和Windows中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在UNIX中，子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间。 停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为守护进程（daemon） 进程的终止 正常退出（自愿的） 多数进程是由于完成了它们的工作而终止。当编译器完成了所给定程序的编译之后，编译器执行一个系统调用，通知操作系统它的工作已经完成。在UNIX中该调用是exit，而在Windows中，相关的调用是ExitProcess。 出错退出（自愿的） 进程终止的第二个原因是进程发现了严重错误。例如，如果用户键入命令cc foo.c、要编译程序foo.c，但是该文件并不存在，于是编译器就会退出。 严重错误（非自愿） 进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引用不存在的内存，或除数是零等。有些系统中（如UNIX），进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号（被中断），而不是在这类错误出现时终止。 被其他进程杀死（非自愿） 第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在UNIX中，这个系统调用是kill。在Win32中对应的函数是TerminateProcess。在这两种情形中，“杀手”都必须获得确定的授权以便进行动作。 进程的层次结构 某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。进程只有一个父进程（但是可以有零个、一个、两个或多个子进程）。 在UNIX中，进程和它的所有子女以及后裔共同组成一个进程组。 当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号杀死。 这里有另一个例子，可以用来说明进程层次的作用，考虑UNIX在启动时如何初始化自己。一个称为init的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一个用户登录成功，该登录进程就执行一个shell准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以init为根的一棵树。 相反，Windows中没有进程层次的概念，所有的进程都是地位相同的。惟一类似于进程层次的暗示是在创建进程的时侯，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。但是，它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在UNIX中，进程就不能剥夺其子女的“继承权”。 进程的状态 运行态（该时刻进程实际占用CPU） 就绪态（可运行，但因为其他进程正在运行而暂时停止） 阻塞态（除非某种外部事件发生，否则进程不能运行） 在操作系统发现进程不能继续运行下去时，发生转换1。转换2和3是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用CPU时间时，会发生转换2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用CPU运行时，会发生转换3。当进程等待的一个外部事件发生时（如一些输入到达），则发生转换4 从这个观点引出了所示的模型、操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。 进程的实现 **为了实现进程模型，操作系统维护着一张表格（一个结构数组），即进程表（process table）。**每个进程占用一个进程表项。（有些作者称这些表项为进程控制块。）该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。 第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。 在了解进程表后，就可以对在单个（或每一个）CPU上如何维持多个顺序进程的错觉做更多的阐述。与每一I/O类关联的是一个称作中断向量（interrupt vector）的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程3正在运行，则中断硬件将程序计数器、程序状态字，有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。 所有的中断都从保存寄存器开始，对于当前进程而言，通常是在进程表项中。随后，会从堆栈中删除由中断硬件机制存入堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用C语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。 当该例程结束后，它调用一个C过程处理某个特定的中断类型剩下的工作。（假定操作系统由C语言编写，通常这是所有真实操作系统的选择）。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行。图2-5中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。 多道程序设计模型 采用多道程序设计可以提高CPU的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的20%，且内存中同时有5个进程，则CPU将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这5个进程不会同时等待I/O。 更好的模型是从概率的角度来看CPU的利用率。假设一个进程等待I/O操作的时间与其停留在内存中时间的比为p。当内存中同时有n个进程时，则所有n个进程都在等待I/O（此时CPU空转）的概率是pn 。CPU的利用率由下面的公式给出：CPU利用率=1-p^n 从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它假设所有n个进程是独立的，即内存中的5个进程中，3个运行，2个等待，是完全可接受的。但在单CPU中，不能同时运行3个进程，所以当CPU忙时，已就绪的进程也必须等待CPU。因而，进程不是独立的。更精确的模型应该用排队论构造，但我们的模型（当进程就绪时，给进程分配CPU，否则让CPU空转）仍然是有效的 ","date":"2021-03-20","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/:1:1","tags":["操作系统"],"title":"操作系统-进程","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-17","objectID":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/","tags":["操作系统"],"title":"操作系统结构与层次","uri":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"},{"categories":["操作系统"],"content":"操作系统结构 这六种设计是，单体系统、层次系统、微内核、客户机-服务器系统、虚拟机和exokernels等 单体系统 需要一个主程序，用来处理服务过程请求。 需要一套服务过程，用来执行系统调用。 需要一套实用过程，用来辅助服务过程。 每一个系统调用都通过一个服务过程为其工作并运行之。要有一组实用程序来完成一些服务过程所需要用到的功能，如从用户程序取数据等。可将各种过程划分为一个三层的模型 进一步通用化，就变成一个层次式结构的操作系统，它的上层软件都是在下一层软件的基础之上构建的。 层次式系统 内存管理在第1层中进行，它分配进程的主存空间，当内存用完时则在一个512K字的磁鼓上保留进程的一部分（页面）。在第1层上，进程不用考虑它是在磁鼓上还是在内存中运行。第1层软件保证一旦需要访问某一页面时，该页面必定已在内存中。第2层处理进程与操作员控制台（即用户）之间的通信。在这层的上部，可以认为每个进程都有自己的操作员控制台。第3层管理I/O设备和相关的信息流缓冲区。在第3层上，每个进程都与有良好特性的抽象I/O设备打交道，而不必考虑外部设备的物理细节。第4层是用户程序层。用户程序不用考虑进程、内存、控制台或I/O设备管理等细节。系统操作员进程位于第5层中。 在分层方式中，设计者要确定在哪里划分内核-用户的边界。在传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能的做法更好，因为内核中的错误会快速拖累系统。 微内核 微内核设计背后的思想是，为了实现高可靠性，将操作系统划分成小的、良好定义的模块，只有其中一个模块——微内核——运行在内核态上，其余的模块，由于功能相对弱些，则作为普通用户进程运行。这些模块中的错误虽然会使这些模块崩溃，但是不会使得整个系统死机。 在内核的外部，系统的构造有三层进程，它们都在用户态中运行。最底层中包含设备驱动器。由于它们在用户态中运行，所以不能物理地访问I/O端口空间，也不能直接发出I/O命令。相反，为了能够对I/O设备编程，驱动器构建了一个结构，指明哪个参数值写到哪个I/O端口，并生成一个内核调用，通知内核完成写操作。这个处理意味着内核可以检查驱动正在对I/O的读（或写）是否是得到授权使用的。这样，（与单体设计不同），一个有错误的操作就不能够偶发性地在硬盘上进行写操作。 系统对每个进程的权限有着许多限制。正如已经提及的，设备驱动器只能与授权的I/O端口接触，对内核调用的访问也是按单个进程进行控制的，是考虑到进程具有向其他多个进程发送消息的能力。进程也可获得有限的许可，让在内核的其他进程访问其地址空间。 一个与小内核相关联的思想是在内核中的机制与策略分离的原则。 客户机-服务器模式 一个微内核思想的略微变体是将进程划分为两类：服务器，每个服务器提供某种服务；客户端，使用这些服务。这个模式就是所谓的客户机-服务器模式。通常，在系统最底层是微内核，但并不是必须这样的。这个模式的本质是存在客户端进程和服务器进程。 这个思想的一个显然的、普遍方式是，客户端和服务器运行在不同的计算机上，它们通过局域或广域网连接，由于客户端通过发送消息与服务器通信，客户端并不需要知道这些消息是在它们的本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。所以，客户机-服务器模式是一种可以应用在单机或者网络机器上的抽象。 虚拟机 这个系统最初被命名为CP/CMS，后来改名为VM/370（Seawright和MacKinnon，1979）。它是源于如下一种机敏的观察。分时系统应该提供这些功能：（1）多道程序，（2）一个比裸机更方便的、有扩展界面的计算机。VM/370存在的目的是将二者彻底地隔离开来。 这个系统的核心称为虚拟机监控程序（virtual machine monitor），它在裸机上运行并且具备了多道程序功能。该系统向上层提供了若干台虚拟机，它不同于其他操作系统的地方是：这些虚拟机不是那种具有文件等优良特征的扩展计算机。与之相反，它们仅仅是裸机硬件的精确复制品。这个复制品包含了内核态/用户态、I/O功能、中断及其他真实硬件所应该具有的全部内容。 外核 在底层中，一种称为外核（exokernel，Engler等人，1995）的程序在内核态中运行。它的任务是为虚拟机分配资源，并检查试图使用这些资源的企图，以确保没有机器会使用他人的资源。每个用户层的虚拟机可以运行自己的操作系统，如VM/370和Pentium虚拟8086等，但限制在只能使用已经申请并且获得分配的那部分资源。 外核机制的优点是，它减少了映像层。在其他的设计中，每个虚拟机都认为它有自己的磁盘，其盘块号从0到最大编号，这样虚拟机监控程序必须维护一张表格用以重映像磁盘地址（以及其他资源）。有了外核这个重映像处理就不需要了。外核只需要记录已经分配给各个虚拟机的有关资源即可。这个方法还有一个优点，它将多道程序（在外核内）与用户操作系统代码（在用户空间内）加以分离，而且相应负载并不重，这是因为外核所做的一切，只是保持多个虚拟机彼此不发生冲突。 与虚拟机克隆真实机器不同，另一种策略是对机器进行分区，换句话说，给每个用户整个资源的一个子集。 参考书籍：现代操作系统（原书第4版）_Modern Operating Systems (4th Edition) ([荷] Andrew S. Tanenbaum [荷] Herbert Bos) ","date":"2021-03-17","objectID":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/:0:1","tags":["操作系统"],"title":"操作系统结构与层次","uri":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"},{"categories":["操作系统"],"content":"霞诗子のblog","date":"2021-03-04","objectID":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/","tags":["操作系统"],"title":"现代操作系统","uri":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["操作系统"],"content":"现代操作系统概念 进程 进程本质上是正在执行的一个程序。 与每个进程相关的是进程的地址空间（address space），这是从某个最小值的存储位置（通常是零）到某个最大值存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器（含有程序计数器和堆栈指针）、打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是容纳运行一个程序所需要所有信息的容器。 若一个进程能够创建一个或多个进程（称为子进程），而且这些进程又可以创建子进程，则很容易得到进程树,合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为进程间通信（interprocess communication） 可用的进程系统调用包括：申请更多的内存（或释放不再需要的内存）、等待一个子进程结束、用另一个程序覆盖该程序等。 系统管理器授权每个进程使用一个给定的UID标识（User IDentification）。每个被启动的进程都有一个启动该进程的用户UID。子进程拥有与父进程一样的UID。用户可以是某个组的成员，每个组也有一个GID标识（Group IDentification）。 地址空间 较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们彼此互相干扰（包括操作系统），需要有某种保护机制。虽然这种机制必然是硬件形式的，但是它由操作系统掌控。上述的观点涉及对计算机主存的管理和保护。 另一种不同的但是同样重要并与存储器有关的内容，是管理进程的地址空间。通常，每个进程有一些可以使用的地址集合，典型值从0开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程。 文件 为了提供保存文件的地方，大多数操作系统支持目录（directory）的概念，从而可把文件分类成组。 进程和文件层次都可以组织成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。 管道。管道（pipe）是一种虚文件，它可连接两个进程，如图1-16所示。如果进程A和B希望通过管道对话，它们必须提前设置该管道。当进程A想对进程B发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据，仿佛该管道就是一个输入文件一样。这样，在UNIX中两个进程之间的通信就很类似于普通文件的读写了。 输入输出 所有的计算机都有用来获取输入和产生输出的物理设备。有各种类型的输入和输出设备，包括键盘、显示器、打印机等。对这些设备的管理全然依靠操作系统。 所以，每个操作系统都有管理其I/O设备的I/O子系统。某些I/O软件是设备独立的，即这些I/O软件部分可以同样应用于许多或者全部的I/O设备上。I/O软件的其他部分，如设备驱动程序，是专门为特定的I/O设备设计的 保护 计算机中有大量的信息，用户经常希望对其进行保护，并保守秘密。这些信息可包括电子邮件、商业计划、退税等诸多内容。管理系统的安全性完全依靠操作系统 参考UNIX。UNIX操作系统通过对每个文件赋予一个9位的二进制保护代码，对UNIX中的文件实现保护。该保护代码有三个3位字段，一个用于所有者，一个用于所有者同组（用户被系统管理员划分成组）中的其他成员，而另一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是知名的rwx位。 shell 操作系统是进行系统调用的代码 shell本身不是操作系统的一部分，但它体现了许多操作系统的特性，并很好地说明了系统调用的具体用法。shell同时也是终端用户与操作系统之间的界面，除非用户使用的是一个图形用户界面。有许多种类的shell，如sh、csh、ksh以及bash等 个体重复系统发育 大型内存 保护硬件 硬盘 虚拟内存 参考书籍：现代操作系统（原书第4版）_Modern Operating Systems (4th Edition) ([荷] Andrew S. Tanenbaum [荷] Herbert Bos) ","date":"2021-03-04","objectID":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:0:1","tags":["操作系统"],"title":"现代操作系统","uri":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["network"],"content":"霞诗子のblog","date":"2019-12-04","objectID":"/posts/thinking/wireshark_use/","tags":["network","wireshark"],"title":"Wireshark抓包工具分析","uri":"/posts/thinking/wireshark_use/"},{"categories":["network"],"content":"Wireshark的使用与常见错误 wireshark的主要作用是为了诊断网络出现的问题，大致上比较重要的部分是过滤器与结果的表达，这两点是比较重要的，比如在过滤器中对协议进行选择，排除无关协议的影响，比如结果的如何呈现会更加直观，对tcp来讲，选择tcp流形图会不会比流量图更好。 以下是一张wireshark主界面图： 注意，本机系统为archlinux,启动时要使用管理员身份。 ","date":"2019-12-04","objectID":"/posts/thinking/wireshark_use/:1:0","tags":["network","wireshark"],"title":"Wireshark抓包工具分析","uri":"/posts/thinking/wireshark_use/"},{"categories":["network"],"content":"过滤器 协议过滤 例如：ARP(ip转mac协议) 注意不区分大小写 协议参数过滤 例如这里选择了IPv4协议，对源地址进行了筛选ip.src_host 连接词的使用 类同于C语言，\u0026\u0026(与)，||(或)， !(非)，除此之外，还有and,or之类，与前一致。 ! 的使用 \u0026\u0026的使用 注意连接词可以同时使用 ","date":"2019-12-04","objectID":"/posts/thinking/wireshark_use/:1:1","tags":["network","wireshark"],"title":"Wireshark抓包工具分析","uri":"/posts/thinking/wireshark_use/"},{"categories":["network"],"content":"结果输出 ip.src_host == 43.129.76.227 \u0026\u0026 ip.dst_host == 192.168.88.153主机之间的流量图 ip.src_host == 43.129.76.227 \u0026\u0026 ip.dst_host == 192.168.88.153 主机之间的通信，数据包流量图如图所示。 注意：捕获选项中的混杂器选项代表了主机是否丢弃非目的地址的包，可以打开此选项以此来查看子网流通性或关闭此选项来减少捕获包的数量，从而减少分析难度 ","date":"2019-12-04","objectID":"/posts/thinking/wireshark_use/:1:2","tags":["network","wireshark"],"title":"Wireshark抓包工具分析","uri":"/posts/thinking/wireshark_use/"},{"categories":["Code","C"],"content":"霞诗子のblog","date":"2019-06-04","objectID":"/posts/coding/c_point/","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["Code","C"],"content":"指针与多级指针 什么是指针？指针是变量，确切的讲是储存地址的一种变量，全称应当是指针变量而非指针，以下是定义整形指针变量的代码。 #include\u003cstdio.h\u003e int main() { int *p = NULL; int m = 10; int *q = \u0026m; p = \u0026m; printf(\"%d %d\\n\",*q,*p);//p与q地址相同 return 0;//此时指针p q等效 } ","date":"2019-06-04","objectID":"/posts/coding/c_point/:1:0","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["Code","C"],"content":"一级指针 一级指针是指指向某个变量并储存其地址的指针变量，或者是它本身就是地址，指针和地址其实是同样的意思。 注意指针本身就是一种变量，它本身也开辟了一块空间来存储它本身，指针变量本身也有地址，这就引出了多级指针，在外文中没有多级指针的说法，取而代之的则是pointer to pointer。 一级指针的定义 #include\u003cstdio.h\u003e int *p = NULL; int m = 10; p = \u0026m;//指针变量取得是地址，所以要加上取地址符 printf(\"%d\\n\",*p);//10 return 0; ","date":"2019-06-04","objectID":"/posts/coding/c_point/:1:1","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["Code","C"],"content":"多级指针（重点） 本质上讲多级指针和一级指针并没有区别，储存的都是地址，但多级指针是指向指针的指针，如下例代码： //此处p的地址是0x7fffffffdd54 *p 0xffffdd540000000a //q是0x7fffffffdd58 *q是0x7fffffffdd54，**q是0xffffdd540000000a int main() { int **p =NULL; int ***q = NULL; int m = 10; p = \u0026m; //q= \u0026m; //printf(\"%d %d\\n\",*p,*q); //几级指针取地址就几级指针解引用 q = \u0026p; printf(\"%d %d\\n\",*p,**q);//10 10 return 0; } 指针变量p是一个二级指针，指向的是整形变量m = 10，他用了p去存储这个整形变量的地址，也即是p的地址0xffffdd540000000a，是这个整形变量的地址，此时我们再用另外一个多级指针q来指向这个指针p，可以看到在q中出现了三个地址，这其中有两个地址是相同的，也即是指针p本身的地址0x7fffffffdd54也被指针储存了，除此之外，还储存了*p所指向的整形变量m的地址0xffffdd540000000a，另外，q本身也有地址 0x7fffffffdd58 我们来看看对应关系： p *p **p 0x7fffffffdd54 0xffffdd540000000a 并不储存地址 q *q **q ***q 0x7fffffffdd58 0x7fffffffdd54 0xffffdd540000000a 并不存储地址 二级指针p直接指向整形变量的话，实际上他是取了一级指针p指向整形变量而非二级指针直接指向整形变量m,而三级指针q在指向二级指针p时，则在本身地址的基础上全面继承了二级指针p的地址，对应关系如上表。 按照gcc编译来说多级指针来说是不能直接指向整形变量m的，会报一个warning,提示间隔级别int *和int ** 不同，有些编译器可能不出现警告，这也是正常的） 以下是在上面基础上修改过的代码： int main() { int *t = NULL; int **p =NULL; int ***q = NULL; int m = 10; t = \u0026m; p = \u0026t; //q= \u0026m; //printf(\"%d %d\\n\",*p,*q); //几级指针取地址就几级指针解引用 q = \u0026p; printf(\"%d %d\\n\",**p,***q); return 0; } 断点调试，他们的地址如下： t : 0x7fffffffdd4c *t : 10 p : 0x7fffffffdd50 *p : 0x7fffffffdd4c **p : 10 q : 0x7fffffffdd58 *q : 0x7fffffffdd50 **q : 0x7fffffffdd4c ***q : 10 思考：为什么这里存在一个数值10？而在上方代码中则不存在。 对比发现，上方的结论是正确的，以上就是指针与多级指针的内容。 ","date":"2019-06-04","objectID":"/posts/coding/c_point/:1:2","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"}]