[{"categories":["Go","Code"],"content":"ココのcoding","date":"2022-07-15","objectID":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/","tags":["Go","Code"],"title":"go并发的三种模式","uri":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["Go","Code"],"content":"并发的三种模式 runner.go 主要为切片放置任务函数 package runner import ( \"errors\" \"os\" \"os/signal\" \"time\" ) type Runner struct { // interrupt 通道报告从操作系统发送的信号 interrupt chan os.Signal //complete通道报告处理任务已经完成 complete chan error //timeout 报告任务超时，注意方向 timeout \u003c-chan time.Time //tasks持有依次执行的任务函数 tasks []func(int) } //任务超时返回 var ErrTimeout = errors.New(\"received timeout\") //任务中断返回 var ErrInterrupt = errors.New(\"received interrupt\") //New返回一个新的准备使用的runner、初始化操作 func New(d time.Duration) *Runner { return \u0026Runner{ interrupt: make(chan os.Signal, 1), complete: make(chan error), timeout: time.After(d), } } //Add函数添加任务到Runner上 func (r *Runner) Add(tasks ...func(int)) { r.tasks = append(r.tasks, tasks...) } //start执行任务，并监视管道 func (r *Runner) Start() error { //接受所有中断信号 signal.Notify(r.interrupt, os.Interrupt) //用不同的goroutine执行不同的任务 go func() { r.complete \u003c- r.run() }() select { //当任务完成的发出的信号 case err := \u003c-r.complete: return err //当任务超时的时发出的信号 case \u003c-r.timeout: return ErrTimeout } } func (r *Runner) run() error { for id, task := range r.tasks { //检测操作系统的中断信号 if r.gotInterrupt() { return ErrInterrupt } //执行已经在队列中的任务 task(id) } return nil } func (r *Runner) gotInterrupt() bool { select { //当中断时间被触发时的信号 case \u003c-r.interrupt: //停止接收后续信号 signal.Stop(r.interrupt) return true //继续正常运行 default: return false } } pool.go 主要有缓冲channel放置任务函数 package pool import ( \"errors\" \"log\" \"io\" \"sync\" ) //管理goroutine的pool type Pool struct{ m sync.Mutex resources chan io.Closer factory func()(io.Closer,error) closed bool } //pool已经关闭 var ErrPoolClosed = errors.New(\"Pool has been closed\") func New(fn func()(io.Closer,error),size uint)(*Pool,error){ if size \u003c= 0{ return nil,errors.New(\"size value too small\") } return \u0026Pool{ factory: fn, resources: make(chan io.Closer,size), },nil } //从池子获取资源 func (p *Pool)Acquire()(io.Closer,error){ select{ //检查是否存在空闲资源 case r,ok := \u003c- p.resources: log.Println(\"Acquire:\",\"Shared Resource\") if !ok { return nil,ErrPoolClosed } return r,nil //因为没有空闲资源，所以提供一个新资源 default: log.Println(\"Acquire:\",\"New Resource\") return p.factory() } } //将最后一个资源放回池子里面 func (p *Pool)Release(r io.Closer){ //保证可靠性 p.m.Lock() defer p.m.Unlock() //如果池子已经被关闭,则销毁资源 if p.closed { r.Close() return } select{ //将资源放入队列 case p.resources \u003c-r: log.Println(\"Releae:\",\"In Queue\") //队列已满，关闭资源 default: log.Println(\"Release:\",\"Closing\") r.Close() } } //让资源池停止工作，并且释放资源 func (p *Pool)Close(){ //保证操作安全性 p.m.Lock() defer p.m.Unlock() //如果pool已经被关闭 if p.closed { return } //关闭池子 p.closed = true //清空管道资源之前要关闭管道，不然会发生死锁 close(p.resources) for r := range p.resources { r.Close() } } work.go 主要为无缓冲放置任务函数 package work import \"sync\" type Worker interface { Task() } type Pool struct { work chan Worker wg sync.WaitGroup } func New(maxGoroutine int) *Pool { p := Pool{ work: make(chan Worker), } p.wg.Add(maxGoroutine) for i := 0; i \u003c maxGoroutine; i++ { go func() { for w := range p.work { w.Task() } p.wg.Done() }() } return \u0026p } func (p *Pool) Run(w Worker) { p.work \u003c- w } func (p *Pool) Shutdown() { close(p.work) p.wg.Wait() } ","date":"2022-07-15","objectID":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/:0:1","tags":["Go","Code"],"title":"go并发的三种模式","uri":"/posts/coding/go%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["算法"],"content":"ココの~rsa思考","date":"2022-07-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"非对称加密-RSA算法 ","date":"2022-07-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:0","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"概念 加密和解密可以使用不同的规则，只要这两种规则之间存在某种对应关系即可，这样就避免了直接传递密钥。这种新的加密模式被称为\"非对称加密算法\"。 对称加密： 甲方选择某一种加密规则，对信息进行加密； 乙方使用同一种规则，对信息进行解密。 非对称加密： 乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 甲方获取乙方的公钥，然后用它对信息加密。 乙方得到加密后的信息，用私钥解密。 常见的非对称加密算法有RSA算法、ECC椭圆曲线算法等等 ","date":"2022-07-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:1","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"前置知识 RSA算法与欧拉函数存在一定关系，本篇不对欧拉函数进行讨论，仅仅了解计算即可 互质关系： 一个数是质数，另一个数只要不是前者的倍数，两者就构成互质关系，比如3和10。 如果两个数之中，较大的那个数是质数，则两者构成互质关系，比如97和57。 1和任意一个自然数是都是互质关系，比如1和99。 p是大于1的整数，则p和p-1构成互质关系，比如57和56。 p是大于1的奇数，则p和p-2构成互质关系，比如17和15。 欧拉函数计算： 概念：任意给定正整数n，请问在小于等于n的正整数之中，有多少个与n构成互质关系，计算这个值的方法就叫做欧拉函数，以φ(n)表示。例如、在1到7之中，与7形成互质关系的是1、2、3、4、5、6，在1到9之中，与9形成互质关系的是1、2、4、5、7、8。 公式：m^φ(n) ≡ 1 (mod n) 若 p * q = n 且pq也为质数的情况下，则有φ(n) = (p-1) * (q-1)。也即是得出结论：两个质数之积的欧拉函数的值等于两个数的欧拉函数之值的乘积。利用到了互质关系中的第三点，任何数与质数都是互质关系。 模反元素： 模反元素：如果两个正整数a和n互质，那么一定可以找到整数b，使得 ab-1 被n整除，或者说ab被n除的余数是1，b就叫做a的\"模反元素\"。此处的ab即为RSA算法中提到的\"私钥\"与\"公钥\"。公式有：ab≡ 1 (mod n) 举例有：3和11互质，那么3的模反元素就是4，因为3*4-1刚好可以被11整除,所以4和3互为模反元素，又如5和34互质，那么5和7就互为模反元素，也是5*7-1=34 注意互质关系不一定两个数都是质数，具体可以参考5和34,7和12等等。 ","date":"2022-07-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:2","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"RSA加密 加密过程： 第一步：随机生成质数p与q、得出n = p * q 第二步：计算n的欧拉函数值，使用欧拉函数公式即可：φ(n) = (p-1) * (q-1) 第三步：在1与φ(n)之间随机生成整数e，条件是1\u003c e \u003c φ(n)，且e与φ(n) 互质。 第四步：计算e对于φ(n)的模反元素d，带入公式有ed≡ 1 (mod n)，等价于 ed - 1 = kφ(n)、于是，找到模反元素d 第五步：将n和e封装成公钥，n和d封装成私钥。 举例分析：若p = 53、q= 61、则 n = p*q = 3233、φ(n) = (p-1)*(q-1) = 3120、若随即选择e = 17、d = 2753。则私钥对为（3233,2753）、公钥对为（3233,17）。 可靠性分析：p、q、n、e、φ(n)、d是已经出现的数字、这六个数字之中，公钥用到了两个（n和e），其余四个数字都是不公开的。其中最关键的是d，因为n和d组成了私钥，一旦d泄漏，就等于私钥泄漏。那么在（n,e）公开的情况下，有没有可能推导出d,从而得出私钥（n,d）。 推导条件： ed≡1 (mod φ(n))。只有知道e和φ(n)，才能算出d。 φ(n)=(p-1)(q-1)。只有知道p和q，才能算出φ(n)。 n=pq。只有将n因数分解，才能算出p和q。 结论：如果n可以被因数分解，d就可以算出，也就意味着私钥被破解。 “对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法，那么RSA的可靠性就会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA密钥才可能被暴力破解。到2008年为止，世界上还没有任何可靠的攻击RSA算法的方式。只要密钥长度足够长，用RSA加密的信息实际上是不能被解破的。” 解密过程： 加密：m^e ≡ c (mod n)带入上述数字得出65^17 ≡ 2790 (mod 3233)，也即是2790为加密数字，65为真实数字 解密：c^d ≡ m (mod n)带入计算有2790^2753 ≡ 65 (mod 3233),解密得出65为真实数字 至此，“加密–解密\"的整个过程全部完成。 私钥解密的证明： 为什么用私钥解密，一定可以正确地得到m 由解密规则有：c^d ≡ m (mod n)、又由加密规则有：ｍ^e ≡ c (mod n)、则有：c = m^e - kn、将c代入要我们要证明的那个解密规则：(m^e - kn)^d ≡ m (mod n)等同于m^(ed) ≡ m (mod n)推出ed ≡ 1 (mod φ(n))、既有ed = hφ(n)+1、将ed代入ed ≡ 1 (mod φ(n))：m^(hφ(n)+1) ≡ m (mod n) 若mn互质：则有m^φ(n) ≡ 1 (mod n)、与上式连立有：(m^φ(n))^h × m ≡ m (mod n),原式得到证明。 若mn不为互质关系：以 m = kp为例，考虑到这时k与q必然互质，则根据欧拉定理，下面的式子成立：　(kp)^(q-1) ≡ 1 (mod q)、进一步得到:[(kp)^(q-1) ]^h(p-1) × kp ≡ kp (mod q)、既有(kp)ed ≡ kp (mod q)、改写为：(kp)^ed = tq + kp、这时t必然能被p整除，即 t=t’p、因为 m=kp，n=pq，所以m^ed ≡ m (mod n)、得证。 本文参考自：https://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html ","date":"2022-07-04","objectID":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/:1:3","tags":["算法","加密","RSA"],"title":"RSA加密算法","uri":"/posts/thinking/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"},{"categories":["Code","C"],"content":"ココの领悟～","date":"2022-06-04","objectID":"/posts/coding/c_point/","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["Code","C"],"content":"指针与多级指针 什么是指针？指针是变量，确切的讲是储存地址的一种变量，全称应当是指针变量而非指针，以下是定义整形指针变量的代码。 #include\u003cstdio.h\u003e int main() { int *p = NULL; int m = 10; int *q = \u0026m; p = \u0026m; printf(\"%d %d\\n\",*q,*p);//p与q地址相同 return 0;//此时指针p q等效 } ","date":"2022-06-04","objectID":"/posts/coding/c_point/:1:0","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["Code","C"],"content":"一级指针 一级指针是指指向某个变量并储存其地址的指针变量，或者是它本身就是地址，指针和地址其实是同样的意思。 注意指针本身就是一种变量，它本身也开辟了一块空间来存储它本身，指针变量本身也有地址，这就引出了多级指针，在外文中没有多级指针的说法，取而代之的则是pointer to pointer。 一级指针的定义 #include\u003cstdio.h\u003e int *p = NULL; int m = 10; p = \u0026m;//指针变量取得是地址，所以要加上取地址符 printf(\"%d\\n\",*p);//10 return 0; ","date":"2022-06-04","objectID":"/posts/coding/c_point/:1:1","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["Code","C"],"content":"多级指针（重点） 本质上讲多级指针和一级指针并没有区别，储存的都是地址，但多级指针是指向指针的指针，如下例代码： //此处p的地址是0x7fffffffdd54 *p 0xffffdd540000000a //q是0x7fffffffdd58 *q是0x7fffffffdd54，**q是0xffffdd540000000a int main() { int **p =NULL; int ***q = NULL; int m = 10; p = \u0026m; //q= \u0026m; //printf(\"%d %d\\n\",*p,*q); //几级指针取地址就几级指针解引用 q = \u0026p; printf(\"%d %d\\n\",*p,**q);//10 10 return 0; } 指针变量p是一个二级指针，指向的是整形变量m = 10，他用了p去存储这个整形变量的地址，也即是p的地址0xffffdd540000000a，是这个整形变量的地址，此时我们再用另外一个多级指针q来指向这个指针p，可以看到在q中出现了三个地址，这其中有两个地址是相同的，也即是指针p本身的地址0x7fffffffdd54也被指针储存了，除此之外，还储存了*p所指向的整形变量m的地址0xffffdd540000000a，另外，q本身也有地址 0x7fffffffdd58 我们来看看对应关系： p *p **p 0x7fffffffdd54 0xffffdd540000000a 并不储存地址 q *q **q ***q 0x7fffffffdd58 0x7fffffffdd54 0xffffdd540000000a 并不存储地址 二级指针p直接指向整形变量的话，实际上他是取了一级指针p指向整形变量而非二级指针直接指向整形变量m,而三级指针q在指向二级指针p时，则在本身地址的基础上全面继承了二级指针p的地址，对应关系如上表。 按照gcc编译来说多级指针来说是不能直接指向整形变量m的，会报一个warning,提示间隔级别int *和int ** 不同，有些编译器可能不出现警告，这也是正常的） 以下是在上面基础上修改过的代码： int main() { int *t = NULL; int **p =NULL; int ***q = NULL; int m = 10; t = \u0026m; p = \u0026t; //q= \u0026m; //printf(\"%d %d\\n\",*p,*q); //几级指针取地址就几级指针解引用 q = \u0026p; printf(\"%d %d\\n\",**p,***q); return 0; } 断点调试，他们的地址如下： t : 0x7fffffffdd4c *t : 10 p : 0x7fffffffdd50 *p : 0x7fffffffdd4c **p : 10 q : 0x7fffffffdd58 *q : 0x7fffffffdd50 **q : 0x7fffffffdd4c ***q : 10 思考：为什么这里存在一个数值10？而在上方代码中则不存在。 对比发现，上方的结论是正确的，以上就是指针与多级指针的内容。 ","date":"2022-06-04","objectID":"/posts/coding/c_point/:1:2","tags":["C","Point"],"title":"C指针与多级指针","uri":"/posts/coding/c_point/"},{"categories":["network"],"content":"ココの～网络","date":"2022-04-04","objectID":"/posts/thinking/wireshark_use/","tags":["network","wireshark"],"title":"Wireshark的使用","uri":"/posts/thinking/wireshark_use/"},{"categories":["network"],"content":"Wireshark的使用与常见错误 wireshark的主要作用是为了诊断网络出现的问题，大致上比较重要的部分是过滤器与结果的表达，这两点是比较重要的，比如在过滤器中对协议进行选择，排除无关协议的影响，比如结果的如何呈现会更加直观，对tcp来讲，选择tcp流形图会不会比流量图更好。 以下是一张wireshark主界面图： 注意，本机系统为archlinux,启动时要使用管理员身份。 ","date":"2022-04-04","objectID":"/posts/thinking/wireshark_use/:1:0","tags":["network","wireshark"],"title":"Wireshark的使用","uri":"/posts/thinking/wireshark_use/"},{"categories":["network"],"content":"过滤器 协议过滤 例如：ARP(ip转mac协议) 注意不区分大小写 协议参数过滤 例如这里选择了IPv4协议，对源地址进行了筛选ip.src_host 连接词的使用 类同于C语言，\u0026\u0026(与)，||(或)， !(非)，除此之外，还有and,or之类，与前一致。 ! 的使用 \u0026\u0026的使用 注意连接词可以同时使用 ","date":"2022-04-04","objectID":"/posts/thinking/wireshark_use/:1:1","tags":["network","wireshark"],"title":"Wireshark的使用","uri":"/posts/thinking/wireshark_use/"},{"categories":["network"],"content":"结果输出 ip.src_host == 43.129.76.227 \u0026\u0026 ip.dst_host == 192.168.88.153主机之间的流量图 ip.src_host == 43.129.76.227 \u0026\u0026 ip.dst_host == 192.168.88.153 主机之间的通信，数据包流量图如图所示。 注意：捕获选项中的混杂器选项代表了主机是否丢弃非目的地址的包，可以打开此选项以此来查看子网流通性或关闭此选项来减少捕获包的数量，从而减少分析难度 ","date":"2022-04-04","objectID":"/posts/thinking/wireshark_use/:1:2","tags":["network","wireshark"],"title":"Wireshark的使用","uri":"/posts/thinking/wireshark_use/"},{"categories":["操作系统"],"content":"ココの调度","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"调度 当计算机系统是多道程序设计系统时，通常就会有多个进程或线程同时竞争CPU。只要有两个或更多的进程处于就绪状态，这种情形就会发生。如果只有一个CPU可用，那么就必须选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为调度程序（scheduler），该程序使用的算法称为调度算法（scheduling algorithm）。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:0","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"调度介绍 调度程序还要考虑CPU的利用率，因为进程切换的代价是比较高的。 首先，用户态必须切换到内核态；然后要保存当前进程的状态，包括在进程表中存储寄存器值以便以后重新装载。在许多系统中，内存映像（例如，页表内的内存访问位）也必须保存；接着，通过运行调度算法选定一个新进程；之后，应该将新进程的内存映像重新装入MMU；最后新进程开始运行。除此之外，进程切换还要使整个内存高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核一次，离开内核一次）。总之，如果每秒钟切换进程的次数太多，会耗费大量CPU时间，所以有必要提醒注意。 进程行为 几乎所有进程的（磁盘）I/O请求或计算都是交替突发的 典型地，CPU不停顿地运行一段时间，然后发出一个系统调用以便读写文件。在完成系统调用之后，CPU又开始计算，直到它需要读更多的数据或写更多的数据为止。 请注意，某些I/O活动可以看作是计算。例如，当CPU向视频RAM复制数据以更新屏幕时，因为使用了CPU，所以这是计算，而不是I/O活动 何时调度 第一，在创建一个新进程之后，需要决定是运行父进程还是运行子进程 由于这两种进程都处于就绪状态，所以这是一种正常的调度决策，可以任意决定，也就是说，调度程序可以合法选择先运行父进程还是先运行子进程。 第二，在一个进程退出时必须做出调度决策。 一个进程不再运行（因为它不再存在），所以必须从就绪进程集中选择另外某个进程。如果没有就绪的进程，通常会运行一个系统提供的空闲进程。 第三，当一个进程阻塞在I/O和信号量上或由于其他原因阻塞时，必须选择另一个进程运行。 有时，阻塞的原因会成为选择的因素。例如，如果A是一个重要的进程，并正在等待B退出临界区，让B随后运行将会使得B退出临界区，从而可以让A运行。不过问题是，通常调度程序并不拥有做出这种相关考虑的必要信息。 第四，在一个I/O中断发生时，必须做出调度决策。 如果中断来自I/O设备，而该设备现在完成了工作，某些被阻塞的等待该I/O的进程就成为可运行的就绪进程了。是否让新就绪的进程运行，这取决于调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让某个其他进程运行。 调度算法分类 批处理。 在批处理系统中，不会有用户不耐烦地在终端旁等待一个短请求的快捷响应。因此，非抢占式算法，或对每个进程都有长时间周期的抢占式算法，通常都是可接受的。 交互式。 在交互式用户环境中，为了避免一个进程霸占CPU拒绝为其他进程服务，抢占是必需的。服务器也归于此类，因为通常它们要服务多个突发的（远程）用户。 实时 实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。 调度算法的目标 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:1","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"批处理系统中的调度 先来先服务 在所有调度算法中，最简单的是非抢占式的先来先服务（first-come first-severd）算法。使用该算法，进程按照它们请求CPU的顺序使用CPU。基本上，有一个就绪进程的单一队列。 这个算法的主要优点是易于理解并且便于在程序中运用。就难以得到的体育或音乐会票的分配问题而言，这对那些愿意在早上两点就去排队的人们也是公平的。在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或阻塞一个进程，只要把该作业或进程附加在相应队列的末尾即可。 最短作业优先 现在来看一种适用于运行时间可以预知的另一个非抢占式的批处理调度算法。 这里有4个作业A、B、C、D，运行时间分别为8、4、4、4分钟。若按图中的次序运行，则A的周转时间为8分钟，B为12分钟，C为16分钟，D为20分钟，平均为14分钟。 考虑有4个作业的情况，其运行时间分别为a、b、c、d。第一个作业在时间a结束，第二个在时间a+b结束，以此类推。平均周转时间为（4a+3b+2c+d）/4。显然a对平均值影响最大，所以它应是最短作业，其次是b，再次是c，最后的d只影响它自己的周转时间。 最短作业调度是将后续具有最短处理时间的进程先放到CPU上运行，如果就绪队列中有同样长度的进程，那么它们之间是采用FCFS调度的。 最短下一个CPU区间，需要操作系统知道接下来是那个进程的CPU区间最短。 SJF就是调度这个最短CPU区间的进程。 有必要指出，只有在所有的作业都可同时运行的情形下，最短作业优先算法才是最优化的。 最短剩余时间优先 最短作业优先的抢占式版本是最短剩余时间优先（shortest remaining time next）算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。 再次提醒，有关的运行时间必须提前掌握。当一个新的作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式可以使新的短作业获得良好的服务。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:2","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"交互式系统中的调度 轮转调度 一种最古老、最简单、最公平且使用最广的算法是轮转调度（round robin）。 每个进程被分配一个时间段，称为时间片（quantum），即允许该进程在该时间段中运行。如果在时间片结束时该进程还在运行，则将剥夺CPU并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则CPU立即进行切换。时间片轮转调度很容易实现，调度程序所要做的就是维护一张可运行进程列表，当一个进程用完它的时间片后，就被移到队列的末尾 时间片轮转调度中惟一有趣的一点是时间片的长度。从一个进程切换到另一个进程是需要一定时间进行管理事务处理的——保存和装入寄存器值及内存映像、更新各种表格和列表、清除和重新调入内存高速缓存等。假如进程切换（process switch），有时称为上下文切换（context switch），需要1ms，包括切换内存映像、清除和重新调入高速缓存等。再假设时间片设为4ms。有了这些参数，则CPU在做完4ms有用的工作之后，CPU将花费（即浪费）1ms来进行进程切换。因此，CPU时间的20%浪费在管理开销上。 可以归结如下结论：时间片设得太短会导致过多的进程切换，降低了CPU效率；而设得太长又可能引起对短的交互请求的响应时间变长。将时间片设为20ms～50 ms通常是一个比较合理的折中。 优先级调度 轮转调度做了一个隐含的假设，即所有的进程同等重要 可以很方便地将一组进程按优先级分成若干类，并且在各类之间采用优先级调度，而在各类进程的内部采用轮转调度。 优先级也可以由系统动态确定。优先级可以是静态赋予或动态赋予。为了防止高优先级进程无休止地运行下去，调度程序可以在每个时钟滴答（即每个时钟中断）降低当前进程的优先级。如果这个动作导致该进程的优先级低于次高优先级的进程，则进行进程切换。一个可采用的方法是，每个进程可以被赋予一个允许运行的最大时间片，当这个时间片用完时，下一个次高优先级的进程获得机会运行。 如果不偶尔对优先级进行调整，则低优先级进程很可能会产生饥饿现象。 多级队列 如前所述，长时间片的进程又会影响到响应时间，其解决办法是设立优先级类。属于最高优先级类的进程运行一个时间片，属于次高优先级类的进程运行2个时间片，再次一级运行4个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。 最短进程优先 对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互进程，那将是非常好的。 一种办法是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设某个终端上每条命令的估计运行时间为T0 。现在假设测量到其下一次运行时间为T1 。可以用这两个值的加权和来改进估计时间，即aT0 +(1-a)T1 。 保证调度 一种完全不同的调度算法是向用户作出明确的性能保证，然后去实现它。 一种很实际并很容易实现的保证是：若用户工作时有n个用户登录，则用户将获得CPU处理能力的1/n。类似地，在一个有n个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得1/n的CPU时间。看上去足够公平了。 为了实现所做的保证，系统必须跟踪各个进程自创建以来已使用了多少CPU时间。然后它计算各个进程应获得的CPU时间，即自创建以来的时间除以n。由于各个进程实际获得的CPU时间是已知的，所以很容易计算出真正获得的CPU时间和应获得的CPU时间之比。比率为0.5说明一个进程只获得了应得时间的一半，而比率为2.0则说明它获得了应得时间的2倍。于是该算法随后转向比率最低的进程，直到该进程的比率超过它的最接近竞争者为止。 彩票调度 其基本思想是向进程提供各种系统资源（如CPU时间）的彩票。一旦需要做出一项调度决策时，就随机抽出一张彩票，拥有该彩票的进程获得该资源。 彩票调度具有若干有趣的性质。例如，如果有一个新的进程出现并得到一些彩票，那么在下一次的抽奖中，该进程会有同它持有彩票数量成比例的机会赢得奖励。换句话说，彩票调度是反应迅速的。 公平分享调度 到现在为止，我们假设被调度的都是各个进程自身，并不关注其所有者是谁。这样做的结果是，如果用户1启动9个进程而用户2启动1个进程，使用轮转或相同优先级调度算法，那么用户1将得到90%的CPU时间，而用户2只得到10%的CPU时间。 为了避免这种情形，某些系统在调度处理之前考虑谁拥有进程这一因素。在这种模式中，每个用户分配到CPU时间的一部分，而调度程序以一种强制的方式选择进程。这样，如果两个用户都得到获得50%CPU时间的保证，那么无论一个用户有多少进程存在，每个用户都会得到应有的CPU份额。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:3","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"实时系统中的调度 实时系统是一种时间起着主导作用的系统。典型地，外部的一种或多种物理设备给了计算机一个刺激，而计算机必须在一个确定的时间范围内恰当地做出反应。 实时系统通常可以分为硬实时（hard real time）和软实时（soft real time），前者的含义是必须满足绝对的截止时间，后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。 在这两种情形中，实时性能都是通过把程序划分为一组进程而实现的，其中每个进程的行为是可预测和提前掌握的。这些进程一般寿命较短，并且极快地就运行完成。在检测到一个外部信号时，调度程序的任务就是按照满足所有截止时间的要求调度进程。 实时系统中的事件可以按照响应方式进一步分类为周期性（以规则的时间间隔发生）事件或非周期性（发生时间不可预知）事件。 一个系统可能要响应多个周期性事件流。根据每个事件需要处理时间的长短，系统甚至有可能无法处理完所有的事件。例如，如果有m个周期事件，事件i以周期Pi 发生，并需要Ci 秒CPU时间处理一个事件，那么可以处理负载的条件是 满足这个条件的实时系统称为是可调度的。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:4","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"策略和机制 以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。 解决问题的方法是将调度机制（scheduling mechanism）与调度策略（scheduling policy）分离（著名的原则，Levin等人，1975），也就是将调度算法以某种形式参数化，而参数可以由用户进程填写。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:5","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"线程调度 当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。 首先考虑用户级线程。由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为A，并给予A以时间片控制。A中的线程调度程序决定哪个线程运行，假设为A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。在进程A终于又一次运行时，线程A1会接着运行。该线程会继续耗费A进程的所有时间，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程A内部所发生的事。 惟一的局限是，缺乏一个时钟将运行过长的线程加以中断。 现在考虑A线程每次CPU计算的工作比较少的情况，例如，在50ms的时间片中有5ms的计算工作。于是，每个线程运行一会儿，然后把CPU交回给线程调度程序。这样在内核切换到进程B之前，就会有序列A1，A2，A3，A1，A2，A3，A1，A2，A3，A1 现在考虑使用内核级线程的情形。内核选择一个特定的线程运行。它不用考虑该线程属于哪个进程，不过如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在50ms的时间片内，5ms之后被阻塞，在30ms的时间段中，线程的顺序会是A1，B1，A2，B2，A3，B3 用户级线程和内核级线程之间的差别在于性能。 用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:6","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"IPC问题 哲学家就餐问题 有 5 个哲学家，他们面前都有一双筷子，即左手有一根筷子，右手有一根筷子。当然，这个问题有多个版本的描述，可以说是筷子，也可以说是一刀一叉，因为吃牛排的时候，需要刀和叉，缺一不可，也有说是用两把叉子来吃意大利面。这里具体是刀叉还是筷子并不重要，重要的是必须要同时持有左右两边的两个才行，也就是说，哲学家左手要拿到一根筷子，右手也要拿到一根筷子，在这种情况下哲学家才能吃饭。 读者-写者问题 例如，设想一个飞机订票系统，其中有许多竞争的进程试图读写其中的数据。多个进程同时读数据库是可以接受的，但如果一个进程正在更新（写）数据库，则所有的其他进程都不能访问该数据库，即使读操作也不行。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:7","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"小结 为了隐蔽中断的影响，操作系统提供了一个由并行运行的顺序进程组成的概念模型。进程可以动态地创建和终止。每个进程都有自己的地址空间。 对于某些应用而言，在一个进程中使用多个控制线程是有益的。这些线程被独立调度，每个线程有自己的堆栈，但是在一个进程中的所有线程共享一个公共地址空间。线程可以在用户空间或内核中实现。 进程之间通过进程间通信原语彼此通信，如信号量、管程或消息。这些原语用来确保同一时刻不会有两个进程在临界区中，免除了出现混乱的情形。进程可以处在运行、可运行或阻塞状态，并且在该进程或其他进程执行某个进程间通信原语时，可以改变其状态。线程间通信也是类似的。 进程间通信原语可以用来解决诸如生产者-消费者问题、哲学家就餐问题和读者-写者问题等。即便有了这些原语，也要仔细设计以避免出错和死锁。 已经有一大批研究出来的调度算法。某些算法主要用于批处理系统中，如最短作业优先调度算法。其他算法常用在批处理系统和交互式系统中，它们包括轮转调度、优先级调度、多级队列、保证调度、彩票调度以及公平分享调度等。有些系统将调度策略和调度机制清晰地分离，这样可以使用户对调度算法进行控制。 ","date":"2021-03-25","objectID":"/posts/thinking/%E8%B0%83%E5%BA%A6/:1:8","tags":["操作系统"],"title":"调度","uri":"/posts/thinking/%E8%B0%83%E5%BA%A6/"},{"categories":["操作系统"],"content":"ココの通信","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"进程间通信 简要地说，有三个问题。 第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。 第二个要处理的问题是，确保两个或更多的进程在关键活动中不会出现交叉，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。 第三个问题与正确的顺序有关（如果该顺序是有关联的话），比如，如果进程A产生数据而进程B打印数据，那么B在打印之前必须等待，直到A已经产生一些数据。我们将从下一节开始考察所有这三个问题。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:0","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"竞争条件 即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为竞争条件（race condition） 在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中（可能是在内核数据结构中），也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。 怎样避免竞争条件？实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。 换言之，我们需要的是互斥（mutual exclusion），即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:1","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"临界区 我们把对共享内存进行访问的程序片段称作临界区域（critical region）或临界区（critical section） 对于一个好的解决方案，需要满足以下4个条件： 任何两个进程不能同时处于其临界区。 不应对CPU的速度和数量做任何假设。 临界区外运行的进程不得阻塞其他进程。 不得使进程无限期等待进入临界区。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:2","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"忙等待的互斥 屏蔽中断 意义 在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介入。 缺陷 把屏蔽中断的权力交给用户进程是不明智的。设想一下，若一个进程屏蔽中断后不再打开中断，其结果将会如何？整个系统可能会因此终止。而且，如果系统是多处理器（有两个或可能更多的处理器），则屏蔽中断仅仅对执行disable指令的那个CPU有效。其他CPU仍将继续运行，并可以访问共享内存。屏蔽一个CPU的中断不会阻止其他CPU干预第一个CPU所做的操作。结果是人们需要更加复杂的计划。 所以结论是：屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。 锁变量 意义 设想有一个共享（锁）变量，其初始值为0。当一个进程想进入其临界区时，它首先测试这把锁。如果该锁的值为0，则该进程将其设置为1并进入临界区。若这把锁的值已经为1，则该进程将等待直到其值变为0。于是，0就表示临界区内没有进程，1表示已经有某个进程进入临界区。 缺陷 这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为0，而恰好在它将其值设置为1之前，另一个进程被调度运行，将该锁变量设置为1。当第一个进程再次能运行时，它同样也将该锁设置为1，则此时同时有两个进程进入临界区中。同样还会发生竞争条件。 严格轮换法 整型变量turn，初始值为0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程0检查turn，发现其值为0，于是进入临界区。进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。连续测试一个变量直到某个值出现为止，称为忙等待（busy waiting）。由于这种方式浪费CPU时间，所以通常应该避免。 只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为自旋锁（spin lock）。 进程0离开临界区时，它将turn的值设置为1，以便允许进程1进入其临界区。假设进程1很快便离开了临界区，则此时两个进程都处于临界区之外，turn的值又被设置为0。现在进程0很快就执行完其整个循环，它退出临界区，并将turn的值设置为1。此时，turn的值为1，两个进程都在其临界区外执行。 突然，进程0结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为turn的当前值为1，而此时进程1还在忙于非临界区的操作，进程0只有继续while循环，直到进程1把turn的值改为0。这说明，在一个进程比另一个慢了很多的情况下，轮流进入临界区并不是一个好办法。 尽管该算法的确避免了所有的竞争条件，但由于它违反了条件3，所以不能作为一个很好的备选方案。 Peterson解法 在使用共享变量（即进入其临界区）之前，各个进程使用其进程号0或1作为参数来调用enter_region。该调用在需要时将使进程等待，直到能安全地进入临界区。在完成对共享变量的操作之后，进程将调用leave_region，表示操作已完成，若其他的进程希望进入临界区，则现在就可以进入。 一开始，没有任何进程处于临界区中，现在进程0调用enter_region。它通过设置其数组元素和将turn置为0来标识它希望进入临界区。由于进程1并不想进入临界区，所以enter_region很快便返回。如果进程1现在调用enter_region，进程1将在此处挂起直到interested[0]变成FALSE，该事件只有在进程0调用leave_region退出临界区时才会发生。 现在考虑两个进程几乎同时调用enter_region的情况。它们都将自己的进程号存入turn，但只有后被保存进去的进程号才有效，前一个因被重写而丢失。假设进程1是后存入的，则turn为1。当两个进程都运行到while语句时，进程0将循环0次并进入临界区，而进程1则将不停地循环且不能进入临界区，直到进程0退出临界区为止。 TSL指令 TSL RX,LOCK 称为测试并加锁（Test and Set Lock），它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行TSL指令的CPU将锁住内存总线，以禁止其他CPU在本指令结束之前访问内存。 注意 锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器1上屏蔽中断对处理器2根本没有任何影响。让处理器2远离内存直到处理器1完成的惟一方法就是锁住总线，这需要一个特殊的硬件设施（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用）。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:3","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"睡眠与唤醒 Peterson解法和TSL或XCHG解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的：当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。 考虑一台计算机有两个进程，H优先级较高，L优先级较低。调度规则规定，只要H处于就绪态它就可以运行。在某一时刻，L处于临界区中，此时H变到就绪态，准备运行（例如，一条I/O操作结束）。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。这种情况有时被称作优先级反转问题（priority inversion problem）。 生产者-消费者（producer-consumer）问题，也称作有界缓冲区（bounded-buffer）问题。 两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者，将信息放入缓冲区；另一个是消费者，从缓冲区中取出信息。（也可以把这个问题一般化为m个生产者和n个消费者问题，但是我们只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。） 问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。 这个方法听起来很简单，但它包含与前边假脱机目录问题一样的竞争条件。为了跟踪缓冲区中的数据项数，我们需要一个变量count。 如果缓冲区最多存放N个数据项，则生产者代码将首先检查count是否达到N，若是，则生产者睡眠；否则生产者向缓冲区中放入一个数据项并增量count的值。消费者的代码与此类似：首先测试count是否为0，若是，则睡眠；否则从中取走一个数据项并递减count的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。 现在回到竞争条件的问题。这里有可能会出现竞争条件，其原因是对count的访问未加限制。有可能出现以下情况：缓冲区为空，消费者刚刚读取count的值发现它为0。此时调度程序决定暂停消费者并启动运行生产者。生产者向缓冲区中加入一个数据项，count加1。现在count的值变成了1。它推断认为由于count刚才为0，所以消费者此时一定在睡眠，于是生产者调用wakeup来唤醒消费者。但是，消费者此时在逻辑上并未睡眠，所以wakeup信号丢失。当消费者下次运行时，它将测试先前读到的count值，发现它为0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。 问题的实质在于发给一个（尚）未睡眠进程的wakeup信号丢失了。如果它没有丢失，则一切都很正常。 一种快速的弥补方法是修改规则，加上一个唤醒等待位。当一个wakeup信号发送给一个清醒的进程信号时，将该位置1。随后，当该进程要睡眠时，如果唤醒等待位为1，则将该位清除，而该进程仍然保持清醒。唤醒等待位实际上就是wakeup信号的一个小仓库。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:4","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"信号量 信号量是E.W.Dijkstra在1965年提出的一种方法，它使用一个整型变量来累计唤醒次数，供以后使用。在他的建议中引入了一个新的变量类型，称作信号量（semaphore）。一个信号量的取值可以为0（表示没有保存下来的唤醒操作）或者为正值（表示有一个或多个唤醒操作）。 检查数值、修改变量值以及可能发生的睡眠操作均作为一个单一的、不可分割的原子操作完成。保证一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。 所谓原子操作，是指一组相关联的操作要么都不间断地执行，要么都不执行。原子操作在计算机科学的其他领域也是非常重要的。 读者必须搞清楚，使用TSL或XCHG指令来防止几个CPU同时访问一个信号量，这与生产者或消费者使用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量操作仅需几个毫秒，而生产者或消费者则可能需要任意长的时间。 信号量的另一种用途是用于实现同步（synchronization）。信号量full和empty用来保证某种事件的顺序发生或不发生。在本例中，它们保证当缓冲区满的时候生产者停止运行，以及当缓冲区空的时候消费者停止运行。这种用法与互斥是不同的。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:5","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"互斥量 如果不需要信号量的计数能力，有时可以使用信号量的一个简化版本，称为互斥量（mutex）。互斥量仅仅适用于管理共享资源或一小段代码。由于互斥量在实现时既容易又有效，这使得互斥量在实现用户空间线程包时非常有用。 互斥量是一个可以处于两态之一的变量：解锁和加锁。这样，只需要一个二进制位表示它，不过实际上，常常使用一个整型量，0表示解锁，而其他所有的值则表示加锁。互斥量使用两个过程。当一个线程（或进程）需要访问临界区时，它调用mutex_lock。如果该互斥量当前是解锁的（即临界区可用），此调用成功，调用线程可以自由进入该临界区。 另一方面，如果该互斥量已经加锁，调用线程被阻塞，直到在临界区中的线程完成并调用mutex_unlock。如果多个线程被阻塞在该互斥量上，将随机选择一个线程并允许它获得锁。 Pthread中的互斥 Pthread提供许多可以用来同步线程的函数。其基本机制是使用一个可以被锁定和解锁的互斥量来保护每个临界区。 除互斥量之外，pthread提供了另一种同步机制：条件变量。互斥量在允许或阻塞对临界区的访问上是很有用的，条件变量则允许线程由于一些未达到的条件而阻塞。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:6","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"管道 为了更易于编写正确的程序，Brinch Hansen（1973）和Hoare（1974）提出了一种高级同步原语，称为管程（monitor） 管道有一个很重要的特性，即任一时刻管道中只能有一个活跃进程，这一特性使管道能有效地完成互斥。管道是编程语言的组成部分，编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管道的调用。 进入管程时的互斥由编译器负责，但通常的做法是用一个互斥量或二元信号量。因为是由编译器而非程序员来安排互斥，所以出错的可能性要小得多。在任一时刻，写管程的人无须关心编译器是如何实现互斥的。他只需知道将所有的临界区转换成管程过程即可，决不会有两个进程同时执行临界区中的代码。 与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问公共内存的一个或多个CPU上的互斥问题的。通过将信号量放在共享内存中并用TSL或XCHG指令来保护它们，可以避免竞争。 如果一个分布式系统具有多个CPU，并且每个CPU拥有自己的私有内存，它们通过一个局域网相连，那么这些原语将失效。这里的结论是：信号量太低级了，而管程在少数几种编程语言之外又无法使用，并且，这些原语均未提供机器间的信息交换方法。所以还需要其他的方法。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:7","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"消息传递 。这种进程间通信的方法使用两条原语send和receive，它们像信号量而不像管程，是系统调用而不是语言成分。因此，可以很容易地将它们加入到库例程中去。例如：send(destination,＆message);receive(source,＆message); 前一个调用向一个给定的目标发送一条消息，后一个调用从一个给定的源（或者是任意源，如果接收者不介意的话）接收一条消息。如果没有消息可用，则接收者可能被阻塞，直到一条消息到达，或者，带着一个错误码立即返回。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:8","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"屏障 最后一个同步机制是准备用于进程组而不是用于双进程的生产者-消费者类情形的。在有些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段。可以通过在每个阶段的结尾安置屏障（barrier）来实现这种行为。当一个进程到达屏障时，它就被屏障阻拦，直到所有进程都到达该屏障为止。 ","date":"2021-03-22","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/:1:9","tags":["操作系统"],"title":"进程间通信","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"},{"categories":["操作系统"],"content":"ココの线程","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"进程与线程～线程篇 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:0","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"线程的使用 必要性 并行实体共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型（它们具有不同地址空间）所无法表达的。 由于线程比进程更轻量级，所以它们比进程更容易（即更快）创建，也更容易撤销。 若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:1","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"经典的线程模型 概念的差异 理解进程的一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的报警、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。 另一个概念是，进程拥有一个执行的线程，通常简写为线程（thread）。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体。 线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。 在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为轻量级进程（lightweight process）。 通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象。多线程的工作方式也是类似的。CPU在线程之间的快速切换，制造了线程并行运行的假象，好似它们在一个比实际CPU慢一些的CPU上同时运行。在一个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个CPU上得到了真实CPU速度的三分之一。 进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。 线程之间是没有保护的，原因是: 不可能 也没有必要 这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。 线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作。 和传统进程一样（即只有一个线程的进程），线程可以处于若干种状态的任何一个：运行、阻塞、就绪或终止。线程状态之间的转换和进程状态之间的转换是一样的 认识到每个线程有其自己的堆栈很重要、通常每个线程会调用不同的过程，从而有一个各自不同的执行历史。这就是为什么每个线程需要有自己的堆栈的原因 在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数（如thread_create）创建新的线程。thread_create的参数专门指定了新线程要运行的过程名。这里，没有必要对新线程的地址空间加以规定，因为新线程会自动在创建线程的地址空间中运行。有时，线程是有层次的，它们具有一种父子关系，但是，通常不存在这样一种关系，所有的线程都是平等的。不论有无层次关系，创建线程通常都返回一个线程标识符，该标识符就是新线程的名字。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:2","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"在用户空间中实现线程 有两种主要的方法实现线程包：在用户空间中和在内核中。这两种方法互有利弊，不过混合实现方式也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。 第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。这种方法第一个，也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。 在用户空间管理线程时，每个进程需要有其专用的线程表（thread table），用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。 线程与进程有一个关键的差别。在线程完成运行时，例如，在它调用thread_yield时，pthread_yield代码可以把该线程的信息保存在线程表中、进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。 用户级线程还有另一个优点。它允许每个进程有自己定制的调度算法。 例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题。 尽管用户级线程包有更好的性能，但它也存在一些明显的问题。 其中第一个问题是如何实现阻塞系统调用。 假设在还没有任何击键之前，一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。有了阻塞系统调用，这个目标不是轻易地能够实现的。 系统调用可以全部改成非阻塞的（例如，如果没有被缓冲的字符，对键盘的read操作可以只返回0字节），但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变read操作的语义需要修改许多用户程序。 在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些UNIX版本中，有一个系统调用select可以允许调用者通知预期的read是否会阻塞。若有这个调用，那么库过程read就可以被新的操作替代，首先进行select调用，然后只有在安全的情形下（即不会阻塞）才进行read调用。如果read调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为包装器（jacket或wrapper）。 页面故障问题 此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令（和该指令的“邻居们”），这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘I/O完成为止，尽管其他的线程是可以运行的。 用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU。 在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度（轮流）的方式调度进程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。对线程永久运行问题的一个可能的解决方案是让运行时系统请求每秒一次的时钟信号（中断），但是这样对程序也是生硬和无序的。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。 在经常发生线程阻塞的应用中才希望使用多个线程。例如，在多线程Web服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行select系统调用，以便检查read系统调用是否安全。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢？这样的做法并不能得到任何益处。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:3","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"在内核中实现线程 内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中（在运行时系统中）的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息（即进程状态）的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。 所有能够阻塞线程的调用都以系统调用的形式实现，这与运行时系统过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程（若有一个就绪线程）或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU（或者没有可运行的线程存在了）为止。 由于在内核中创建或撤销线程的代价比较大，某些系统采取“环保”的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。 在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。 内核线程不需要任何新的、非阻塞系统调用。 如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:4","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"混合实现 使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来、采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。 内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。如同在没有多线程能力操作系统中某个进程中的用户级线程一样，可以创建、撤销和调度这些用户级线程。在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:5","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"调度程序激活机制 调度程序激活机制的一个目标是作为上行调用的信赖基础，这是一种违反分层次系统内在结构的概念。通常，n层提供n+1层可调用的特定服务，但是n层不能调用n+1层中的过程。上行调用并不遵守这个基本原理。 使该机制工作的基本思路是，当内核了解到一个线程被阻塞之后（例如，由于执行了一个阻塞系统调用或者产生了一个页面故障），内核通知该进程的运行时系统，并且在堆栈中以参数形式传递有问题的线程编号和所发生事件的一个描述。内核通过在一个已知的起始地址启动运行时系统，从而发出了通知，这是对UNIX中信号的一种粗略模拟。这个机制称为上行调用upcall 一旦如此激活，运行时系统就重新调度其线程，这个过程通常是这样的：把当前线程标记为阻塞并从就绪表中取出另一个线程，设置其寄存器，然后再启动之。稍后，当内核知道原来的线程又可运行时（例如，原先试图读取的管道中有了数据，或者已经从磁盘中读入了故障的页面），内核就又一次上行调用运行时系统，通知它这一事件。此时该运行时系统按照自己的判断，或者立即重启动被阻塞的线程，或者把它放入就绪表中稍后运行。 在某个用户线程运行的同时发生一个硬件中断时，被中断的CPU切换进核心态。如果被中断的进程对引起该中断的事件不感兴趣，比如，是另一个进程的I/O完成了，那么在中断处理程序结束之后，就把被中断的线程恢复到中断之前的状态。不过，如果该进程对中断感兴趣，比如，是该进程中的某个线程所需要的页面到达了，那么被中断的线程就不再启动，代之为挂起被中断的线程。而运行时系统则启动对应的虚拟CPU，此时被中断线程的状态保存在堆栈中。随后，运行时系统决定在该CPU上调度哪个线程：被中断的线程、新就绪的线程还是某个第三种选择。 调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。避免了在用户空间和内核空间之间的不必要转换、例如，如果某个线程由于等待另一个线程的工作而阻塞，此时没有理由请求内核，这样就减少了内核-用户转换的开销。用户空间的运行时系统可以阻塞同步的线程而另外调度一个新线程。 ","date":"2021-03-21","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/:1:6","tags":["操作系统"],"title":"进程与线程～线程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"ココの进程","date":"2021-03-20","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/","tags":["操作系统"],"title":"进程与线程～进程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"进程与线程～进程篇 ","date":"2021-03-20","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/:1:0","tags":["操作系统"],"title":"进程与线程～进程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"进程 进程模型 一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟CPU。 在一台多道程序计算机的内存中有4道程序。在图2-1b中，这4道程序被抽象为4个各自拥有自己控制流程（即每个程序自己的逻辑程序计数器）的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束（或暂停执行）时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中 在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。 一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。 创建进程 有4种主要事件导致进程的创建： 系统初始化。 启动操作系统时，通常会创建若干个进程。 执行了正在运行的进程所调用的进程创建系统调用。 除了在启动阶段创建进程之外，新的进程也可以以后创建。一个正在运行的进程经常发出系统调用，以便创建一个或多个新进程协助其工作。 用户请求创建一个新进程。 在交互式系统中，键入一个命令或者点（双）击一个图标就可以启动一个程序。在基于命令行的UNIX系统中运行程序X，新的进程会从该进程接管开启它的窗口。 一个批处理作业的初始化。 最后一种创建进程的情形仅在大型机的批处理系统中应用。用户在这种系统中（可能是远程地）提交批处理作业。在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。 在UNIX和Windows中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在UNIX中，子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间。 停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为守护进程（daemon） 进程的终止 正常退出（自愿的） 多数进程是由于完成了它们的工作而终止。当编译器完成了所给定程序的编译之后，编译器执行一个系统调用，通知操作系统它的工作已经完成。在UNIX中该调用是exit，而在Windows中，相关的调用是ExitProcess。 出错退出（自愿的） 进程终止的第二个原因是进程发现了严重错误。例如，如果用户键入命令cc foo.c、要编译程序foo.c，但是该文件并不存在，于是编译器就会退出。 严重错误（非自愿） 进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引用不存在的内存，或除数是零等。有些系统中（如UNIX），进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号（被中断），而不是在这类错误出现时终止。 被其他进程杀死（非自愿） 第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在UNIX中，这个系统调用是kill。在Win32中对应的函数是TerminateProcess。在这两种情形中，“杀手”都必须获得确定的授权以便进行动作。 进程的层次结构 某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。进程只有一个父进程（但是可以有零个、一个、两个或多个子进程）。 在UNIX中，进程和它的所有子女以及后裔共同组成一个进程组。 当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号杀死。 这里有另一个例子，可以用来说明进程层次的作用，考虑UNIX在启动时如何初始化自己。一个称为init的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一个用户登录成功，该登录进程就执行一个shell准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以init为根的一棵树。 相反，Windows中没有进程层次的概念，所有的进程都是地位相同的。惟一类似于进程层次的暗示是在创建进程的时侯，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。但是，它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在UNIX中，进程就不能剥夺其子女的“继承权”。 进程的状态 运行态（该时刻进程实际占用CPU） 就绪态（可运行，但因为其他进程正在运行而暂时停止） 阻塞态（除非某种外部事件发生，否则进程不能运行） 在操作系统发现进程不能继续运行下去时，发生转换1。转换2和3是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用CPU时间时，会发生转换2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用CPU运行时，会发生转换3。当进程等待的一个外部事件发生时（如一些输入到达），则发生转换4 从这个观点引出了所示的模型、操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。 进程的实现 **为了实现进程模型，操作系统维护着一张表格（一个结构数组），即进程表（process table）。**每个进程占用一个进程表项。（有些作者称这些表项为进程控制块。）该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。 第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。 在了解进程表后，就可以对在单个（或每一个）CPU上如何维持多个顺序进程的错觉做更多的阐述。与每一I/O类关联的是一个称作中断向量（interrupt vector）的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程3正在运行，则中断硬件将程序计数器、程序状态字，有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。 所有的中断都从保存寄存器开始，对于当前进程而言，通常是在进程表项中。随后，会从堆栈中删除由中断硬件机制存入堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用C语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。 当该例程结束后，它调用一个C过程处理某个特定的中断类型剩下的工作。（假定操作系统由C语言编写，通常这是所有真实操作系统的选择）。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行。图2-5中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。 多道程序设计模型 采用多道程序设计可以提高CPU的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的20%，且内存中同时有5个进程，则CPU将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这5个进程不会同时等待I/O。 更好的模型是从概率的角度来看CPU的利用率。假设一个进程等待I/O操作的时间与其停留在内存中时间的比为p。当内存中同时有n个进程时，则所有n个进程都在等待I/O（此时CPU空转）的概率是pn 。CPU的利用率由下面的公式给出：CPU利用率=1-p^n 从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它假设所有n个进程是独立的，即内存中的5个进程中，3个运行，2个等待，是完全可接受的。但在单CPU中，不能同时运行3个进程，所以当CPU忙时，已就绪的进程也必须等待CPU。因而，进程不是独立的。更精确的模型应该用排队论构造，但我们的模型（当进程就绪时，给进程分配CPU，否则让CPU空转）仍然是有效的 ","date":"2021-03-20","objectID":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/:1:1","tags":["操作系统"],"title":"进程与线程～进程篇","uri":"/posts/thinking/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%AF%87/"},{"categories":["操作系统"],"content":"ココの","date":"2021-03-17","objectID":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/","tags":["操作系统"],"title":"操作系统结构","uri":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"},{"categories":["操作系统"],"content":"操作系统结构 这六种设计是，单体系统、层次系统、微内核、客户机-服务器系统、虚拟机和exokernels等 单体系统 需要一个主程序，用来处理服务过程请求。 需要一套服务过程，用来执行系统调用。 需要一套实用过程，用来辅助服务过程。 每一个系统调用都通过一个服务过程为其工作并运行之。要有一组实用程序来完成一些服务过程所需要用到的功能，如从用户程序取数据等。可将各种过程划分为一个三层的模型 进一步通用化，就变成一个层次式结构的操作系统，它的上层软件都是在下一层软件的基础之上构建的。 层次式系统 内存管理在第1层中进行，它分配进程的主存空间，当内存用完时则在一个512K字的磁鼓上保留进程的一部分（页面）。在第1层上，进程不用考虑它是在磁鼓上还是在内存中运行。第1层软件保证一旦需要访问某一页面时，该页面必定已在内存中。第2层处理进程与操作员控制台（即用户）之间的通信。在这层的上部，可以认为每个进程都有自己的操作员控制台。第3层管理I/O设备和相关的信息流缓冲区。在第3层上，每个进程都与有良好特性的抽象I/O设备打交道，而不必考虑外部设备的物理细节。第4层是用户程序层。用户程序不用考虑进程、内存、控制台或I/O设备管理等细节。系统操作员进程位于第5层中。 在分层方式中，设计者要确定在哪里划分内核-用户的边界。在传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能的做法更好，因为内核中的错误会快速拖累系统。 微内核 微内核设计背后的思想是，为了实现高可靠性，将操作系统划分成小的、良好定义的模块，只有其中一个模块——微内核——运行在内核态上，其余的模块，由于功能相对弱些，则作为普通用户进程运行。这些模块中的错误虽然会使这些模块崩溃，但是不会使得整个系统死机。 在内核的外部，系统的构造有三层进程，它们都在用户态中运行。最底层中包含设备驱动器。由于它们在用户态中运行，所以不能物理地访问I/O端口空间，也不能直接发出I/O命令。相反，为了能够对I/O设备编程，驱动器构建了一个结构，指明哪个参数值写到哪个I/O端口，并生成一个内核调用，通知内核完成写操作。这个处理意味着内核可以检查驱动正在对I/O的读（或写）是否是得到授权使用的。这样，（与单体设计不同），一个有错误的操作就不能够偶发性地在硬盘上进行写操作。 系统对每个进程的权限有着许多限制。正如已经提及的，设备驱动器只能与授权的I/O端口接触，对内核调用的访问也是按单个进程进行控制的，是考虑到进程具有向其他多个进程发送消息的能力。进程也可获得有限的许可，让在内核的其他进程访问其地址空间。 一个与小内核相关联的思想是在内核中的机制与策略分离的原则。 客户机-服务器模式 一个微内核思想的略微变体是将进程划分为两类：服务器，每个服务器提供某种服务；客户端，使用这些服务。这个模式就是所谓的客户机-服务器模式。通常，在系统最底层是微内核，但并不是必须这样的。这个模式的本质是存在客户端进程和服务器进程。 这个思想的一个显然的、普遍方式是，客户端和服务器运行在不同的计算机上，它们通过局域或广域网连接，由于客户端通过发送消息与服务器通信，客户端并不需要知道这些消息是在它们的本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。所以，客户机-服务器模式是一种可以应用在单机或者网络机器上的抽象。 虚拟机 这个系统最初被命名为CP/CMS，后来改名为VM/370（Seawright和MacKinnon，1979）。它是源于如下一种机敏的观察。分时系统应该提供这些功能：（1）多道程序，（2）一个比裸机更方便的、有扩展界面的计算机。VM/370存在的目的是将二者彻底地隔离开来。 这个系统的核心称为虚拟机监控程序（virtual machine monitor），它在裸机上运行并且具备了多道程序功能。该系统向上层提供了若干台虚拟机，它不同于其他操作系统的地方是：这些虚拟机不是那种具有文件等优良特征的扩展计算机。与之相反，它们仅仅是裸机硬件的精确复制品。这个复制品包含了内核态/用户态、I/O功能、中断及其他真实硬件所应该具有的全部内容。 外核 在底层中，一种称为外核（exokernel，Engler等人，1995）的程序在内核态中运行。它的任务是为虚拟机分配资源，并检查试图使用这些资源的企图，以确保没有机器会使用他人的资源。每个用户层的虚拟机可以运行自己的操作系统，如VM/370和Pentium虚拟8086等，但限制在只能使用已经申请并且获得分配的那部分资源。 外核机制的优点是，它减少了映像层。在其他的设计中，每个虚拟机都认为它有自己的磁盘，其盘块号从0到最大编号，这样虚拟机监控程序必须维护一张表格用以重映像磁盘地址（以及其他资源）。有了外核这个重映像处理就不需要了。外核只需要记录已经分配给各个虚拟机的有关资源即可。这个方法还有一个优点，它将多道程序（在外核内）与用户操作系统代码（在用户空间内）加以分离，而且相应负载并不重，这是因为外核所做的一切，只是保持多个虚拟机彼此不发生冲突。 与虚拟机克隆真实机器不同，另一种策略是对机器进行分区，换句话说，给每个用户整个资源的一个子集。 参考书籍：现代操作系统（原书第4版）_Modern Operating Systems (4th Edition) ([荷] Andrew S. Tanenbaum [荷] Herbert Bos) ","date":"2021-03-17","objectID":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/:0:1","tags":["操作系统"],"title":"操作系统结构","uri":"/posts/thinking/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"},{"categories":["操作系统"],"content":"ココの操作系统","date":"2021-03-04","objectID":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/","tags":["操作系统"],"title":"操作系统概念","uri":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["操作系统"],"content":"现代操作系统概念 进程 进程本质上是正在执行的一个程序。 与每个进程相关的是进程的地址空间（address space），这是从某个最小值的存储位置（通常是零）到某个最大值存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器（含有程序计数器和堆栈指针）、打开文件的清单、突出的报警、有关进程清单，以及运行该程序所需要的所有其他信息。进程基本上是容纳运行一个程序所需要所有信息的容器。 若一个进程能够创建一个或多个进程（称为子进程），而且这些进程又可以创建子进程，则很容易得到进程树,合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为进程间通信（interprocess communication） 可用的进程系统调用包括：申请更多的内存（或释放不再需要的内存）、等待一个子进程结束、用另一个程序覆盖该程序等。 系统管理器授权每个进程使用一个给定的UID标识（User IDentification）。每个被启动的进程都有一个启动该进程的用户UID。子进程拥有与父进程一样的UID。用户可以是某个组的成员，每个组也有一个GID标识（Group IDentification）。 地址空间 较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们彼此互相干扰（包括操作系统），需要有某种保护机制。虽然这种机制必然是硬件形式的，但是它由操作系统掌控。上述的观点涉及对计算机主存的管理和保护。 另一种不同的但是同样重要并与存储器有关的内容，是管理进程的地址空间。通常，每个进程有一些可以使用的地址集合，典型值从0开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程。 文件 为了提供保存文件的地方，大多数操作系统支持目录（directory）的概念，从而可把文件分类成组。 进程和文件层次都可以组织成树状结构，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地，只有父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也可以访问该文件。 管道。管道（pipe）是一种虚文件，它可连接两个进程，如图1-16所示。如果进程A和B希望通过管道对话，它们必须提前设置该管道。当进程A想对进程B发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据，仿佛该管道就是一个输入文件一样。这样，在UNIX中两个进程之间的通信就很类似于普通文件的读写了。 输入输出 所有的计算机都有用来获取输入和产生输出的物理设备。有各种类型的输入和输出设备，包括键盘、显示器、打印机等。对这些设备的管理全然依靠操作系统。 所以，每个操作系统都有管理其I/O设备的I/O子系统。某些I/O软件是设备独立的，即这些I/O软件部分可以同样应用于许多或者全部的I/O设备上。I/O软件的其他部分，如设备驱动程序，是专门为特定的I/O设备设计的 保护 计算机中有大量的信息，用户经常希望对其进行保护，并保守秘密。这些信息可包括电子邮件、商业计划、退税等诸多内容。管理系统的安全性完全依靠操作系统 参考UNIX。UNIX操作系统通过对每个文件赋予一个9位的二进制保护代码，对UNIX中的文件实现保护。该保护代码有三个3位字段，一个用于所有者，一个用于所有者同组（用户被系统管理员划分成组）中的其他成员，而另一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是知名的rwx位。 shell 操作系统是进行系统调用的代码 shell本身不是操作系统的一部分，但它体现了许多操作系统的特性，并很好地说明了系统调用的具体用法。shell同时也是终端用户与操作系统之间的界面，除非用户使用的是一个图形用户界面。有许多种类的shell，如sh、csh、ksh以及bash等 个体重复系统发育 大型内存 保护硬件 硬盘 虚拟内存 参考书籍：现代操作系统（原书第4版）_Modern Operating Systems (4th Edition) ([荷] Andrew S. Tanenbaum [荷] Herbert Bos) ","date":"2021-03-04","objectID":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:0:1","tags":["操作系统"],"title":"操作系统概念","uri":"/posts/thinking/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"}]